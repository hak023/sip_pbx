"""
Extraction Pipeline v2

ë©€í‹°ìŠ¤í… ì§€ì‹ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.
Chain-of-Interactions (EMNLP 2025) ì°¸ì¡°.

íŒŒì´í”„ë¼ì¸:
  Stage 1: ì „ì²˜ë¦¬ (transcript ë¡œë“œ)
  Stage 2: ë©€í‹°ìŠ¤í… ì¶”ì¶œ (ìš”ì•½ â†’ QA â†’ ì—”í‹°í‹° â†’ ìœ ìš©ì„±)
  Stage 3: í’ˆì§ˆ ê²€ì¦ (í™˜ê° â†’ ì¤‘ë³µ â†’ í’ˆì§ˆ ê²Œì´íŠ¸)
  Stage 4: VectorDB ì €ì¥ (í™•ì¥ ë©”íƒ€ë°ì´í„°)
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass, field

import structlog

from .summarizer import ConversationSummarizer
from .qa_extractor import QAPairExtractor
from .entity_extractor import EntityExtractor
from .hallucination_checker import HallucinationChecker
from .semantic_deduplicator import SemanticDeduplicator
from .quality_gate import QualityGate

logger = structlog.get_logger(__name__)

# íŒŒì´í”„ë¼ì¸ ë²„ì „
PIPELINE_VERSION = "v2"


@dataclass
class ExtractionItem:
    """ì¶”ì¶œëœ ê°œë³„ í•­ëª©"""
    doc_type: str           # "knowledge" | "qa_pair" | "entity"
    text: str               # VectorDBì— ì €ì¥í•  í…ìŠ¤íŠ¸ (ê²€ìƒ‰ìš©)
    category: str
    confidence: float
    keywords: List[str] = field(default_factory=list)
    # QA ì „ìš©
    question: Optional[str] = None
    answer: Optional[str] = None
    source_speaker: Optional[str] = None
    # Entity ì „ìš©
    entity_type: Optional[str] = None
    normalized_value: Optional[str] = None
    entity_speaker: Optional[str] = None
    # í’ˆì§ˆ ê²€ì¦ ê²°ê³¼
    hallucination_passed: bool = True
    dedup_status: str = "unique"       # "unique" | "duplicate" | "near_duplicate"
    merged_with: Optional[str] = None
    quality_passed: bool = True
    quality_warnings: List[str] = field(default_factory=list)


@dataclass
class ExtractionResult:
    """íŒŒì´í”„ë¼ì¸ ì „ì²´ ê²°ê³¼"""
    call_id: str
    success: bool
    pipeline_version: str = PIPELINE_VERSION
    # ìš”ì•½
    summary: str = ""
    main_topics: List[str] = field(default_factory=list)
    call_purpose: str = ""
    # ì¶”ì¶œ í•­ëª©
    items: List[ExtractionItem] = field(default_factory=list)
    # ì €ì¥ í†µê³„
    stored_count: int = 0
    skipped_duplicate: int = 0
    skipped_quality: int = 0
    skipped_hallucination: int = 0
    # íƒ€ì´ë°
    elapsed_ms: float = 0
    error: Optional[str] = None


class ExtractionPipeline:
    """ë©€í‹°ìŠ¤í… ì§€ì‹ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ v2"""

    def __init__(
        self,
        llm_client,
        embedder,
        vector_db,
        config: Optional[Dict] = None,
    ):
        """
        Args:
            llm_client: LLMClient ì¸ìŠ¤í„´ìŠ¤
            embedder: TextEmbedder ì¸ìŠ¤í„´ìŠ¤
            vector_db: VectorDB ì¸ìŠ¤í„´ìŠ¤
            config: knowledge_extraction ì„¤ì • (config.yaml)
        """
        self.llm = llm_client
        self.embedder = embedder
        self.vector_db = vector_db
        self.config = config or {}

        # ìŠ¤í… ì„¤ì •
        steps = self.config.get("steps", {})
        self.enable_summarize = steps.get("summarize", True)
        self.enable_qa_extract = steps.get("qa_extract", True)
        self.enable_entity_extract = steps.get("entity_extract", True)

        # í’ˆì§ˆ ì„¤ì •
        quality_cfg = self.config.get("quality", {})
        self.min_confidence = quality_cfg.get("min_confidence", 0.7)
        self.enable_hallucination = quality_cfg.get("hallucination_check", True)
        self.enable_dedup = quality_cfg.get("deduplication", True)

        # ìë™ ìŠ¹ì¸
        auto_cfg = self.config.get("auto_approve", {})
        self.auto_approve_enabled = auto_cfg.get("enabled", True)
        self.auto_approve_confidence = auto_cfg.get("min_confidence", 0.9)

        # ë¹„ìš© ì œì–´
        self.max_llm_calls = self.config.get("max_llm_calls_per_extraction", 6)
        self.skip_short_calls = self.config.get("skip_short_calls_seconds", 30)

        # ì„œë¸Œ ì»´í¬ë„ŒíŠ¸
        self.summarizer = ConversationSummarizer(llm_client)
        self.qa_extractor = QAPairExtractor(llm_client)
        self.entity_extractor = EntityExtractor(llm_client)
        self.hallucination_checker = HallucinationChecker(embedder, llm_client)
        self.deduplicator = SemanticDeduplicator(vector_db, embedder)
        self.quality_gate = QualityGate(
            min_confidence=self.min_confidence,
            min_text_length=self.config.get("min_text_length", 10),
            max_text_length=self.config.get("max_text_length", 2000),
        )

        # ì²­í‚¹ ì„¤ì •
        self.chunk_size = self.config.get("chunk_size", 500)
        self.chunk_overlap = self.config.get("chunk_overlap", 50)

        # í†µê³„
        self.total_extractions = 0
        self.total_stored = 0

        logger.info(
            "ExtractionPipeline v2 initialized",
            steps=steps,
            quality=quality_cfg,
        )

    async def extract_from_call(
        self,
        call_id: str,
        transcript_path: str,
        owner_id: str,
        speaker: str = "both",
    ) -> ExtractionResult:
        """
        í†µí™”ì—ì„œ ì§€ì‹ ì¶”ì¶œ (v2 íŒŒì´í”„ë¼ì¸)

        Args:
            call_id: í†µí™” ID
            transcript_path: ì „ì‚¬ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            owner_id: ì†Œìœ ì ID
            speaker: í™”ì í•„í„° (caller/callee/both)

        Returns:
            ExtractionResult
        """
        import time
        start_time = time.time()

        result = ExtractionResult(call_id=call_id, success=False)

        try:
            # â”€â”€ Stage 1: ì „ì²˜ë¦¬ â”€â”€
            logger.info("ğŸ“‹ [Pipeline v2] Stage 1: ì „ì²˜ë¦¬", call_id=call_id)

            full_transcript = self._load_transcript(transcript_path)
            if not full_transcript or len(full_transcript.strip()) < 10:
                result.error = "Empty or too short transcript"
                logger.warning("pipeline_skip_empty", call_id=call_id)
                return result

            # í™”ì í•„í„° (QA/ì—”í‹°í‹°/ìš”ì•½ìš©). ì§€ì‹ ì •ì œ(judge_usefulness)ì—ëŠ” ì „ì²´ ì „ì‚¬ ì „ë‹¬(ë§¥ë½)
            transcript = full_transcript
            if speaker not in ("both", "all"):
                transcript = self._filter_by_speaker(full_transcript, speaker)
                if not transcript:
                    result.error = "No content from target speaker"
                    return result

            # â”€â”€ Stage 2: ë©€í‹°ìŠ¤í… ì¶”ì¶œ â”€â”€
            logger.info("ğŸ”¬ [Pipeline v2] Stage 2: ë©€í‹°ìŠ¤í… ì¶”ì¶œ", call_id=call_id)

            items: List[ExtractionItem] = []

            # Step 2-1: ìš”ì•½ (ë³‘ë ¬ ì‹œì‘)
            summary_task = None
            if self.enable_summarize:
                summary_task = asyncio.create_task(
                    self.summarizer.summarize(transcript, call_id)
                )

            # Step 2-2: QA ìŒ ì¶”ì¶œ
            qa_pairs = []
            if self.enable_qa_extract:
                qa_pairs = await self.qa_extractor.extract(transcript, call_id)
                for qa in qa_pairs:
                    # QA ìŒì€ "Q: ... A: ..." í˜•íƒœë¡œ VectorDBì— ì €ì¥ (ê²€ìƒ‰ ìµœì í™”)
                    qa_text = f"Q: {qa['question']}\nA: {qa['answer']}"
                    items.append(ExtractionItem(
                        doc_type="qa_pair",
                        text=qa_text,
                        category=qa.get("category", "ì •ë³´"),
                        confidence=0.85,  # QA ì¶”ì¶œì€ ê¸°ë³¸ 0.85
                        keywords=self._extract_keywords(qa_text),
                        question=qa["question"],
                        answer=qa["answer"],
                        source_speaker=qa.get("source_speaker", ""),
                    ))

            # Step 2-3: ì—”í‹°í‹° ì¶”ì¶œ
            entities = []
            if self.enable_entity_extract:
                entities = await self.entity_extractor.extract(transcript, call_id)
                for ent in entities:
                    ent_text = f"{ent['entity_type']}: {ent['value']}"
                    if ent.get("context"):
                        ent_text += f" ({ent['context']})"
                    items.append(ExtractionItem(
                        doc_type="entity",
                        text=ent_text,
                        category=ent["entity_type"],
                        confidence=ent.get("confidence", 0.8),
                        entity_type=ent["entity_type"],
                        normalized_value=ent.get("normalized"),
                        entity_speaker=ent.get("speaker", ""),
                    ))

            # Step 2-4: ì§€ì‹ ì •ì œ â€” ì„¤ê³„ì„œ: ë§¥ë½ ìœ„í•´ ì „ì²´ ì „ì‚¬ ì „ë‹¬, ì €ì¥ì€ ì°©ì‹ ì ë°œí™”ë§Œ
            judgment = await self.llm.judge_usefulness(full_transcript, speaker, call_id=call_id)
            if judgment.get("is_useful") and judgment.get("confidence", 0) >= self.min_confidence:
                for info in judgment.get("extracted_info", []):
                    info_text = info.get("text", "")
                    if info_text and len(info_text) >= 10:
                        items.append(ExtractionItem(
                            doc_type="knowledge",
                            text=info_text,
                            category=info.get("category", "ê¸°íƒ€"),
                            confidence=judgment["confidence"],
                            keywords=info.get("keywords", []),
                        ))

            # ìš”ì•½ ê²°ê³¼ ìˆ˜ì§‘
            if summary_task:
                summary_data = await summary_task
                result.summary = summary_data.get("summary", "")
                result.main_topics = summary_data.get("main_topics", [])
                result.call_purpose = summary_data.get("call_purpose", "")

            logger.info(
                "ğŸ”¬ [Pipeline v2] Stage 2 ì™„ë£Œ",
                call_id=call_id,
                qa_count=len(qa_pairs),
                entity_count=len(entities),
                knowledge_count=sum(1 for i in items if i.doc_type == "knowledge"),
                total_items=len(items),
            )

            if not items:
                result.success = True
                result.elapsed_ms = (time.time() - start_time) * 1000
                logger.info("pipeline_no_items", call_id=call_id)
                return result

            # â”€â”€ Stage 3: í’ˆì§ˆ ê²€ì¦ â”€â”€
            logger.info("âœ… [Pipeline v2] Stage 3: í’ˆì§ˆ ê²€ì¦", call_id=call_id)

            verified_items: List[ExtractionItem] = []

            for item in items:
                # 3-1: í™˜ê° ê²€ì¦
                if self.enable_hallucination:
                    halluc = await self.hallucination_checker.check(
                        item.text,
                        transcript,
                        skip_entailment=(item.confidence >= 0.9),
                    )
                    item.hallucination_passed = halluc.passed
                    if not halluc.passed:
                        result.skipped_hallucination += 1
                        logger.debug(
                            "hallucination_skip",
                            text=item.text[:50],
                            reason=halluc.details,
                        )
                        continue

                # 3-2: í’ˆì§ˆ ê²Œì´íŠ¸
                qr = self.quality_gate.check({
                    "text": item.text,
                    "confidence": item.confidence,
                    "category": item.category,
                    "hallucination_passed": item.hallucination_passed,
                })
                item.quality_passed = qr.passed
                item.quality_warnings = qr.warnings
                if not qr.passed:
                    result.skipped_quality += 1
                    logger.debug(
                        "quality_gate_skip",
                        text=item.text[:50],
                        rules=qr.failed_rules,
                    )
                    continue

                # 3-3: ì¤‘ë³µ ê²€ì¦
                if self.enable_dedup:
                    embedding = await self.embedder.embed(item.text)
                    dedup = await self.deduplicator.check(item.text, embedding)
                    item.dedup_status = dedup.status
                    item.merged_with = dedup.similar_doc_id
                    if dedup.action == "skip":
                        result.skipped_duplicate += 1
                        logger.debug(
                            "dedup_skip",
                            text=item.text[:50],
                            similar=dedup.similar_doc_id,
                        )
                        continue

                verified_items.append(item)

            logger.info(
                "âœ… [Pipeline v2] Stage 3 ì™„ë£Œ",
                call_id=call_id,
                verified=len(verified_items),
                skipped_halluc=result.skipped_hallucination,
                skipped_quality=result.skipped_quality,
                skipped_dedup=result.skipped_duplicate,
            )

            # â”€â”€ Stage 4: VectorDB ì €ì¥ â”€â”€
            logger.info("ğŸ’¾ [Pipeline v2] Stage 4: ì €ì¥", call_id=call_id)

            now = datetime.now().isoformat()

            for idx, item in enumerate(verified_items):
                doc_id = f"{call_id}_{item.doc_type}_{idx}"
                embedding = await self.embedder.embed(item.text)

                # ìë™ ìŠ¹ì¸ íŒì •
                review_status = "pending"
                if self.auto_approve_enabled and item.confidence >= self.auto_approve_confidence:
                    if item.hallucination_passed:
                        review_status = "approved"

                metadata = {
                    # ê¸°ë³¸
                    "doc_type": item.doc_type,
                    "category": item.category,
                    "keywords": ",".join(item.keywords) if item.keywords else "",
                    # ì¶”ì¶œ ì¶œì²˜
                    "extraction_source": "call",
                    "extraction_call_id": call_id,
                    "extraction_timestamp": now,
                    "extraction_pipeline_version": PIPELINE_VERSION,
                    "owner": owner_id,
                    # í’ˆì§ˆ
                    "confidence_score": item.confidence,
                    "hallucination_check": "passed" if item.hallucination_passed else "failed",
                    "dedup_status": item.dedup_status,
                    "merged_with": item.merged_with or "",
                    # ë¦¬ë·°
                    "review_status": review_status,
                    "reviewed_by": "",
                    "reviewed_at": "",
                    # í™œìš© ì¶”ì 
                    "usage_count": 0,
                    "last_used_at": "",
                    "useful_feedback_count": 0,
                }

                # QA ì „ìš© í•„ë“œ
                if item.doc_type == "qa_pair":
                    metadata["question"] = item.question or ""
                    metadata["source_speaker"] = item.source_speaker or ""

                # Entity ì „ìš© í•„ë“œ
                if item.doc_type == "entity":
                    metadata["entity_type"] = item.entity_type or ""
                    metadata["normalized_value"] = item.normalized_value or ""
                    metadata["entity_speaker"] = item.entity_speaker or ""

                await self.vector_db.upsert(
                    doc_id=doc_id,
                    embedding=embedding,
                    text=item.text,
                    metadata=metadata,
                )
                result.stored_count += 1

            result.items = verified_items
            result.success = True
            result.elapsed_ms = (time.time() - start_time) * 1000

            self.total_extractions += 1
            self.total_stored += result.stored_count

            logger.info(
                "ğŸ‰ [Pipeline v2] ì¶”ì¶œ ì™„ë£Œ",
                call_id=call_id,
                stored=result.stored_count,
                elapsed_ms=f"{result.elapsed_ms:.0f}",
                summary_topics=result.main_topics,
            )

            return result

        except Exception as e:
            result.error = str(e)
            result.elapsed_ms = (time.time() - start_time) * 1000
            logger.error(
                "pipeline_error",
                call_id=call_id,
                error=str(e),
                exc_info=True,
            )
            return result

    # â”€â”€ ìœ í‹¸ë¦¬í‹° â”€â”€

    def _load_transcript(self, path: str) -> str:
        try:
            return Path(path).read_text(encoding="utf-8")
        except Exception as e:
            logger.warning("transcript_load_error", path=path, error=str(e))
            return ""

    @staticmethod
    def _filter_by_speaker(transcript: str, speaker: str) -> str:
        label = "ì°©ì‹ ì" if speaker == "callee" else "ë°œì‹ ì"
        lines = []
        for line in transcript.split("\n"):
            line = line.strip()
            if ":" in line:
                parts = line.split(":", 1)
                if parts[0].strip() == label:
                    text = parts[1].strip()
                    if text:
                        lines.append(text)
        return " ".join(lines)

    @staticmethod
    def _extract_keywords(text: str) -> List[str]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ í•œê¸€ ëª…ì‚¬ í›„ë³´)"""
        import re
        tokens = re.findall(r'[ê°€-í£]{2,}', text)
        # ë¹ˆë„ìˆœ ìƒìœ„ 5ê°œ
        freq: Dict[str, int] = {}
        for t in tokens:
            freq[t] = freq.get(t, 0) + 1
        sorted_tokens = sorted(freq.items(), key=lambda x: -x[1])
        return [t for t, _ in sorted_tokens[:5]]

    def get_stats(self) -> Dict:
        return {
            "total_extractions": self.total_extractions,
            "total_stored": self.total_stored,
            "pipeline_version": PIPELINE_VERSION,
            "steps": {
                "summarize": self.enable_summarize,
                "qa_extract": self.enable_qa_extract,
                "entity_extract": self.enable_entity_extract,
            },
        }
