"""
AI Orchestrator

AI ë³´ì´ìŠ¤ë´‡ì˜ í•µì‹¬ ë¡œì§ - ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ê³  ëŒ€í™” íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤.
"""

import asyncio
from typing import Optional, Dict, Any
import structlog

from ..models.conversation import AIConversation, ConversationState
from ..audio_buffer import AudioBuffer
from ..vad_detector import VADDetector
from ..ai_pipeline.stt_client import STTClient
from ..ai_pipeline.tts_client import TTSClient
from ..ai_pipeline.llm_client import LLMClient
from ..ai_pipeline.rag_engine import RAGEngine
from ..recording.recorder import CallRecorder
from ..knowledge.knowledge_extractor import KnowledgeExtractor
from ..knowledge.organization_info import get_organization_manager, OrganizationInfoManager
from .barge_in_controller import BargeInController
from src.sip_core.models.outbound import OutboundCallResult, TranscriptEntry

logger = structlog.get_logger(__name__)

# HITL ê´€ë ¨ import (ì„ íƒì )
try:
    from ...services.hitl import HITLService
    from ...websocket import manager as websocket_manager
    HITL_AVAILABLE = True
except ImportError:
    logger.info("hitl_not_available", 
                message="HITL modules not available. HITL features will be disabled.")
    HITLService = None
    websocket_manager = None
    HITL_AVAILABLE = False


class AIOrchestrator:
    """
    AI Orchestrator
    
    AI ë³´ì´ìŠ¤ë´‡ì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¡œ, ëª¨ë“  AI íŒŒì´í”„ë¼ì¸ì„ í†µí•©í•˜ê³ 
    ëŒ€í™” íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Args:
            config: AI ë³´ì´ìŠ¤ë´‡ ì„¤ì •
        """
        self.config = config
        
        # ëŒ€í™” ìƒíƒœ
        self.conversation: Optional[AIConversation] = None
        self.state = ConversationState.IDLE
        self.is_speaking = False
        self.current_user_speech = ""
        
        # í†µí™” ì •ë³´
        self.call_id: Optional[str] = None
        self.caller: Optional[str] = None
        self.callee: Optional[str] = None
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ì§€ì—° ì´ˆê¸°í™”)
        self.audio_buffer: Optional[AudioBuffer] = None
        self.vad: Optional[VADDetector] = None
        self.stt: Optional[STTClient] = None
        self.tts: Optional[TTSClient] = None
        self.llm: Optional[LLMClient] = None
        self.rag: Optional[RAGEngine] = None
        self.recorder: Optional[CallRecorder] = None
        self.extractor: Optional[KnowledgeExtractor] = None
        
        # âœ… ê¸°ê´€ ì •ë³´ ê´€ë¦¬ì
        self.org_manager = get_organization_manager()
        
        # âœ… Barge-in ì œì–´ê¸°
        self.barge_in_controller = BargeInController(
            silence_threshold=config.get('silence_threshold', 2.0)
        )
        
        # RTP ì „ì†¡ ì½œë°±
        self.rtp_send_callback = None
        
        # í†µê³„
        self.total_calls = 0
        self.total_turns = 0
        
        # HITL ì§€ì› (ì¶”ê°€)
        self.hitl_service: Optional[HITLService] = None
        self.hitl_enabled = config.get('hitl', {}).get('enabled', False)
        self.hitl_confidence_threshold = config.get('hitl', {}).get('confidence_threshold', 0.6)
        self.hitl_response_event: Optional[asyncio.Event] = None
        self.hitl_response_text: Optional[str] = None
        self.is_waiting_for_human = False
        
        logger.info("AIOrchestrator created", hitl_enabled=self.hitl_enabled)
    
    async def initialize(
        self,
        audio_buffer: AudioBuffer,
        vad: VADDetector,
        stt: STTClient,
        tts: TTSClient,
        llm: LLMClient,
        rag: RAGEngine,
        recorder: CallRecorder,
        extractor: KnowledgeExtractor
    ):
        """
        ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        
        Args:
            audio_buffer: Audio Buffer
            vad: VAD Detector
            stt: STT Client
            tts: TTS Client
            llm: LLM Client
            rag: RAG Engine
            recorder: Call Recorder
            extractor: Knowledge Extractor
        """
        self.audio_buffer = audio_buffer
        self.vad = vad
        self.stt = stt
        self.tts = tts
        self.llm = llm
        self.rag = rag
        self.recorder = recorder
        self.extractor = extractor
        
        logger.info("AIOrchestrator initialized with all components")
    
    def set_rtp_callback(self, callback):
        """
        RTP ì „ì†¡ ì½œë°± ì„¤ì •
        
        Args:
            callback: async def callback(audio_data: bytes)
        """
        self.rtp_send_callback = callback
    
    async def handle_call(
        self, 
        call_id: str, 
        caller: str,
        callee: str
    ):
        """
        AI í†µí™” ì²˜ë¦¬ ë©”ì¸ ë¡œì§
        
        Args:
            call_id: í†µí™” ID
            caller: ë°œì‹ ì
            callee: ì°©ì‹ ì
        """
        try:
            self.call_id = call_id
            self.caller = caller
            self.callee = callee
            self.total_calls += 1
            
            # ëŒ€í™” ì„¸ì…˜ ìƒì„±
            from datetime import datetime
            self.conversation = AIConversation(
                session_id=f"ai_{call_id}",
                call_id=call_id,
                caller=caller,
                callee=callee,
                started_at=datetime.now()
            )
            
            # ë…¹ìŒ ì‹œì‘
            self.recorder.start_recording(call_id)
            
            # ì˜¤ë””ì˜¤ ë²„í¼ ì‹œì‘
            await self.audio_buffer.start()
            
            # STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
            await self.stt.start_stream(self._on_stt_result)
            
            # 1. ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ
            self.state = ConversationState.GREETING
            await self.play_greeting()
            
            # 2. ëŒ€í™” ë£¨í”„ ì‹œì‘
            self.state = ConversationState.LISTENING
            
            logger.info("AI call handling started",
                       call_id=call_id,
                       caller=caller,
                       callee=callee)
            
        except Exception as e:
            logger.error("Handle call error", error=str(e), exc_info=True)
            self.state = ConversationState.ENDED
    
    async def on_audio_packet(self, audio_data: bytes, direction: str = "caller"):
        """
        RTP íŒ¨í‚· ìˆ˜ì‹  ì²˜ë¦¬
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„°
            direction: ë°©í–¥ (caller/callee)
        """
        if self.state == ConversationState.ENDED:
            return
        
        try:
            # ë…¹ìŒ
            if direction == "caller":
                self.recorder.add_caller_audio(audio_data)
            else:
                self.recorder.add_callee_audio(audio_data)
            
            # Caller ìŒì„±ë§Œ ì²˜ë¦¬ (AIê°€ Callee ì—­í• )
            if direction != "caller":
                return
            
            # VAD ê²€ì‚¬
            is_speech = self.vad.detect(audio_data)
            
            # Barge-in í™•ì¸
            if self.vad.is_barge_in() and self.is_speaking:
                logger.info("Barge-in detected, stopping TTS")
                await self.stop_speaking()
                self.state = ConversationState.LISTENING
            
            # STTë¡œ ì „ì†¡
            await self.stt.send_audio(audio_data)
            
        except Exception as e:
            logger.error("Audio packet processing error", error=str(e))
    
    async def _on_stt_result(self, text: str, is_final: bool):
        """
        STT ê²°ê³¼ ìˆ˜ì‹  ì½œë°± (Barge-in ì œì–´ í†µí•©)
        
        Args:
            text: ì¸ì‹ëœ í…ìŠ¤íŠ¸
            is_final: ìµœì¢… ê²°ê³¼ ì—¬ë¶€
        """
        # 1. Barge-in Controllerë¡œ í•„í„°ë§
        if not self.barge_in_controller.should_process_speech(is_final):
            logger.debug("STT result ignored (TTS speaking or barge-in disabled)",
                        text=text[:50] if text else "",
                        is_final=is_final)
            return
        
        # 2. ìŒì„± ê°ì§€ ë“±ë¡
        self.barge_in_controller.on_speech_detected(text, is_final)
        
        if not is_final:
            # Interim result
            self.current_user_speech = text
            logger.debug("STT interim", text=text[:50])
            return
        
        # 3. ì¹¨ë¬µ ê°ì§€ (2ì´ˆ ì´ìƒ ë§ì´ ì—†ìœ¼ë©´ ë°œí™” ì™„ë£Œë¡œ ê°„ì£¼)
        await asyncio.sleep(2.0)
        
        if self.barge_in_controller.check_silence():
            # 4. ë°œí™” ì™„ë£Œ - ëˆ„ì ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            user_text = self.barge_in_controller.get_and_reset_utterance()
            
            if not user_text:
                return
            
            logger.info("STT final result (after silence)", text=user_text)
            
            # 5. ëŒ€í™” ë©”ì‹œì§€ ì¶”ê°€
            if self.conversation:
                self.conversation.add_message("user", user_text)
            
            self.total_turns += 1
            
            # 6. ë‹µë³€ ìƒì„± ë° ì¬ìƒ
            await self.generate_and_speak_response(user_text)
    
    async def generate_and_speak_response(self, user_text: str):
        """
        ë‹µë³€ ìƒì„± ë° ì¬ìƒ (ê¸°ê´€ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ + Transfer Intent ê°ì§€)
        
        Args:
            user_text: ì‚¬ìš©ì ì§ˆë¬¸
        """
        try:
            self.state = ConversationState.THINKING
            
            # 1. ê¸°ê´€ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            org_context = self.org_manager.get_full_context_for_llm(user_text)
            
            logger.info("Organization context prepared",
                       context_length=len(org_context))
            
            # 2. RAG ê²€ìƒ‰ (call_id ì „ë‹¬)
            documents = await self.rag.search(
                query=user_text,
                owner_filter=self.callee,
                call_id=self.call_id  # DB ë¡œê¹…ìš©
            )
            
            # â˜… Transfer intent ê°ì§€: ìƒìœ„ ê²°ê³¼ì˜ response_type í™•ì¸
            if documents and len(documents) > 0:
                top_doc = documents[0]
                response_type = getattr(top_doc, 'metadata', {}).get('response_type', 'info') if hasattr(top_doc, 'metadata') else 'info'
                similarity_score = getattr(top_doc, 'score', 0.0)
                
                # Transfer intent ê°ì§€ (ë†’ì€ ìœ ì‚¬ë„ + transfer íƒ€ì…)
                transfer_threshold = self.config.get('transfer', {}).get('min_similarity_threshold', 0.75) if isinstance(self.config.get('transfer'), dict) else 0.75
                if response_type == "transfer" and similarity_score >= transfer_threshold:
                    logger.info("transfer_intent_detected",
                               call_id=self.call_id,
                               user_text=user_text,
                               department=getattr(top_doc, 'metadata', {}).get('display_name', '') if hasattr(top_doc, 'metadata') else '',
                               score=similarity_score)
                    await self._handle_transfer_intent(user_text, top_doc)
                    return
            
            context_docs = [doc.text for doc in documents]
            
            # ê¸°ê´€ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë§¨ ì•ì— ì¶”ê°€
            context_docs.insert(0, org_context)
            
            logger.info("RAG search completed", 
                       docs_count=len(context_docs))
            
            # 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = self.org_manager.get_system_prompt()
            
            # 4. LLM ë‹µë³€ ìƒì„± (call_id ì „ë‹¬)
            response_text = await self.llm.generate_response(
                user_text=user_text,
                context_docs=context_docs,
                call_id=self.call_id,  # DB ë¡œê¹…ìš©
                system_prompt=system_prompt
            )
            
            logger.info("LLM response generated", 
                       response_length=len(response_text),
                       response_preview=response_text[:100] if len(response_text) > 100 else response_text)
            
            # ëŒ€í™” ë©”ì‹œì§€ ì¶”ê°€
            if self.conversation:
                self.conversation.add_message("assistant", response_text)
            
            # 5. TTS ì¬ìƒ
            await self.speak(response_text)
            
        except Exception as e:
            logger.error("Response generation error", error=str(e), exc_info=True)
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            await self.speak("ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    async def speak(self, text: str):
        """
        TTS ìŒì„± ì¬ìƒ (Barge-in ì œì–´ í†µí•©)
        
        Args:
            text: ì¬ìƒí•  í…ìŠ¤íŠ¸
        """
        self.state = ConversationState.SPEAKING
        self.is_speaking = True
        
        try:
            # 1. Barge-in Controllerì— TTS ì‹œì‘ ì•Œë¦¼
            await self.barge_in_controller.on_tts_start()
            
            logger.info("ğŸ”Š TTS started", text_length=len(text), 
                       text_preview=text[:50] if len(text) > 50 else text)
            
            # 2. TTS ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
            async for audio_chunk in self.tts.synthesize_stream(text):
                if not self.is_speaking:  # Barge-in ì²´í¬
                    logger.info("Speaking interrupted by barge-in")
                    break
                
                # RTPë¡œ ì „ì†¡
                if self.rtp_send_callback:
                    await self.rtp_send_callback(audio_chunk)
                
                # ë…¹ìŒ
                self.recorder.add_callee_audio(audio_chunk)
            
            logger.info("âœ… TTS completed", text_length=len(text))
            
        except Exception as e:
            logger.error("TTS playback error", error=str(e), exc_info=True)
        finally:
            self.is_speaking = False
            
            # 3. Barge-in Controllerì— TTS ì¢…ë£Œ ì•Œë¦¼
            await self.barge_in_controller.on_tts_end()
            
            if self.state == ConversationState.SPEAKING:
                self.state = ConversationState.LISTENING
    
    async def stop_speaking(self):
        """TTS ì¬ìƒ ì¤‘ë‹¨ (Barge-in)"""
        self.is_speaking = False
        self.tts.stop()
        logger.info("TTS stopped")
    
    # ê°€ì´ë“œ ë©˜íŠ¸ ìºì‹œ (ownerë³„)
    _capability_guide_cache: dict = {}

    async def play_greeting(self):
        """
        2-Phase AI ì¸ì‚¬ë§ ì¬ìƒ
        
        Phase 1: config.yamlì˜ greeting_messageë¥¼ ì¦‰ì‹œ TTS (ê³ ì •, ì§€ì—° 0)
        Phase 2: VectorDBì—ì„œ í™œì„± capability ëª©ë¡ â†’ LLM ìì—°ì–´ ìš”ì•½ â†’ TTS
        """
        try:
            logger.info("ğŸ”„ [AI Takeover] 2-Phase Greeting start", call_id=self.call_id)
            
            # â•â•â• Phase 1: ê³ ì • ì¸ì‚¬ë§ (config.yaml) â•â•â•
            fixed_greeting = self.config.get(
                'greeting_message',
                'ì•ˆë…•í•˜ì„¸ìš”. AI ë¹„ì„œì…ë‹ˆë‹¤.'
            )
            logger.info("âœ… [Phase 1] Fixed greeting", greeting=fixed_greeting)
            
            if self.conversation:
                self.conversation.add_message("assistant", fixed_greeting)
            
            # Barge-in OFF (ì¸ì‚¬ë§ ì¤‘ ëŠì§€ ëª»í•˜ê²Œ)
            await self.barge_in_controller.on_tts_start()
            
            # Phase 2ë¥¼ Phase 1 ë°œí™” ì¤‘ ë³‘ë ¬ ìƒì„±
            guide_task = asyncio.create_task(self._generate_capability_guide())
            
            # Phase 1 TTS ë°œí™”
            await self.speak(fixed_greeting)
            
            # â•â•â• Phase 2: ê°€ì´ë“œ ë©˜íŠ¸ (VectorDB ê¸°ë°˜) â•â•â•
            try:
                guide_text = await guide_task
            except Exception as guide_err:
                logger.warning("guide_generation_failed", error=str(guide_err))
                guide_text = None
            
            if guide_text:
                logger.info("âœ… [Phase 2] Capability guide", guide=guide_text)
                if self.conversation:
                    self.conversation.add_message("assistant", guide_text)
                
                # Barge-in ON (ê°€ì´ë“œ ì¤‘ì—ëŠ” ëŠì„ ìˆ˜ ìˆê²Œ)
                await self.barge_in_controller.on_tts_end()
                await self.speak(guide_text)
            else:
                await self.barge_in_controller.on_tts_end()
            
            logger.info("âœ… [AI Takeover] 2-Phase Greeting completed", call_id=self.call_id)
            
        except Exception as e:
            logger.error("Greeting error", error=str(e), exc_info=True)
            fallback = "ì•ˆë…•í•˜ì„¸ìš”. AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            if self.conversation:
                self.conversation.add_message("assistant", fallback)
            await self.speak(fallback)

    async def _generate_capability_guide(self) -> Optional[str]:
        """VectorDBì—ì„œ í™œì„± ì„œë¹„ìŠ¤ ëª©ë¡ â†’ LLM ìì—°ì–´ ìš”ì•½ (ìºì‹œ ì§€ì›)"""
        try:
            cache_key = self.callee or "__default__"
            
            # ìºì‹œ í™•ì¸
            if cache_key in AIOrchestrator._capability_guide_cache:
                cached = AIOrchestrator._capability_guide_cache[cache_key]
                import time
                if time.time() - cached.get("ts", 0) < 3600:
                    logger.debug("capability_guide_cache_hit", owner=cache_key)
                    return cached["text"]
            
            # VectorDBì—ì„œ capability ì¡°íšŒ
            from src.services.knowledge_service import get_knowledge_service
            ks = get_knowledge_service()
            capabilities = await ks.get_all_capabilities(
                owner=self.callee,
                active_only=True,
            )
            
            if not capabilities:
                return None
            
            # display_name ì¶”ì¶œ (priority ìˆœ, ìµœëŒ€ 5ê°œ)
            max_items = self.config.get('capability_guide', {}).get('max_items', 5) if isinstance(self.config.get('capability_guide'), dict) else 5
            display_names = [cap["display_name"] for cap in capabilities[:max_items]]
            
            if not display_names:
                return None
            
            # LLMìœ¼ë¡œ ìì—°ì–´ ìš”ì•½
            items_text = ", ".join(display_names)
            prompt = (
                f"ë‹¤ìŒ ì„œë¹„ìŠ¤ í•­ëª©ë“¤ì„ ìì—°ì–´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.\n"
                f"í•­ëª©: {items_text}\n"
                f"í˜•ì‹ ì˜ˆì‹œ: 'ì €ëŠ” A, B, Cë¥¼ ì•ˆë‚´í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì–´ë–¤ ê²ƒì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?'"
            )
            
            guide_text = await self.llm.generate_response(
                user_text=prompt,
                context_docs=[],
                call_id=self.call_id,
                system_prompt="ì „í™” ìƒë‹´ ì•ˆë‚´ ë©˜íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”."
            )
            
            # ìºì‹œ ì €ì¥
            import time
            AIOrchestrator._capability_guide_cache[cache_key] = {
                "text": guide_text,
                "ts": time.time(),
            }
            
            return guide_text
            
        except Exception as e:
            logger.error("capability_guide_generation_error", error=str(e), exc_info=True)
            return None
    
    # ==================== Transfer Methods ====================
    
    # TransferManager ì°¸ì¡° (SIPEndpointì—ì„œ ì„¤ì •)
    transfer_manager = None
    
    # â”€â”€ Outbound ëª¨ë“œ ì§€ì› â”€â”€
    _outbound_context: dict = None
    _outbound_task_tracker = None
    _outbound_transcript: list = None
    _outbound_complete_cb = None
    _outbound_turns: int = 0
    _outbound_max_turns: int = 20
    _outbound_call_start_time: float = 0
    
    def set_outbound_complete_callback(self, callback):
        """ì•„ì›ƒë°”ìš´ë“œ ì™„ë£Œ ì½œë°± ì„¤ì •"""
        self._outbound_complete_cb = callback
    
    async def handle_outbound_call(
        self,
        call_id: str,
        outbound_context: dict,
    ):
        """ì•„ì›ƒë°”ìš´ë“œ ì½œ AI ëŒ€í™” ì‹œì‘
        
        ê¸°ì¡´ handle_callê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ì•„ì›ƒë°”ìš´ë“œ ì „ìš© ì»¨í…ìŠ¤íŠ¸ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
        
        Args:
            call_id: SIP Call-ID
            outbound_context: {outbound_id, purpose, questions, caller_display_name, callee_number}
        """
        import time as _time
        try:
            self.call_id = call_id
            self.caller = outbound_context.get('callee_number', '')  # ì°©ì‹ ì(ê³ ê°)
            self.callee = 'AI'  # AIê°€ ë°œì‹ ì
            self.total_calls += 1
            self._outbound_context = outbound_context
            self._outbound_turns = 0
            self._outbound_max_turns = self.config.get('outbound', {}).get('ai', {}).get('max_turns', 20) if isinstance(self.config.get('outbound'), dict) else 20
            self._outbound_call_start_time = _time.time()
            self._outbound_transcript = []
            
            # TaskTracker ì´ˆê¸°í™”
            from src.ai_voicebot.orchestrator.task_tracker import TaskTracker
            self._outbound_task_tracker = TaskTracker(outbound_context.get('questions', []))
            
            # ëŒ€í™” ì„¸ì…˜ ìƒì„±
            from datetime import datetime
            self.conversation = AIConversation(
                session_id=f"ob_{call_id}",
                call_id=call_id,
                caller='AI',
                callee=self.caller,
                started_at=datetime.now()
            )
            
            # ë…¹ìŒ ì‹œì‘
            self.recorder.start_recording(call_id)
            
            # ì˜¤ë””ì˜¤ ë²„í¼ ì‹œì‘
            await self.audio_buffer.start()
            
            # STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
            await self.stt.start_stream(self._on_outbound_stt_result)
            
            # ì²« ì¸ì‚¬ë§ + ëª©ì  ì „ë‹¬
            self.state = ConversationState.GREETING
            greeting = self._build_outbound_greeting(outbound_context)
            
            if self.conversation:
                self.conversation.add_message("assistant", greeting)
            self._outbound_transcript.append(TranscriptEntry(
                timestamp=round(_time.time() - self._outbound_call_start_time, 1),
                speaker="ai",
                text=greeting,
            ))
            self._outbound_turns += 1
            
            await self.speak(greeting)
            
            # ëŒ€í™” ë£¨í”„ ì‹œì‘
            self.state = ConversationState.LISTENING
            
            logger.info("outbound_ai_call_started",
                       call_id=call_id,
                       outbound_id=outbound_context.get('outbound_id'),
                       purpose=outbound_context.get('purpose', '')[:50],
                       questions_count=len(outbound_context.get('questions', [])))
            
        except Exception as e:
            logger.error("outbound_handle_call_error", error=str(e), exc_info=True)
            self.state = ConversationState.ENDED
    
    def _build_outbound_greeting(self, context: dict) -> str:
        """ì•„ì›ƒë°”ìš´ë“œ ì¸ì‚¬ë§ ìƒì„± (í…œí”Œë¦¿ ê¸°ë°˜)"""
        display_name = context.get('caller_display_name', '')
        purpose = context.get('purpose', '')
        
        # configì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
        template = "ì•ˆë…•í•˜ì„¸ìš”, {display_name} AI ë¹„ì„œì…ë‹ˆë‹¤. {purpose} ê´€ë ¨í•˜ì—¬ ì—°ë½ë“œë ¸ìŠµë‹ˆë‹¤."
        outbound_ai_config = self.config.get('outbound', {}).get('ai', {}) if isinstance(self.config.get('outbound'), dict) else {}
        if outbound_ai_config:
            template = outbound_ai_config.get('greeting_template', template)
        
        greeting = template.format(
            display_name=display_name or "íšŒì‚¬",
            purpose=purpose,
        )
        return greeting.strip()
    
    def _build_outbound_system_prompt(self) -> str:
        """ì•„ì›ƒë°”ìš´ë“œ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        context = self._outbound_context
        questions_text = "\n".join(
            f"  {i+1}. {q}" for i, q in enumerate(context.get('questions', []))
        )
        
        display_name = context.get('caller_display_name', 'íšŒì‚¬')
        
        return f"""ë‹¹ì‹ ì€ {display_name}ì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.
ê³ ê°ì—ê²Œ ì „í™”ë¥¼ ê±¸ì–´ ì•„ë˜ ëª©ì ê³¼ í™•ì¸ ì‚¬í•­ì„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

## í†µí™” ëª©ì 
{context.get('purpose', '')}

## í™•ì¸í•´ì•¼ í•  ì‚¬í•­
{questions_text}

## ëŒ€í™” ê·œì¹™
1. ì´ë¯¸ ìê¸°ì†Œê°œì™€ í†µí™” ëª©ì ì€ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë°”ë¡œ í™•ì¸ ì‚¬í•­ì„ ì§ˆë¬¸í•˜ì„¸ìš”.
2. í™•ì¸ ì‚¬í•­ì„ í•˜ë‚˜ì”© ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”.
3. ë‹µë³€ì´ ë¶ˆëª…í™•í•˜ë©´ ì •ì¤‘í•˜ê²Œ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”.
4. ëª¨ë“  í™•ì¸ ì‚¬í•­ì— ëŒ€í•œ ë‹µë³€ì„ ë°›ìœ¼ë©´ ê°ì‚¬ ì¸ì‚¬ë¥¼ í•˜ê³  í†µí™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
5. ê³ ê°ì´ ë°”ì˜ê±°ë‚˜ ê±°ë¶€í•˜ë©´ ì–‘í•´ë¥¼ êµ¬í•˜ê³  í†µí™”ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”.
6. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ì„¸ìš”. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.
7. 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

## ì‘ë‹µ ì‹œ ë‚´ë¶€ íƒœìŠ¤í¬ ìƒíƒœ ì¶”ì 
ë§¤ ì‘ë‹µ ë§ˆì§€ë§‰ì— ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ í˜„ì¬ ìƒíƒœë¥¼ [TASK_STATE] íƒœê·¸ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
[TASK_STATE]{{"questions": [{{"id": "q1", "status": "answered|pending|unclear|refused", "answer": "ê³ ê° ë‹µë³€ ìš”ì•½"}}], "all_completed": false, "should_end_call": false}}[/TASK_STATE]

status ê°’:
- pending: ì•„ì§ ì§ˆë¬¸í•˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹µë³€ì„ ë°›ì§€ ëª»í•¨
- answered: ëª…í™•í•œ ë‹µë³€ì„ ë°›ìŒ
- unclear: ë¶ˆëª…í™•í•œ ë‹µë³€ (ì¬ì§ˆë¬¸ í•„ìš”)
- refused: ê³ ê°ì´ ë‹µë³€ì„ ê±°ë¶€í•¨

should_end_call: ê³ ê°ì´ í†µí™”ë¥¼ ì›í•˜ì§€ ì•Šê±°ë‚˜ ë°”ì˜ë‹¤ê³  í•˜ë©´ trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
"""

    async def _on_outbound_stt_result(self, text: str, is_final: bool):
        """ì•„ì›ƒë°”ìš´ë“œ ëª¨ë“œ STT ê²°ê³¼ ì½œë°±"""
        import time as _time
        
        if not self.barge_in_controller.should_process_speech(is_final):
            return
        
        self.barge_in_controller.on_speech_detected(text, is_final)
        
        if not is_final:
            self.current_user_speech = text
            return
        
        await asyncio.sleep(2.0)
        
        if self.barge_in_controller.check_silence():
            user_text = self.barge_in_controller.get_and_reset_utterance()
            if not user_text:
                return
            
            logger.info("outbound_stt_final", text=user_text)
            
            # ëŒ€í™” ê¸°ë¡
            if self.conversation:
                self.conversation.add_message("user", user_text)
            self._outbound_transcript.append(TranscriptEntry(
                timestamp=round(_time.time() - self._outbound_call_start_time, 1),
                speaker="customer",
                text=user_text,
            ))
            
            self.total_turns += 1
            self._outbound_turns += 1
            
            # ìµœëŒ€ í„´ ìˆ˜ í™•ì¸
            if self._outbound_turns >= self._outbound_max_turns:
                logger.warning("outbound_max_turns_reached",
                              turns=self._outbound_turns)
                closing = "ì£„ì†¡í•©ë‹ˆë‹¤. í†µí™”ê°€ ê¸¸ì–´ì¡Œë„¤ìš”. ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”."
                await self.speak(closing)
                await self._finalize_outbound()
                return
            
            # ì•„ì›ƒë°”ìš´ë“œ ì „ìš© ì‘ë‹µ ìƒì„±
            await self._generate_outbound_response(user_text)
    
    async def _generate_outbound_response(self, user_text: str):
        """ì•„ì›ƒë°”ìš´ë“œ ëª¨ë“œ ì „ìš© ì‘ë‹µ ìƒì„±"""
        import time as _time
        from src.ai_voicebot.orchestrator.task_tracker import TaskTracker
        
        try:
            self.state = ConversationState.THINKING
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = self._build_outbound_system_prompt()
            
            # LLM ì‘ë‹µ ìƒì„±
            response_text = await self.llm.generate_response(
                user_text=user_text,
                context_docs=[],
                call_id=self.call_id,
                system_prompt=system_prompt,
            )
            
            # íƒœìŠ¤í¬ ìƒíƒœ íŒŒì‹±
            task_state = TaskTracker.parse_task_state(response_text)
            if task_state and self._outbound_task_tracker:
                self._outbound_task_tracker.update(task_state)
                
                progress = self._outbound_task_tracker.get_progress()
                logger.info("outbound_task_progress",
                           progress=progress,
                           call_id=self.call_id)
            
            # íƒœê·¸ ì œê±° í›„ TTS
            clean_response = TaskTracker.strip_task_tags(response_text)
            
            if self.conversation:
                self.conversation.add_message("assistant", clean_response)
            self._outbound_transcript.append(TranscriptEntry(
                timestamp=round(_time.time() - self._outbound_call_start_time, 1),
                speaker="ai",
                text=clean_response,
            ))
            self._outbound_turns += 1
            
            await self.speak(clean_response)
            
            # íƒœìŠ¤í¬ ì™„ë£Œ í™•ì¸
            if self._outbound_task_tracker and self._outbound_task_tracker.is_all_completed():
                logger.info("outbound_all_tasks_completed",
                           call_id=self.call_id)
                await self._finalize_outbound()
            
        except Exception as e:
            logger.error("outbound_response_error", error=str(e), exc_info=True)
            await self.speak("ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    async def _finalize_outbound(self):
        """ì•„ì›ƒë°”ìš´ë“œ ì½œ ì™„ë£Œ ì²˜ë¦¬ (ê²°ê³¼ ìƒì„± + ì½œë°±)"""
        import time as _time
        
        try:
            # í†µí™” ì‹œê°„ ê³„ì‚°
            duration = int(_time.time() - self._outbound_call_start_time) if self._outbound_call_start_time else 0
            
            # ìš”ì•½ ìƒì„±
            summary = ""
            try:
                transcript_text = "\n".join(
                    f"{'AI' if t.speaker == 'ai' else 'ê³ ê°'}: {t.text}"
                    for t in self._outbound_transcript
                )
                summary_prompt = f"ë‹¤ìŒ í†µí™” ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{transcript_text}"
                summary = await self.llm.generate_response(
                    user_text=summary_prompt,
                    context_docs=[],
                    call_id=self.call_id,
                    system_prompt="í†µí™” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.",
                )
            except Exception as e:
                logger.warning("outbound_summary_error", error=str(e))
                summary = "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
            
            # ê²°ê³¼ ìƒì„±
            answers = self._outbound_task_tracker.to_answers() if self._outbound_task_tracker else []
            ai_turns = sum(1 for t in self._outbound_transcript if t.speaker == "ai")
            customer_turns = sum(1 for t in self._outbound_transcript if t.speaker == "customer")
            
            result = OutboundCallResult(
                answers=answers,
                summary=summary,
                task_completed=self._outbound_task_tracker.is_all_completed() if self._outbound_task_tracker else False,
                transcript=self._outbound_transcript or [],
                duration_seconds=duration,
                ai_turns=ai_turns,
                customer_turns=customer_turns,
            )
            
            logger.info("outbound_result_generated",
                       call_id=self.call_id,
                       task_completed=result.task_completed,
                       duration=duration,
                       answers_count=len(answers))
            
            # OutboundCallManagerì— ì™„ë£Œ í†µë³´
            if self._outbound_complete_cb:
                await self._outbound_complete_cb(self.call_id, result)
            
        except Exception as e:
            logger.error("outbound_finalize_error", error=str(e), exc_info=True)
    
    async def get_partial_outbound_result(self) -> 'OutboundCallResult':
        """í˜„ì¬ê¹Œì§€ì˜ ë¶€ë¶„ ê²°ê³¼ ìˆ˜ì§‘ (ìƒëŒ€ë°©ì´ ë¨¼ì € ëŠì—ˆì„ ë•Œ)"""
        import time as _time
        
        duration = int(_time.time() - self._outbound_call_start_time) if self._outbound_call_start_time else 0
        answers = self._outbound_task_tracker.to_answers() if self._outbound_task_tracker else []
        ai_turns = sum(1 for t in (self._outbound_transcript or []) if t.speaker == "ai")
        customer_turns = sum(1 for t in (self._outbound_transcript or []) if t.speaker == "customer")
        
        return OutboundCallResult(
            answers=answers,
            summary="í†µí™” ì¤‘ ìƒëŒ€ë°©ì´ ì¢…ë£Œí•¨",
            task_completed=self._outbound_task_tracker.is_all_completed() if self._outbound_task_tracker else False,
            transcript=self._outbound_transcript or [],
            duration_seconds=duration,
            ai_turns=ai_turns,
            customer_turns=customer_turns,
        )
    
    def set_transfer_manager(self, transfer_manager):
        """TransferManager ì„¤ì •"""
        self.transfer_manager = transfer_manager
        logger.info("TransferManager configured", call_id=self.call_id)
    
    async def _handle_transfer_intent(self, user_text: str, rag_result):
        """í˜¸ ì „í™˜ ì˜ë„ ì²˜ë¦¬
        
        RAGì—ì„œ response_type=="transfer" ê²°ê³¼ë¥¼ ê°ì§€í–ˆì„ ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
        TransferManagerì— ì „í™˜ ìš”ì²­ì„ ìœ„ì„í•©ë‹ˆë‹¤.
        
        Args:
            user_text: ì‚¬ìš©ìì˜ ì›ë˜ ìš”ì²­ í…ìŠ¤íŠ¸
            rag_result: RAG ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 1ê±´, transfer íƒ€ì…)
        """
        metadata = getattr(rag_result, 'metadata', {}) if hasattr(rag_result, 'metadata') else {}
        department_name = metadata.get('display_name', 'ë‹´ë‹¹ë¶€ì„œ')
        transfer_to = metadata.get('transfer_to', '')
        phone_display = metadata.get('phone_display', transfer_to)
        
        if not transfer_to:
            logger.warning("transfer_no_target",
                          call_id=self.call_id,
                          department=department_name)
            await self.speak("ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¶€ì„œì˜ ì—°ê²° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info("transfer_request",
                    call_id=self.call_id,
                    department=department_name,
                    transfer_to=transfer_to,
                    phone_display=phone_display)
        
        # ëŒ€í™” ë©”ì‹œì§€ì— ê¸°ë¡
        if self.conversation:
            self.conversation.add_message("system", f"[Transfer] {department_name} ({phone_display})")
        
        if self.transfer_manager:
            # TransferManagerì— ì „í™˜ ìœ„ì„
            record = await self.transfer_manager.initiate_transfer(
                call_id=self.call_id,
                transfer_to=transfer_to,
                department_name=department_name,
                phone_display=phone_display,
                user_request_text=user_text,
                caller_uri=self.caller or "",
                caller_display=self.caller or "",
            )
            
            if not record:
                await self.speak("ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì „í™” ì—°ê²°ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # TransferManagerê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ë§Œ ì œê³µ
            logger.warning("transfer_manager_not_available", call_id=self.call_id)
            await self.speak(
                f"{department_name}ì˜ ì „í™”ë²ˆí˜¸ëŠ” {phone_display}ì…ë‹ˆë‹¤. "
                f"ì§ì ‘ ì—°ë½í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
            )
    
    async def end_call(self):
        """í†µí™” ì¢…ë£Œ ì²˜ë¦¬"""
        try:
            self.state = ConversationState.ENDED
            
            # STT ì¤‘ì§€
            await self.stt.stop_stream()
            
            # ì˜¤ë””ì˜¤ ë²„í¼ ì¤‘ì§€
            await self.audio_buffer.stop()
            
            # ë…¹ìŒ ì €ì¥
            metadata = await self.recorder.stop_recording()
            
            # ëŒ€í™” ì¢…ë£Œ ì‹œê°„ ì„¤ì •
            if self.conversation:
                from datetime import datetime
                self.conversation.ended_at = datetime.now()
            
            # ì „ì‚¬ í…ìŠ¤íŠ¸ ì €ì¥
            if self.conversation:
                transcript = self._build_transcript()
                await self.recorder.save_transcript(self.call_id, transcript)
                
                # ì§€ì‹ ì¶”ì¶œ (ë¹„ë™ê¸°, ë°±ê·¸ë¼ìš´ë“œ)
                if transcript:
                    asyncio.create_task(
                        self.extractor.extract_from_call(
                            call_id=self.call_id,
                            transcript_path=metadata.get("files", {}).get("transcript", ""),
                            owner_id=self.callee,
                            speaker="callee"
                        )
                    )
            
            logger.info("AI call ended",
                       call_id=self.call_id,
                       total_turns=self.total_turns,
                       duration=self.conversation.get_duration_seconds() if self.conversation else 0)
            
        except Exception as e:
            logger.error("End call error", error=str(e), exc_info=True)
    
    def _build_transcript(self) -> str:
        """ëŒ€í™” ì „ì‚¬ í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.conversation:
            return ""
        
        lines = []
        for msg in self.conversation.messages:
            if msg.role == "user":
                lines.append(f"ë°œì‹ ì: {msg.content}")
            elif msg.role == "assistant":
                lines.append(f"ì°©ì‹ ì(AI): {msg.content}")
        
        return "\n".join(lines)
    
    def get_stats(self) -> dict:
        """í†µê³„ ë°˜í™˜"""
        return {
            "total_calls": self.total_calls,
            "total_turns": self.total_turns,
            "current_state": self.state.value if self.state else "unknown",
            "is_speaking": self.is_speaking,
            "current_call_id": self.call_id,
        }
    
    # ==================== HITL Methods (ì¶”ê°€) ====================
    
    def set_hitl_service(self, hitl_service):
        """HITL Service ì„¤ì •"""
        self.hitl_service = hitl_service
        logger.info("HITL Service configured", call_id=self.call_id)
    
    async def request_human_help(self, user_text: str, rag_results: list, confidence: float):
        """
        ì‚¬ëŒì˜ ë„ì›€ ìš”ì²­ (ìš´ì˜ì ë¶€ì¬ì¤‘ ëª¨ë“œ ì§€ì›)
        
        Args:
            user_text: ì‚¬ìš©ì ì§ˆë¬¸
            rag_results: RAG ê²€ìƒ‰ ê²°ê³¼
            confidence: AI ì‹ ë¢°ë„
            
        Returns:
            True: HITL ìš”ì²­ ì„±ê³µ (ìš´ì˜ì ëŒ€ê¸° ì¤‘)
            False: HITL ìš”ì²­ ê±°ì ˆ (ìš´ì˜ì ë¶€ì¬ì¤‘)
        """
        if not self.hitl_enabled or not self.hitl_service:
            logger.warning("HITL not enabled or service not available")
            return False
        
        logger.info("Requesting human help",
                   call_id=self.call_id,
                   question=user_text,
                   confidence=confidence)
        
        # HITL ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = {
            'caller_id': self.caller,
            'callee_id': self.callee,
            'conversation_history': [
                {'role': msg.role, 'content': msg.content, 'timestamp': msg.timestamp.isoformat()}
                for msg in (self.conversation.messages[-5:] if self.conversation else [])
            ],
            'rag_results': [
                {'text': doc.text, 'score': doc.score}
                for doc in rag_results
            ],
            'ai_confidence': confidence
        }
        
        # HITLServiceì— ìš”ì²­ (ìš´ì˜ì ìƒíƒœ í™•ì¸ í¬í•¨)
        hitl_accepted = await self.hitl_service.request_human_help(
            call_id=self.call_id,
            question=user_text,
            context=context,
            urgency='high' if confidence < 0.3 else 'medium'
        )
        
        if not hitl_accepted:
            # ìš´ì˜ì ë¶€ì¬ì¤‘ - ìë™ fallback ì‘ë‹µ
            logger.info("HITL rejected - operator away, using fallback message",
                       call_id=self.call_id)
            
            # ë¶€ì¬ì¤‘ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (Redisì—ì„œ ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ë˜ëŠ” ê¸°ë³¸ ë©”ì‹œì§€)
            away_message = await self._get_away_message()
            
            # ì¦‰ì‹œ ì‘ë‹µ (ëŒ€ê¸° ìŒì•… ì—†ìŒ)
            if self.tts:
                audio = await self.tts.synthesize(away_message)
                if audio and self.rtp_send_callback:
                    await self.rtp_send_callback(audio)
            
            return False
        
        # ìš´ì˜ì ëŒ€ê¸° ì¤‘ - ê¸°ì¡´ HITL ë¡œì§
        # ëŒ€í™” ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state = ConversationState.WAITING_HUMAN
        self.is_waiting_for_human = True
        
        # ëŒ€ê¸° ë©˜íŠ¸ ì¬ìƒ
        await self._play_hold_message()
        
        return True
    
    async def _get_away_message(self) -> str:
        """
        ìš´ì˜ì ë¶€ì¬ì¤‘ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            ë¶€ì¬ì¤‘ ë©”ì‹œì§€
        """
        # Redisì—ì„œ ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ì¡°íšŒ
        if self.hitl_service and self.hitl_service.redis_client:
            try:
                custom_message = await self.hitl_service.redis_client.get("operator:away_message")
                if custom_message:
                    return custom_message.decode() if isinstance(custom_message, bytes) else custom_message
            except Exception as e:
                logger.error("Failed to get away message from Redis", error=str(e))
        
        # ê¸°ë³¸ ë©”ì‹œì§€
        return self.config.get('hitl', {}).get(
            'away_message',
            "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¶€ë¶„ì€ ì˜ ëª¨ë¥´ëŠ” ë‚´ìš©ì´ë¼ í™•ì¸ í›„ ë³„ë„ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        )
    
    async def _play_hold_message(self):
        """ëŒ€ê¸° ë©˜íŠ¸ ì¬ìƒ"""
        hold_message = self.config.get('hitl', {}).get(
            'hold_message',
            "ì ì‹œë§Œ í™•ì¸ ì¤‘ì´ë‹ˆ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”. ê³§ ë‹µë³€ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        )
        
        logger.info("Playing hold message", call_id=self.call_id)
        
        # TTSë¡œ ëŒ€ê¸° ë©˜íŠ¸ ìƒì„± ë° ì¬ìƒ
        if self.tts:
            audio = await self.tts.synthesize(hold_message)
            if audio and self.rtp_send_callback:
                await self.rtp_send_callback(audio)
        
        # TODO: ëŒ€ê¸° ìŒì•… ì¬ìƒ (ì„ íƒ ì‚¬í•­)
        # await self._play_hold_music()
    
    async def wait_for_human_response(self, timeout: int = 60) -> Optional[str]:
        """
        ìš´ì˜ì ì‘ë‹µ ëŒ€ê¸°
        
        Args:
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            ìš´ì˜ì ì‘ë‹µ í…ìŠ¤íŠ¸ ë˜ëŠ” None (íƒ€ì„ì•„ì›ƒ)
        """
        self.hitl_response_event = asyncio.Event()
        self.hitl_response_text = None
        
        try:
            await asyncio.wait_for(
                self.hitl_response_event.wait(),
                timeout=timeout
            )
            return self.hitl_response_text
        except asyncio.TimeoutError:
            logger.warning("HITL response timeout", call_id=self.call_id)
            self.is_waiting_for_human = False
            self.state = ConversationState.LISTENING
            return None
    
    async def handle_human_response(self, response_text: str, operator_id: str):
        """
        Frontendì—ì„œ ë°›ì€ ìš´ì˜ì ì‘ë‹µ ì²˜ë¦¬
        
        Args:
            response_text: ìš´ì˜ìê°€ ì‘ì„±í•œ ë‹µë³€
            operator_id: ìš´ì˜ì ID
        """
        logger.info("Human response received",
                   call_id=self.call_id,
                   operator_id=operator_id,
                   response_length=len(response_text))
        
        self.hitl_response_text = response_text
        self.is_waiting_for_human = False
        
        # ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
        if self.hitl_response_event:
            self.hitl_response_event.set()
        
        # ëŒ€í™” ìƒíƒœ ë³µì›
        self.state = ConversationState.THINKING
    
    def _is_sensitive_topic(self, text: str) -> bool:
        """ë¯¼ê°í•œ ì£¼ì œì¸ì§€ í™•ì¸"""
        sensitive_keywords = self.config.get('hitl', {}).get('sensitive_keywords', [
            'ê³„ì•½', 'ê²°ì œ', 'í™˜ë¶ˆ', 'í´ë ˆì„', 'ë¶ˆë§Œ', 'ì·¨ì†Œ', 
            'contract', 'payment', 'refund', 'complaint'
        ])
        
        return any(keyword in text.lower() for keyword in sensitive_keywords)
