# AI ì‹¤ì‹œê°„ í†µí™” ì‘ëŒ€ ì‹œìŠ¤í…œ - ì•„í‚¤í…ì²˜ ë¬¸ì„œ

## ğŸ“‹ ë¬¸ì„œ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|-----|------|
| **ë¬¸ì„œ ë²„ì „** | v1.0 |
| **ì‘ì„±ì¼** | 2025-01-05 |
| **ì‘ì„±ì** | Winston (Architect) |
| **í”„ë¡œì íŠ¸ëª…** | AI Voice Assistant Extension for SIP PBX |
| **ìƒíƒœ** | Draft |

### ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë²„ì „ | ì„¤ëª… | ì‘ì„±ì |
|-----|------|------|-------|
| 2025-01-05 | v1.0 | ì´ˆê¸° ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì‘ì„± | Winston |

---

## 1. ê°œìš” (Overview)

### 1.1 í”„ë¡œì íŠ¸ ë°°ê²½

ë³¸ í”„ë¡œì íŠ¸ëŠ” **í˜„ì¬ ìš´ì˜ ì¤‘ì¸ IP-PBX ì‹œìŠ¤í…œ**ì„ í™•ì¥í•˜ì—¬, ì°©ì‹ ìê°€ ë¶€ì¬ ì¤‘ì¼ ë•Œ AIê°€ ìë™ìœ¼ë¡œ ì „í™”ë¥¼ ë°›ì•„ ì‘ëŒ€í•˜ëŠ” **ì§€ëŠ¥í˜• ìŒì„± ë¹„ì„œ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

### 1.2 í•µì‹¬ ëª©í‘œ

#### ğŸ¯ ì¼ë°˜ í†µí™” ì‹œë‚˜ë¦¬ì˜¤
1. **í†µí™” ë…¹ìŒ ë° í…ìŠ¤íŠ¸ ë³€í™˜**
   - ì–‘ë°©í–¥ RTP ìŠ¤íŠ¸ë¦¼ì„ í™”ì ë¶„ë¦¬í•˜ì—¬ STT ë³€í™˜
   - ë¯¹ì‹±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ + í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
   
2. **ì§€ì‹ ë² ì´ìŠ¤ ìë™ êµ¬ì¶•**
   - LLM(Gemini)ì´ í†µí™” ë‚´ìš© ë¶„ì„
   - ìœ ìš©í•œ ì •ë³´ íŒë‹¨ ì‹œ Vector DBì— ìë™ ì €ì¥
   - ì°©ì‹ ìì˜ ë§í•˜ëŠ” ë‚´ìš©ì„ AI ë³´ì´ìŠ¤ë´‡ì˜ ì§€ì‹ìœ¼ë¡œ í™œìš©

#### ğŸ¤– AI ë³´ì´ìŠ¤ë´‡ ì‹œë‚˜ë¦¬ì˜¤
1. **ë¶€ì¬ì¤‘ ìë™ ì‘ë‹µ**
   - ì°©ì‹ ìê°€ 10ì´ˆ ì´ë‚´ ì‘ë‹µ ì—†ì„ ì‹œ PBXê°€ ì§ì ‘ í˜¸ ìˆ˜ì‹ 
   - ê³ ì • ì¸ì‚¬ë§ë¡œ ì‘ëŒ€ ì‹œì‘ (ì„¤ì • ê°€ëŠ¥)

2. **ì‹¤ì‹œê°„ ëŒ€í™” ì²˜ë¦¬**
   - RTP â†” Google gRPC ìŠ¤íŠ¸ë¦¬ë° ì§ì ‘ ì—°ê²° (ìµœì†Œ ì§€ì—°)
   - VAD ê¸°ë°˜ Barge-in ì§€ì› (ì‚¬ìš©ì ë°œí™” ì‹œ TTS ì¦‰ì‹œ ì¤‘ë‹¨)
   - RAG ê¸°ë°˜ ì§€ëŠ¥í˜• ë‹µë³€ ìƒì„±

3. **í†µí™” ê¸°ë¡**
   - AI ë³´ì´ìŠ¤ë´‡ ì‘ëŒ€ ë‚´ìš©ë„ ë…¹ìŒ ë° ë¡œê¹…

### 1.3 ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½

| ë ˆì´ì–´ | ê¸°ìˆ  |
|-------|-----|
| **ê¸°ì¡´ PBX** | Python 3.11+, asyncio, SIP/RTP |
| **AI ìŒì„±** | Google Cloud STT/TTS (gRPC Streaming) |
| **LLM** | Google Gemini (Text Generation) |
| **Vector DB** | Pinecone / ChromaDB |
| **ì˜¤ë””ì˜¤ ì²˜ë¦¬** | PyAudio, pydub, ffmpeg |
| **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | Python asyncio, aiohttp |

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 High-Level ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "External"
        Caller[ë°œì‹ ì]
        Callee[ì°©ì‹ ì]
    end
    
    subgraph "IP-PBX (ê¸°ì¡´ ì‹œìŠ¤í…œ)"
        SIP[SIP Endpoint]
        RTP[RTP Relay]
        CallMgr[Call Manager]
        RegMgr[Register Manager]
    end
    
    subgraph "AI Voice Assistant (ì‹ ê·œ)"
        Orchestrator[AI Orchestrator]
        AudioBuf[Audio Buffer & Jitter]
        VAD[Voice Activity Detector]
        
        subgraph "Recording Module"
            Recorder[Call Recorder]
            Mixer[Audio Mixer]
            Separator[Speaker Separator]
        end
        
        subgraph "AI Pipeline"
            STT[Google STT gRPC]
            LLM[Gemini LLM]
            TTS[Google TTS gRPC]
            RAG[RAG Engine]
        end
        
        subgraph "Knowledge Base"
            VectorDB[(Vector DB)]
            Embedder[Text Embedder]
        end
    end
    
    subgraph "Storage"
        AudioStore[(Audio Files)]
        TextStore[(Text Logs)]
        CDR[(Call Records)]
    end
    
    Caller -->|SIP/RTP| SIP
    Callee -->|SIP/RTP| SIP
    SIP --> CallMgr
    CallMgr --> RTP
    CallMgr --> Orchestrator
    
    RTP -->|RTP Stream| AudioBuf
    AudioBuf --> Recorder
    AudioBuf --> VAD
    AudioBuf --> STT
    
    Recorder --> Mixer
    Recorder --> Separator
    Mixer --> AudioStore
    Separator --> STT
    
    VAD --> Orchestrator
    STT --> Orchestrator
    Orchestrator --> LLM
    Orchestrator --> RAG
    RAG --> VectorDB
    LLM --> TTS
    TTS --> RTP
    
    Separator --> TextStore
    LLM --> VectorDB
    Embedder --> VectorDB
    
    Orchestrator --> CDR
```

### 2.2 ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸

#### 2.2.1 ê¸°ì¡´ PBX ì»´í¬ë„ŒíŠ¸ (í™•ì¥)

**Call Manager (í™•ì¥)**
- **ê¸°ì¡´ ê¸°ëŠ¥**: SIP B2BUA, í†µí™” ë¼ìš°íŒ…
- **ì‹ ê·œ ê¸°ëŠ¥**: 
  - ë¶€ì¬ì¤‘ íƒ€ì„ì•„ì›ƒ ê°ì§€ (10ì´ˆ ì„¤ì • ê°€ëŠ¥)
  - AI ë³´ì´ìŠ¤ë´‡ ëª¨ë“œ í™œì„±í™” í”Œë˜ê·¸
  - RTP ìŠ¤íŠ¸ë¦¼ì„ AI Orchestratorë¡œ ë¼ìš°íŒ…

**RTP Relay (í™•ì¥)**
- **ê¸°ì¡´ ê¸°ëŠ¥**: RTP íŒ¨í‚· ì¤‘ê³„
- **ì‹ ê·œ ê¸°ëŠ¥**:
  - RTP íŒ¨í‚·ì„ AI ëª¨ë“ˆë¡œ ë³µì œ (Tee)
  - ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¼ ë¶„ë¦¬ (caller/callee)
  - AI ì‘ë‹µ RTP ì£¼ì…

#### 2.2.2 AI Orchestrator (ì‹ ê·œ)

**ì±…ì„:**
- ì „ì²´ AI í†µí™” íë¦„ ì œì–´
- ìƒíƒœ ë¨¸ì‹  ê´€ë¦¬ (IDLE â†’ GREETING â†’ LISTENING â†’ THINKING â†’ SPEAKING)
- VAD ì´ë²¤íŠ¸ ê¸°ë°˜ Barge-in ì²˜ë¦¬
- ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ
- RAG ê²€ìƒ‰ ë° LLM í”„ë¡¬í”„íŠ¸ ì¡°ë¦½

**ì£¼ìš” ì¸í„°í˜ì´ìŠ¤:**
```python
class AIOrchestrator:
    async def handle_call(self, call_id: str, caller_info: CallerInfo)
    async def on_audio_packet(self, rtp_packet: RTPPacket)
    async def on_vad_detected(self, speech_detected: bool)
    async def on_stt_result(self, text: str, is_final: bool)
    async def generate_response(self, user_text: str) -> str
    async def play_greeting(self)
    async def stop_speaking()  # Barge-in
```

**ì˜ì¡´ì„±:**
- Google STT gRPC Client
- Google TTS gRPC Client
- Gemini LLM Client
- RAG Engine
- VectorDB Client
- Call Recorder

#### 2.2.3 Audio Buffer & Jitter (ì‹ ê·œ)

**ì±…ì„:**
- UDP RTP íŒ¨í‚·ì„ TCP gRPC ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜
- ì§€í„° ë²„í¼ë§ (20-60ms)
- ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (8kHz telephony â†’ 16kHz STT)
- íŒ¨í‚· ìˆœì„œ ì¬ì •ë ¬ ë° ì†ì‹¤ ë³´ì •

**ê¸°ìˆ  ìŠ¤íƒ:**
- `asyncio.Queue` ê¸°ë°˜ ë²„í¼
- `audioop` / `pydub` ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜
- RTP sequence number ê¸°ë°˜ ì¬ì •ë ¬

#### 2.2.4 Voice Activity Detector (VAD) (ì‹ ê·œ)

**ì±…ì„:**
- ì‹¤ì‹œê°„ ìŒì„± í™œë™ ê°ì§€
- Barge-in íŠ¸ë¦¬ê±°
- STT ë¬¸ì¥ ê²½ê³„ ë³´ì¡°

**ê¸°ìˆ  ì˜µì…˜:**
1. **WebRTC VAD** (ê²½ëŸ‰, ë¹ ë¦„) â­ ì¶”ì²œ
2. **Silero VAD** (ì •í™•ë„ ë†’ìŒ, ONNX)
3. **Google STT ë‚´ì¥ VAD** (ë³„ë„ ëª¨ë“ˆ ë¶ˆí•„ìš”)

**êµ¬í˜„:**
```python
from webrtcvad import Vad

vad = Vad(mode=3)  # 0-3, 3ì´ ê°€ì¥ ë¯¼ê°
is_speech = vad.is_speech(audio_frame, sample_rate=16000)
```

#### 2.2.5 Call Recorder (ì‹ ê·œ)

**ì±…ì„:**
- ì–‘ë°©í–¥ RTP ìŠ¤íŠ¸ë¦¼ ë…¹ìŒ
- í™”ì ë¶„ë¦¬ (caller/callee ë³„ë„ ì±„ë„)
- ì˜¤ë””ì˜¤ ë¯¹ì‹± (ë‹¨ì¼ íŒŒì¼)
- STT í…ìŠ¤íŠ¸ ë¡œê·¸ ì €ì¥

**ì¶œë ¥ íŒŒì¼:**
```
/recordings/{call_id}/
  â”œâ”€â”€ mixed.wav           # ë¯¹ì‹±ëœ ì˜¤ë””ì˜¤
  â”œâ”€â”€ caller.wav          # ë°œì‹ ì ì˜¤ë””ì˜¤
  â”œâ”€â”€ callee.wav          # ì°©ì‹ ì ì˜¤ë””ì˜¤ (or AI)
  â”œâ”€â”€ transcript.txt      # ì „ì²´ ëŒ€í™” í…ìŠ¤íŠ¸
  â””â”€â”€ metadata.json       # í†µí™” ë©”íƒ€ë°ì´í„°
```

**ê¸°ìˆ :**
- `ffmpeg` / `pydub` ì˜¤ë””ì˜¤ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë…¹ìŒ (ë©”ëª¨ë¦¬ íš¨ìœ¨)

#### 2.2.6 Google STT gRPC Client (ì‹ ê·œ)

**ì±…ì„:**
- RTP ì˜¤ë””ì˜¤ â†’ í…ìŠ¤íŠ¸ ì‹¤ì‹œê°„ ë³€í™˜
- Streaming Recognition
- Interim/Final ê²°ê³¼ êµ¬ë¶„

**ì„¤ì •:**
```python
recognition_config = {
    "encoding": "LINEAR16",
    "sample_rate_hertz": 16000,
    "language_code": "ko-KR",
    "model": "telephony",  # ì „í™” ìŒì„± ìµœì í™”
    "use_enhanced": True,
    "enable_automatic_punctuation": True,
    "enable_word_time_offsets": True
}
```

**API:**
- `speech.StreamingRecognize` (gRPC Bidirectional Streaming)

#### 2.2.7 Google TTS gRPC Client (ì‹ ê·œ)

**ì±…ì„:**
- í…ìŠ¤íŠ¸ â†’ ìŒì„± ì‹¤ì‹œê°„ ìƒì„±
- Neural2 ìŒì„± ëª¨ë¸ ì‚¬ìš©
- RTP í˜•ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥

**ì„¤ì •:**
```python
voice_config = {
    "language_code": "ko-KR",
    "name": "ko-KR-Neural2-A",  # ì—¬ì„± ëª©ì†Œë¦¬
    "ssml_gender": "FEMALE"
}

audio_config = {
    "audio_encoding": "LINEAR16",
    "sample_rate_hertz": 16000,
    "speaking_rate": 1.0,
    "pitch": 0.0
}
```

**API:**
- `texttospeech.StreamingSynthesize` (gRPC)

#### 2.2.8 Gemini LLM Client (ì‹ ê·œ)

**ì±…ì„:**
- ì‚¬ìš©ì ì˜ë„ íŒŒì•…
- í†µí™” ë‚´ìš© ìœ ìš©ì„± íŒë‹¨
- RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±
- ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€

**í”„ë¡¬í”„íŠ¸ êµ¬ì¡°:**
```
System: ë‹¹ì‹ ì€ {ì°©ì‹ ì ì´ë¦„}ì˜ AI ë¹„ì„œì…ë‹ˆë‹¤. 
ë°œì‹ ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

Context (from RAG):
{ê´€ë ¨ ë¬¸ì„œ 3ê°œ}

Conversation History:
User: ì•ˆë…•í•˜ì„¸ìš”
AI: ì•ˆë…•í•˜ì„¸ìš”, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
User: {í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸}

Instructions:
1. Contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
2. ëª¨ë¥´ë©´ "í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§íˆ ë‹µë³€
3. ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ (1-2 ë¬¸ì¥)
```

**API:**
- `generativeai.GenerativeModel("gemini-pro")`

#### 2.2.9 RAG Engine (ì‹ ê·œ)

**ì±…ì„:**
- ì‚¬ìš©ì ì§ˆë¬¸ ì„ë² ë”©
- VectorDB ì‹œë§¨í‹± ê²€ìƒ‰
- Top-K ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (K=3)
- ì»¨í…ìŠ¤íŠ¸ ì¬ìˆœìœ„í™” (Reranking)

**ì›Œí¬í”Œë¡œìš°:**
```python
async def search_knowledge(query: str) -> List[Document]:
    # 1. ì§ˆë¬¸ ì„ë² ë”©
    query_embedding = await embedder.embed(query)
    
    # 2. Vector ê²€ìƒ‰
    results = await vector_db.search(
        vector=query_embedding,
        top_k=5,
        filter={"owner": callee_id}  # ì°©ì‹ ì ì „ìš© ì§€ì‹
    )
    
    # 3. Reranking (ì„ íƒ)
    reranked = rerank_by_relevance(query, results)
    
    return reranked[:3]
```

#### 2.2.10 Vector DB (ì‹ ê·œ)

**ì±…ì„:**
- í†µí™” ë‚´ìš© ì„ë² ë”© ì €ì¥
- ì‹œë§¨í‹± ê²€ìƒ‰
- ì‚¬ìš©ìë³„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬

**ì˜µì…˜ ë¹„êµ:**

| í•­ëª© | Pinecone | ChromaDB | Qdrant |
|-----|----------|----------|--------|
| **ë°°í¬** | í´ë¼ìš°ë“œ (SaaS) | ë¡œì»¬/í´ë¼ìš°ë“œ | ë¡œì»¬/í´ë¼ìš°ë“œ |
| **í™•ì¥ì„±** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **ê°€ê²©** | ìœ ë£Œ (ë¬´ë£Œ í‹°ì–´) | ì˜¤í”ˆì†ŒìŠ¤ ë¬´ë£Œ | ì˜¤í”ˆì†ŒìŠ¤ ë¬´ë£Œ |
| **ì„¤ì •** | ì‰¬ì›€ | ë§¤ìš° ì‰¬ì›€ | ë³´í†µ |
| **ì¶”ì²œ** | í”„ë¡œë•ì…˜ | ê°œë°œ/í”„ë¡œí† íƒ€ì… | í”„ë¡œë•ì…˜ |

**â­ ì¶”ì²œ: ChromaDB** (ì´ˆê¸° ê°œë°œ) â†’ **Pinecone** (í”„ë¡œë•ì…˜)

**ìŠ¤í‚¤ë§ˆ:**
```python
{
    "id": "call_123_chunk_5",
    "embedding": [0.1, 0.2, ...],  # 1536-dim (OpenAI) or 768-dim (Sentence Transformers)
    "metadata": {
        "call_id": "call_123",
        "speaker": "callee",
        "timestamp": "2025-01-05T10:30:00Z",
        "owner": "user_1004",
        "text": "ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ íšŒì˜ëŠ” ì˜¤ì „ 10ì‹œì…ë‹ˆë‹¤.",
        "chunk_index": 5
    }
}
```

#### 2.2.11 Text Embedder (ì‹ ê·œ)

**ì±…ì„:**
- í…ìŠ¤íŠ¸ â†’ ë²¡í„° ì„ë² ë”© ë³€í™˜
- í†µí™” ë‚´ìš© ì²­í‚¹ (Chunking)

**ì˜µì…˜:**

1. **OpenAI Embeddings** (`text-embedding-3-small`)
   - ì°¨ì›: 1536
   - í’ˆì§ˆ: â­â­â­â­â­
   - ë¹„ìš©: $0.02 / 1M tokens
   
2. **Sentence Transformers** (`paraphrase-multilingual-mpnet-base-v2`)
   - ì°¨ì›: 768
   - í’ˆì§ˆ: â­â­â­â­
   - ë¹„ìš©: ë¬´ë£Œ (ë¡œì»¬)
   - **â­ ì¶”ì²œ** (í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜)

3. **Google Vertex AI Embeddings**
   - Gemini í†µí•© ìš©ì´

**ì²­í‚¹ ì „ëµ:**
```python
# ì‹œë§¨í‹± ì²­í‚¹ (ë¬¸ì¥ ê¸°ì¤€)
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ". ", " "]
)
chunks = splitter.split_text(transcript)
```

---

## 3. ë°ì´í„° ëª¨ë¸

### 3.1 Call Session (í™•ì¥)

```python
@dataclass
class CallSession:
    call_id: str
    caller: str
    callee: str
    start_time: datetime
    end_time: Optional[datetime]
    state: CallState
    
    # ì‹ ê·œ í•„ë“œ
    is_ai_handled: bool = False
    ai_activated_at: Optional[datetime] = None
    no_answer_timeout: int = 10  # ì´ˆ
    recording_path: Optional[str] = None
    transcript_path: Optional[str] = None
```

### 3.2 AI Conversation

```python
@dataclass
class AIConversation:
    session_id: str
    call_id: str
    messages: List[ConversationMessage]
    context_documents: List[Document]
    started_at: datetime
    ended_at: Optional[datetime]
    
@dataclass
class ConversationMessage:
    role: Literal["user", "assistant", "system"]
    content: str
    timestamp: datetime
    audio_file: Optional[str] = None
```

### 3.3 Recording Metadata

```python
@dataclass
class RecordingMetadata:
    call_id: str
    recording_id: str
    start_time: datetime
    duration_seconds: float
    
    # íŒŒì¼ ê²½ë¡œ
    mixed_audio_path: str
    caller_audio_path: str
    callee_audio_path: str
    transcript_path: str
    
    # í†µê³„
    total_turns: int
    caller_speak_time: float
    callee_speak_time: float
    
    # AI í”Œë˜ê·¸
    is_ai_conversation: bool
    knowledge_extracted: bool
```

### 3.4 Knowledge Document

```python
@dataclass
class KnowledgeDocument:
    id: str
    source_call_id: str
    owner_user_id: str
    text: str
    embedding: List[float]
    
    # ë©”íƒ€ë°ì´í„°
    extracted_at: datetime
    speaker: Literal["caller", "callee"]
    confidence_score: float  # LLM ìœ ìš©ì„± íŒë‹¨ ì ìˆ˜
    
    # ë¶„ë¥˜
    category: Optional[str]  # "ì•½ì†", "ì •ë³´", "ì§€ì‹œ" ë“±
    keywords: List[str]
```

---

## 4. í•µì‹¬ ì›Œí¬í”Œë¡œìš°

### 4.1 ì¼ë°˜ í†µí™” ì‹œë‚˜ë¦¬ì˜¤ (ë…¹ìŒ ë° ì§€ì‹ ì¶”ì¶œ)

```mermaid
sequenceDiagram
    participant Caller
    participant PBX
    participant Callee
    participant Recorder
    participant STT
    participant LLM
    participant VectorDB
    
    Caller->>PBX: INVITE (ì „í™” ê±¸ê¸°)
    PBX->>Callee: INVITE (ì°©ì‹  ì „ë‹¬)
    Callee->>PBX: 200 OK (ì „í™” ë°›ìŒ)
    PBX->>Caller: 200 OK
    
    Note over PBX,Recorder: í†µí™” ì—°ê²°, ë…¹ìŒ ì‹œì‘
    
    PBX->>Recorder: RTP Stream (ì–‘ë°©í–¥)
    Recorder->>Recorder: í™”ì ë¶„ë¦¬ + ë¯¹ì‹±
    
    loop í†µí™” ì¤‘
        Recorder->>STT: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤
        STT->>Recorder: í…ìŠ¤íŠ¸ (interim/final)
    end
    
    Callee->>PBX: BYE (í†µí™” ì¢…ë£Œ)
    PBX->>Caller: BYE
    
    Note over Recorder: ë…¹ìŒ ì™„ë£Œ, íŒŒì¼ ì €ì¥
    
    Recorder->>LLM: í†µí™” ì „ì²´ í…ìŠ¤íŠ¸
    LLM->>LLM: ìœ ìš©ì„± íŒë‹¨
    
    alt ìœ ìš©í•œ ì •ë³´ ìˆìŒ
        LLM->>VectorDB: ì§€ì‹ ì²­í¬ ì €ì¥
    else ìœ ìš©í•œ ì •ë³´ ì—†ìŒ
        LLM->>Recorder: Skip
    end
```

### 4.2 AI ë³´ì´ìŠ¤ë´‡ ì‹œë‚˜ë¦¬ì˜¤ (ë¶€ì¬ì¤‘ ì‘ë‹µ)

```mermaid
sequenceDiagram
    participant Caller
    participant PBX
    participant Callee
    participant AI as AI Orchestrator
    participant STT
    participant LLM
    participant TTS
    participant RAG
    
    Caller->>PBX: INVITE
    PBX->>Callee: INVITE
    
    Note over PBX: 10ì´ˆ ëŒ€ê¸° (no-answer-timeout)
    
    alt Callee ì‘ë‹µ ì—†ìŒ
        PBX->>AI: Activate AI Mode
        AI->>Caller: 200 OK (AIê°€ ì‘ë‹µ)
        
        AI->>TTS: ê³ ì • ì¸ì‚¬ë§ ìƒì„±
        TTS->>Caller: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤..."
        
        loop ëŒ€í™”
            Caller->>PBX: RTP (ìŒì„±)
            PBX->>STT: RTP Stream
            STT->>AI: "ë‹¤ìŒ ì£¼ íšŒì˜ ì‹œê°„ì´ ì–¸ì œì¸ê°€ìš”?"
            
            AI->>RAG: ì§ˆë¬¸ ì„ë² ë”© + ê²€ìƒ‰
            RAG->>VectorDB: Semantic Search
            VectorDB->>RAG: Top-3 ë¬¸ì„œ
            
            AI->>LLM: í”„ë¡¬í”„íŠ¸ (ì§ˆë¬¸ + Context)
            LLM->>AI: "ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 10ì‹œì…ë‹ˆë‹¤."
            
            AI->>TTS: ë‹µë³€ í…ìŠ¤íŠ¸
            TTS->>AI: ìŒì„± ìŠ¤íŠ¸ë¦¼
            AI->>Caller: RTP (AI ìŒì„±)
            
            opt Barge-in (ì‚¬ìš©ì ë°œí™” ê°ì§€)
                Caller->>PBX: RTP (ìŒì„± ì¤‘ë³µ)
                PBX->>AI: VAD Detected
                AI->>TTS: STOP (ì¬ìƒ ì¤‘ë‹¨)
            end
        end
        
        Caller->>PBX: BYE
        AI->>AI: ëŒ€í™” ë¡œê·¸ ì €ì¥
    end
```

### 4.3 ì§€ì‹ ì¶”ì¶œ ì›Œí¬í”Œë¡œìš°

```mermaid
flowchart TD
    A[í†µí™” ì¢…ë£Œ] --> B[ì „ì²´ í…ìŠ¤íŠ¸ ë¡œë“œ]
    B --> C[í™”ìë³„ ë°œí™” ë¶„ë¦¬]
    C --> D[ì°©ì‹ ì ë°œí™”ë§Œ ì¶”ì¶œ]
    
    D --> E{LLM ìœ ìš©ì„± íŒë‹¨}
    E -->|ìœ ìš©í•¨| F[í…ìŠ¤íŠ¸ ì²­í‚¹]
    E -->|ìœ ìš©í•˜ì§€ ì•ŠìŒ| Z[ì¢…ë£Œ]
    
    F --> G[ê° ì²­í¬ ì„ë² ë”©]
    G --> H[VectorDB ì €ì¥]
    H --> I[ë©”íƒ€ë°ì´í„° ê¸°ë¡]
    I --> Z
```

**LLM ìœ ìš©ì„± íŒë‹¨ í”„ë¡¬í”„íŠ¸:**
```
ë‹¤ìŒ í†µí™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í–¥í›„ AI ë¹„ì„œê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” 
ìœ ìš©í•œ ì •ë³´ê°€ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ìœ ìš©í•œ ì •ë³´ ì˜ˆì‹œ:
- ì•½ì† ì¼ì •
- ì—°ë½ì²˜ ì •ë³´
- ì—…ë¬´ ì§€ì‹œì‚¬í•­
- ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€
- ê°œì¸ ì„ í˜¸ë„

í†µí™” ë‚´ìš©:
{transcript}

ì¶œë ¥ í˜•ì‹:
{
  "is_useful": true/false,
  "confidence": 0.0-1.0,
  "reason": "íŒë‹¨ ì´ìœ ",
  "extracted_info": [
    {
      "text": "ì¶”ì¶œí•  í…ìŠ¤íŠ¸",
      "category": "ì•½ì†|ì •ë³´|ì§€ì‹œ|ê¸°íƒ€",
      "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    }
  ]
}
```

---

## 5. ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸

### 5.1 ì „ì²´ ê¸°ìˆ  ìŠ¤íƒ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ë²„ì „ | ìš©ë„ | ì„ ì • ì´ìœ  |
|---------|------|------|------|----------|
| **ì–¸ì–´** | Python | 3.11+ | ì „ì²´ ì‹œìŠ¤í…œ | ê¸°ì¡´ PBXì™€ í†µì¼, AI ë¼ì´ë¸ŒëŸ¬ë¦¬ í’ë¶€ |
| **ë¹„ë™ê¸°** | asyncio | 3.11+ | ì´ë²¤íŠ¸ ë£¨í”„ | ì‹¤ì‹œê°„ ì²˜ë¦¬, ë†’ì€ ë™ì‹œì„± |
| **SIP/RTP** | ê¸°ì¡´ êµ¬í˜„ | - | í†µì‹  í”„ë¡œí† ì½œ | ê¸°ì¡´ PBX í™œìš© |
| **STT** | Google Cloud Speech-to-Text | v2 | ìŒì„±â†’í…ìŠ¤íŠ¸ | í•œêµ­ì–´ ìš°ìˆ˜, ì „í™” ëª¨ë¸, Streaming |
| **TTS** | Google Cloud Text-to-Speech | v2 | í…ìŠ¤íŠ¸â†’ìŒì„± | ìì—°ìŠ¤ëŸ¬ìš´ Neural2, Streaming |
| **LLM** | Google Gemini Pro | 1.5 | ëŒ€í™” ìƒì„± | ë¬´ë£Œ í‹°ì–´, ë¹ ë¥¸ ì‘ë‹µ, í•œêµ­ì–´ |
| **Embedding** | Sentence Transformers | 2.2+ | í…ìŠ¤íŠ¸ ì„ë² ë”© | ë¬´ë£Œ, ë¡œì»¬, í•œêµ­ì–´ ìš°ìˆ˜ |
| **Vector DB** | ChromaDB â†’ Pinecone | 0.4+ / - | ë²¡í„° ê²€ìƒ‰ | ê°œë°œ ìš©ì´ â†’ í”„ë¡œë•ì…˜ í™•ì¥ì„± |
| **ì˜¤ë””ì˜¤** | pydub, ffmpeg | 0.25+ / 6.0+ | ì˜¤ë””ì˜¤ ì²˜ë¦¬ | ë²”ìš©ì„±, ì„±ëŠ¥ |
| **VAD** | webrtcvad | 2.0+ | ìŒì„± ê°ì§€ | ê²½ëŸ‰, ë¹ ë¦„, ê²€ì¦ë¨ |
| **gRPC** | grpcio | 1.60+ | Google API í†µì‹  | ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë°, ì €ì§€ì—° |
| **HTTP** | aiohttp | 3.9+ | ë¹„ë™ê¸° HTTP | ê¸°ì¡´ PBXì™€ í†µì¼ |
| **ì„¤ì •** | Pydantic, PyYAML | 2.5+ / 6.0+ | ì„¤ì • ê´€ë¦¬ | ê¸°ì¡´ PBXì™€ í†µì¼ |
| **ëª¨ë‹ˆí„°ë§** | Prometheus | - | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ | ê¸°ì¡´ PBX í†µí•© |
| **ë¡œê¹…** | structlog | 24.1+ | êµ¬ì¡°í™” ë¡œê·¸ | ê¸°ì¡´ PBXì™€ í†µì¼ |
| **í…ŒìŠ¤íŠ¸** | pytest, pytest-asyncio | 7.4+ | í…ŒìŠ¤íŒ… | ê¸°ì¡´ PBXì™€ í†µì¼ |

### 5.2 Google Cloud ì„œë¹„ìŠ¤

#### STT (Speech-to-Text)

**API:** `google-cloud-speech v2`

**ëª¨ë¸:**
- `telephony` - ì „í™” ìŒì„± ìµœì í™”
- `latest_long` - ê¸´ ì˜¤ë””ì˜¤ (ë°±ì—…)

**ì£¼ìš” ì„¤ì •:**
```python
streaming_config = speech.StreamingRecognitionConfig(
    config=speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="ko-KR",
        model="telephony",
        use_enhanced=True,
        enable_automatic_punctuation=True,
    ),
    interim_results=True,  # ì¤‘ê°„ ê²°ê³¼
    single_utterance=False,  # ì—°ì† ì¸ì‹
)
```

**ë¹„ìš©:**
- Standard ëª¨ë¸: $0.006 / 15ì´ˆ
- Enhanced ëª¨ë¸: $0.009 / 15ì´ˆ
- ì›” 60ë¶„ ë¬´ë£Œ

#### TTS (Text-to-Speech)

**API:** `google-cloud-texttospeech v2`

**ìŒì„±:**
- `ko-KR-Neural2-A` (ì—¬ì„±, ìì—°ìŠ¤ëŸ¬ì›€) â­ ì¶”ì²œ
- `ko-KR-Neural2-B` (ë‚¨ì„±)
- `ko-KR-Neural2-C` (ë‚¨ì„±, ê³µì‹ì )

**ì£¼ìš” ì„¤ì •:**
```python
synthesis_input = texttospeech.SynthesisInput(text=text)
voice = texttospeech.VoiceSelectionParams(
    language_code="ko-KR",
    name="ko-KR-Neural2-A",
    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
)
audio_config = texttospeech.AudioConfig(
    audio_encoding=texttospeech.AudioEncoding.LINEAR16,
    sample_rate_hertz=16000,
    speaking_rate=1.0,  # ì†ë„
    pitch=0.0,  # ìŒë†’ì´
)
```

**ë¹„ìš©:**
- Neural2: $16 / 1M ë¬¸ì
- ì›” 100ë§Œ ë¬¸ì ë¬´ë£Œ

#### Gemini (LLM)

**API:** `google-generativeai`

**ëª¨ë¸:**
- `gemini-pro` - í…ìŠ¤íŠ¸ ì „ìš© â­ ì¶”ì²œ
- `gemini-pro-vision` - ì´ë¯¸ì§€ (ë¯¸ì‚¬ìš©)

**ì£¼ìš” ì„¤ì •:**
```python
model = genai.GenerativeModel('gemini-pro')
generation_config = {
    "temperature": 0.7,  # ì°½ì˜ì„±
    "top_p": 0.8,
    "top_k": 40,
    "max_output_tokens": 200,  # ì§§ì€ ë‹µë³€
}
```

**ë¹„ìš©:**
- ë¬´ë£Œ í‹°ì–´: 60 requests/minute
- ìœ ë£Œ: $0.00025 / 1K characters

### 5.3 Vector DB ë¹„êµ ë° ì„ íƒ

#### ì˜µì…˜ 1: ChromaDB (ê°œë°œ/í”„ë¡œí† íƒ€ì…) â­

**ì¥ì :**
- ì´ˆê¸° ì„¤ì • 5ë¶„ ì´ë‚´
- ë¡œì»¬ ì‹¤í–‰ (SQLite)
- Python ë„¤ì´í‹°ë¸Œ
- ë¬´ë£Œ

**ë‹¨ì :**
- í™•ì¥ì„± ì œí•œ
- ê³ ê°€ìš©ì„± ì—†ìŒ

**ì„¤ì¹˜:**
```bash
pip install chromadb
```

**ì‚¬ìš©:**
```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("knowledge_base")

# ì €ì¥
collection.add(
    embeddings=[[0.1, 0.2, ...]],
    documents=["ë‹¤ìŒ ì£¼ íšŒì˜ëŠ” 10ì‹œì…ë‹ˆë‹¤"],
    metadatas=[{"owner": "user_1004"}],
    ids=["doc1"]
)

# ê²€ìƒ‰
results = collection.query(
    query_embeddings=[[0.15, 0.22, ...]],
    n_results=3
)
```

#### ì˜µì…˜ 2: Pinecone (í”„ë¡œë•ì…˜) â­â­

**ì¥ì :**
- ìë™ í™•ì¥
- ê³ ê°€ìš©ì„± (99.9% SLA)
- ë¹ ë¥¸ ê²€ìƒ‰ (<100ms)
- ê´€ë¦¬í˜• ì„œë¹„ìŠ¤

**ë‹¨ì :**
- ìœ ë£Œ (ë¬´ë£Œ í‹°ì–´: 1 index, 1GB)
- ì™¸ë¶€ ì˜ì¡´ì„±

**ì„¤ì¹˜:**
```bash
pip install pinecone-client
```

**ì‚¬ìš©:**
```python
import pinecone

pinecone.init(api_key="YOUR_API_KEY", environment="us-west1-gcp")
index = pinecone.Index("knowledge-base")

# ì €ì¥
index.upsert(vectors=[
    ("doc1", [0.1, 0.2, ...], {"owner": "user_1004", "text": "..."})
])

# ê²€ìƒ‰
results = index.query(
    vector=[0.15, 0.22, ...],
    top_k=3,
    filter={"owner": "user_1004"}
)
```

**â­ ê¶Œì¥ ì „ëµ:**
1. **Phase 1 (ê°œë°œ):** ChromaDB
2. **Phase 2 (í”„ë¡œë•ì…˜):** Pinecone

---

## 6. ì‹œìŠ¤í…œ ì„¤ì •

### 6.1 ì„¤ì • íŒŒì¼ êµ¬ì¡° (config/ai_config.yaml)

```yaml
ai_voicebot:
  enabled: true
  
  # ë¶€ì¬ì¤‘ ì„¤ì •
  no_answer_timeout: 10  # ì´ˆ
  
  # ê³ ì • ì¸ì‚¬ë§
  greeting_message: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
  
  # Google Cloud
  google_cloud:
    project_id: "your-gcp-project"
    credentials_path: "credentials/gcp-key.json"
    
    stt:
      model: "telephony"
      language_code: "ko-KR"
      enable_enhanced: true
      
    tts:
      voice_name: "ko-KR-Neural2-A"
      speaking_rate: 1.0
      pitch: 0.0
      
    gemini:
      model: "gemini-pro"
      temperature: 0.7
      max_output_tokens: 200
  
  # Vector DB
  vector_db:
    provider: "chromadb"  # chromadb | pinecone
    
    # ChromaDB ì„¤ì •
    chromadb:
      persist_directory: "./data/chromadb"
      
    # Pinecone ì„¤ì • (í”„ë¡œë•ì…˜)
    pinecone:
      api_key: "${PINECONE_API_KEY}"
      environment: "us-west1-gcp"
      index_name: "knowledge-base"
      dimension: 768  # Sentence Transformers
  
  # Embedding
  embedding:
    model: "paraphrase-multilingual-mpnet-base-v2"
    dimension: 768
    batch_size: 32
    
  # RAG
  rag:
    top_k: 3
    similarity_threshold: 0.7
    reranking_enabled: false
    
  # ë…¹ìŒ
  recording:
    enabled: true
    output_dir: "./recordings"
    format: "wav"
    sample_rate: 16000
    
    # ì§€ì‹ ì¶”ì¶œ
    knowledge_extraction:
      enabled: true
      min_confidence: 0.7  # LLM íŒë‹¨ ìµœì†Œ ì‹ ë¢°ë„
      chunk_size: 500
      chunk_overlap: 50
  
  # VAD
  vad:
    enabled: true
    mode: 3  # 0-3, 3ì´ ê°€ì¥ ë¯¼ê°
    frame_duration_ms: 30
    
  # Barge-in
  barge_in:
    enabled: true
    vad_threshold: 0.5
    
  # ì˜¤ë””ì˜¤ ë²„í¼
  audio_buffer:
    jitter_buffer_ms: 60
    max_buffer_size: 100  # íŒ¨í‚·
    
  # ë¡œê¹…
  logging:
    log_conversations: true
    log_audio: true
    log_level: "INFO"
```

### 6.2 í™˜ê²½ ë³€ìˆ˜

```.env
# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=./credentials/gcp-key.json
GCP_PROJECT_ID=your-gcp-project

# Pinecone (í”„ë¡œë•ì…˜)
PINECONE_API_KEY=your-pinecone-key
PINECONE_ENVIRONMENT=us-west1-gcp

# OpenAI (ì„ë² ë”© ëŒ€ì•ˆ)
OPENAI_API_KEY=your-openai-key
```

---

## 7. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
sip-pbx/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai_voicebot/                    # ğŸ†• AI ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py             # AI Orchestrator
â”‚   â”‚   â”œâ”€â”€ audio_buffer.py             # Audio Buffer & Jitter
â”‚   â”‚   â”œâ”€â”€ vad_detector.py             # Voice Activity Detector
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ recording/                  # ë…¹ìŒ ëª¨ë“ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ recorder.py             # Call Recorder
â”‚   â”‚   â”‚   â”œâ”€â”€ mixer.py                # Audio Mixer
â”‚   â”‚   â”‚   â””â”€â”€ separator.py            # Speaker Separator
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai_pipeline/                # AI íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”‚   â”œâ”€â”€ stt_client.py           # Google STT gRPC
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_client.py           # Google TTS gRPC
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_client.py           # Gemini LLM
â”‚   â”‚   â”‚   â””â”€â”€ rag_engine.py           # RAG Engine
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ knowledge/                  # ì§€ì‹ ë² ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_db.py            # Vector DB ì¶”ìƒí™”
â”‚   â”‚   â”‚   â”œâ”€â”€ chromadb_client.py      # ChromaDB êµ¬í˜„
â”‚   â”‚   â”‚   â”œâ”€â”€ pinecone_client.py      # Pinecone êµ¬í˜„
â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.py             # Text Embedder
â”‚   â”‚   â”‚   â””â”€â”€ knowledge_extractor.py  # ì§€ì‹ ì¶”ì¶œ ë¡œì§
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ models/                     # AI ë°ì´í„° ëª¨ë¸
â”‚   â”‚       â”œâ”€â”€ conversation.py
â”‚   â”‚       â”œâ”€â”€ knowledge.py
â”‚   â”‚       â””â”€â”€ recording.py
â”‚   â”‚
â”‚   â”œâ”€â”€ sip_core/                       # ê¸°ì¡´ PBX (í™•ì¥)
â”‚   â”‚   â”œâ”€â”€ call_manager.py             # âœï¸ AI ëª¨ë“œ ì¶”ê°€
â”‚   â”‚   â”œâ”€â”€ sip_endpoint.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ media/                          # ê¸°ì¡´ ë¯¸ë””ì–´ (í™•ì¥)
â”‚   â”‚   â”œâ”€â”€ rtp_relay.py                # âœï¸ AI ëª¨ë“ˆ ì—°ë™
â”‚   â”‚   â”œâ”€â”€ session_manager.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ main.py                         # âœï¸ AI ëª¨ë“ˆ ì´ˆê¸°í™”
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                     # ê¸°ì¡´ ì„¤ì •
â”‚   â””â”€â”€ ai_config.yaml                  # ğŸ†• AI ì„¤ì •
â”‚
â”œâ”€â”€ credentials/                        # ğŸ†• ì¸ì¦ ì •ë³´
â”‚   â”œâ”€â”€ gcp-key.json                    # Google Cloud í‚¤
â”‚   â””â”€â”€ .gitignore                      # ì¸ì¦ íŒŒì¼ ì œì™¸
â”‚
â”œâ”€â”€ recordings/                         # ğŸ†• ë…¹ìŒ íŒŒì¼
â”‚   â””â”€â”€ {call_id}/
â”‚       â”œâ”€â”€ mixed.wav
â”‚       â”œâ”€â”€ caller.wav
â”‚       â”œâ”€â”€ callee.wav
â”‚       â”œâ”€â”€ transcript.txt
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ data/                               # ğŸ†• ë°ì´í„° ì €ì¥
â”‚   â”œâ”€â”€ chromadb/                       # ChromaDB ë°ì´í„°
â”‚   â””â”€â”€ knowledge/                      # ì§€ì‹ ë°±ì—…
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ ai_voicebot/                    # ğŸ†• AI í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ test_stt_client.py
â”‚   â”‚   â”œâ”€â”€ test_rag_engine.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md                 # ê¸°ì¡´ ì•„í‚¤í…ì²˜
â”‚   â””â”€â”€ ai-voicebot-architecture.md     # ğŸ†• ì´ ë¬¸ì„œ
â”‚
â”œâ”€â”€ requirements.txt                    # âœï¸ AI íŒ¨í‚¤ì§€ ì¶”ê°€
â””â”€â”€ README.md                           # âœï¸ AI ê¸°ëŠ¥ ì•ˆë‚´
```

---

## 8. í•µì‹¬ ì½”ë“œ êµ¬ì¡°

### 8.1 AI Orchestrator (í•µì‹¬)

```python
# src/ai_voicebot/orchestrator.py

import asyncio
from enum import Enum
from typing import Optional
from .audio_buffer import AudioBuffer
from .vad_detector import VADDetector
from .ai_pipeline.stt_client import STTClient
from .ai_pipeline.tts_client import TTSClient
from .ai_pipeline.llm_client import LLMClient
from .ai_pipeline.rag_engine import RAGEngine

class AIState(Enum):
    IDLE = "idle"
    GREETING = "greeting"
    LISTENING = "listening"
    THINKING = "thinking"
    SPEAKING = "speaking"
    ENDED = "ended"

class AIOrchestrator:
    def __init__(self, config):
        self.config = config
        self.state = AIState.IDLE
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.audio_buffer = AudioBuffer(config.audio_buffer)
        self.vad = VADDetector(config.vad)
        self.stt = STTClient(config.google_cloud.stt)
        self.tts = TTSClient(config.google_cloud.tts)
        self.llm = LLMClient(config.google_cloud.gemini)
        self.rag = RAGEngine(config.rag, config.vector_db)
        
        # ëŒ€í™” ìƒíƒœ
        self.conversation_history = []
        self.current_user_speech = ""
        self.is_speaking = False
        
    async def handle_call(self, call_id: str, caller_info: dict):
        """AI í†µí™” ì²˜ë¦¬ ë©”ì¸ ë¡œì§"""
        self.state = AIState.GREETING
        
        # 1. ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ
        await self.play_greeting()
        
        # 2. ëŒ€í™” ë£¨í”„ ì‹œì‘
        self.state = AIState.LISTENING
        
        # STT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        asyncio.create_task(self.stt_stream_task())
        
        # TTS ì¬ìƒ íƒœìŠ¤í¬
        self.tts_task = None
        
    async def on_audio_packet(self, rtp_packet):
        """RTP íŒ¨í‚· ìˆ˜ì‹ """
        # ë²„í¼ì— ì¶”ê°€
        await self.audio_buffer.add_packet(rtp_packet)
        
        # VAD ê²€ì‚¬
        audio_frame = await self.audio_buffer.get_frame()
        is_speech = self.vad.detect(audio_frame)
        
        if is_speech and self.state == AIState.SPEAKING:
            # Barge-in: ì‚¬ìš©ì ë°œí™” ê°ì§€, TTS ì¤‘ë‹¨
            await self.stop_speaking()
            self.state = AIState.LISTENING
            
        # STTë¡œ ì „ë‹¬
        await self.stt.send_audio(audio_frame)
        
    async def on_stt_result(self, text: str, is_final: bool):
        """STT ê²°ê³¼ ìˆ˜ì‹ """
        if not is_final:
            # Interim result
            self.current_user_speech = text
            return
            
        # Final result
        user_text = text
        self.conversation_history.append({
            "role": "user",
            "content": user_text
        })
        
        # ë‹µë³€ ìƒì„±
        await self.generate_and_speak_response(user_text)
        
    async def generate_and_speak_response(self, user_text: str):
        """ë‹µë³€ ìƒì„± ë° ì¬ìƒ"""
        self.state = AIState.THINKING
        
        # 1. RAG ê²€ìƒ‰
        context_docs = await self.rag.search(user_text)
        
        # 2. LLM í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
        prompt = self._build_prompt(user_text, context_docs)
        
        # 3. LLM í˜¸ì¶œ
        response_text = await self.llm.generate(prompt)
        
        # 4. ëŒ€í™” ê¸°ë¡
        self.conversation_history.append({
            "role": "assistant",
            "content": response_text
        })
        
        # 5. TTS ì¬ìƒ
        await self.speak(response_text)
        
    async def speak(self, text: str):
        """TTS ìŒì„± ì¬ìƒ"""
        self.state = AIState.SPEAKING
        self.is_speaking = True
        
        # TTS ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
        audio_stream = await self.tts.synthesize_stream(text)
        
        # RTPë¡œ ì „ì†¡
        async for audio_chunk in audio_stream:
            if not self.is_speaking:  # Barge-in ì²´í¬
                break
            await self.send_rtp(audio_chunk)
            
        self.is_speaking = False
        self.state = AIState.LISTENING
        
    async def stop_speaking(self):
        """TTS ì¬ìƒ ì¤‘ë‹¨ (Barge-in)"""
        self.is_speaking = False
        await self.tts.stop()
        
    async def play_greeting(self):
        """ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ"""
        greeting_text = self.config.greeting_message
        await self.speak(greeting_text)
        
    def _build_prompt(self, user_text: str, context_docs: list) -> str:
        """LLM í”„ë¡¬í”„íŠ¸ ì¡°ë¦½"""
        context_str = "\n\n".join([
            f"- {doc.text}" for doc in context_docs
        ])
        
        history_str = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in self.conversation_history[-5:]  # ìµœê·¼ 5í„´
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ AI ë¹„ì„œì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ê´€ë ¨ ì •ë³´:
{context_str}

ëŒ€í™” ì´ë ¥:
{history_str}
User: {user_text}

ë‹µë³€ (1-2 ë¬¸ì¥, ì¹œì ˆí•˜ê³  ê°„ê²°í•˜ê²Œ):"""
        
        return prompt
```

### 8.2 Call Manager í™•ì¥

```python
# src/sip_core/call_manager.py (ê¸°ì¡´ ì½”ë“œ í™•ì¥)

from ..ai_voicebot.orchestrator import AIOrchestrator

class CallManager:
    def __init__(self, config):
        # ê¸°ì¡´ ì´ˆê¸°í™”
        ...
        
        # AI ëª¨ë“ˆ ì´ˆê¸°í™”
        if config.ai_voicebot.enabled:
            self.ai_orchestrator = AIOrchestrator(config.ai_voicebot)
        else:
            self.ai_orchestrator = None
            
        self.no_answer_timeout = config.ai_voicebot.no_answer_timeout
        
    async def handle_invite(self, request):
        """INVITE ì²˜ë¦¬ (í™•ì¥)"""
        caller = request.headers["From"]
        callee = request.headers["To"]
        
        # ê¸°ì¡´ ë¡œì§: calleeì—ê²Œ INVITE ì „ë‹¬
        await self.send_invite_to_callee(callee, request)
        
        # ğŸ†• íƒ€ì´ë¨¸ ì‹œì‘: no-answer-timeout
        timeout_task = asyncio.create_task(
            self._wait_for_answer(request, timeout=self.no_answer_timeout)
        )
        
    async def _wait_for_answer(self, request, timeout: int):
        """ë¶€ì¬ì¤‘ íƒ€ì´ë¨¸"""
        await asyncio.sleep(timeout)
        
        session = self.get_session(request.call_id)
        
        if session.state == CallState.RINGING:
            # 10ì´ˆ ë™ì•ˆ ì‘ë‹µ ì—†ìŒ â†’ AI ëª¨ë“œ í™œì„±í™”
            logger.info(f"No answer timeout, activating AI mode: {request.call_id}")
            await self._activate_ai_mode(session)
            
    async def _activate_ai_mode(self, session):
        """AI ë³´ì´ìŠ¤ë´‡ í™œì„±í™”"""
        if not self.ai_orchestrator:
            # AI ë¹„í™œì„±í™” ìƒíƒœ â†’ 480 Temporarily Unavailable
            await self.send_response(session, 480, "Temporarily Unavailable")
            return
            
        # 1. calleeì—ê²Œ ë³´ë‚¸ INVITE CANCEL
        await self.send_cancel_to_callee(session)
        
        # 2. callerì—ê²Œ 200 OK ì‘ë‹µ (PBXê°€ ì§ì ‘ ì‘ë‹µ)
        await self.send_200_ok_to_caller(session)
        
        # 3. RTP ì„¸ì…˜ ì„¤ì • (PBX â†” Caller)
        await self.setup_rtp_session(session)
        
        # 4. AI Orchestratorì—ê²Œ í˜¸ ì „ë‹¬
        await self.ai_orchestrator.handle_call(
            call_id=session.call_id,
            caller_info={
                "caller": session.caller,
                "callee": session.callee,
            }
        )
        
        # 5. RTPë¥¼ AIë¡œ ë¼ìš°íŒ…
        self.rtp_relay.set_ai_mode(session.call_id, self.ai_orchestrator)
```

### 8.3 RTP Relay í™•ì¥

```python
# src/media/rtp_relay.py (ê¸°ì¡´ ì½”ë“œ í™•ì¥)

class RTPRelay:
    def __init__(self):
        # ê¸°ì¡´ ì´ˆê¸°í™”
        ...
        self.ai_sessions = {}  # call_id -> AIOrchestrator
        
    def set_ai_mode(self, call_id: str, ai_orchestrator):
        """AI ëª¨ë“œ í™œì„±í™”"""
        self.ai_sessions[call_id] = ai_orchestrator
        
    async def handle_rtp_packet(self, packet: RTPPacket):
        """RTP íŒ¨í‚· ì²˜ë¦¬ (í™•ì¥)"""
        # ê¸°ì¡´ ë¡œì§: Bypass ëª¨ë“œ relay
        ...
        
        # ğŸ†• AI ëª¨ë“œ ì²´í¬
        if packet.call_id in self.ai_sessions:
            ai = self.ai_sessions[packet.call_id]
            
            # Caller â†’ PBX â†’ AI
            if packet.direction == "caller_to_pbx":
                await ai.on_audio_packet(packet)
                
            # AI â†’ PBX â†’ CallerëŠ” AI Orchestratorì—ì„œ ì§ì ‘ ì „ì†¡
```

---

## 9. ë°°í¬ ë° ìš´ì˜

### 9.1 ë°°í¬ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Cloud (GCP)"
        STT[Cloud STT API]
        TTS[Cloud TTS API]
        Gemini[Gemini API]
        Pinecone[(Pinecone)]
    end
    
    subgraph "On-Premise / VM"
        PBX[SIP PBX + AI Module]
        ChromaDB[(ChromaDB)]
        Storage[(File Storage)]
    end
    
    Users[SIP Users] -->|SIP/RTP| PBX
    PBX -->|gRPC Streaming| STT
    PBX -->|gRPC Streaming| TTS
    PBX -->|HTTPS| Gemini
    PBX -->|HTTPS| Pinecone
    PBX --> ChromaDB
    PBX --> Storage
```

**ê¶Œì¥ ë°°í¬ í™˜ê²½:**
- **ê°œë°œ**: ë¡œì»¬ VM + ChromaDB + Google Cloud APIs
- **í”„ë¡œë•ì…˜**: Kubernetes + Pinecone + Google Cloud APIs

### 9.2 ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­

| ì»´í¬ë„ŒíŠ¸ | CPU | ë©”ëª¨ë¦¬ | ë””ìŠ¤í¬ | ë„¤íŠ¸ì›Œí¬ |
|---------|-----|-------|-------|---------|
| **PBX (ê¸°ì¡´)** | 2 Core | 2GB | 10GB | 100Mbps |
| **AI Module** | 2 Core | 4GB | 50GB | 100Mbps |
| **ChromaDB** | 1 Core | 2GB | 100GB | - |
| **í•©ê³„** | 4-6 Core | 8GB | 160GB | 100Mbps |

**ì˜ˆìƒ ë¶€í•˜ (100 ë™ì‹œ í†µí™” ê¸°ì¤€):**
- CPU: 50-70%
- ë©”ëª¨ë¦¬: 6-7GB
- ë„¤íŠ¸ì›Œí¬: 50Mbps (outbound to Google Cloud)

### 9.3 ëª¨ë‹ˆí„°ë§

#### ì‹ ê·œ Prometheus ë©”íŠ¸ë¦­

```python
# AI ê´€ë ¨ ë©”íŠ¸ë¦­
ai_active_conversations = Gauge('ai_active_conversations', 'Active AI conversations')
ai_conversation_duration = Histogram('ai_conversation_duration_seconds', 'AI conversation duration')
ai_response_time = Histogram('ai_response_time_seconds', 'AI response generation time')

# Google Cloud API
stt_latency = Histogram('stt_latency_seconds', 'STT API latency')
tts_latency = Histogram('tts_latency_seconds', 'TTS API latency')
llm_latency = Histogram('llm_latency_seconds', 'LLM API latency')

# Vector DB
vector_search_latency = Histogram('vector_search_latency_seconds', 'Vector search latency')
knowledge_documents_total = Gauge('knowledge_documents_total', 'Total knowledge documents')

# ë…¹ìŒ
recordings_total = Counter('recordings_total', 'Total recordings')
knowledge_extracted_total = Counter('knowledge_extracted_total', 'Knowledge extraction count')
```

#### Grafana ëŒ€ì‹œë³´ë“œ

**íŒ¨ë„ ì¶”ê°€:**
1. AI í™œì„± ëŒ€í™” ìˆ˜
2. AI ì‘ë‹µ ì‹œê°„ ë¶„í¬
3. STT/TTS/LLM API ì§€ì—°ì‹œê°„
4. Vector DB ê²€ìƒ‰ ì§€ì—°
5. ì§€ì‹ ë¬¸ì„œ ì¦ê°€ ì¶”ì´
6. ë…¹ìŒ íŒŒì¼ ì €ì¥ ìƒíƒœ

### 9.4 ë¡œê¹…

```python
# êµ¬ì¡°í™” ë¡œê·¸ ì˜ˆì‹œ
logger.info("ai_conversation_started", 
    call_id=call_id,
    caller=caller,
    callee=callee,
    mode="ai_voicebot"
)

logger.info("ai_response_generated",
    call_id=call_id,
    user_text=user_text,
    response_text=response_text,
    context_docs_count=len(context_docs),
    generation_time_ms=gen_time,
    rag_search_time_ms=search_time
)

logger.info("knowledge_extracted",
    call_id=call_id,
    chunks_count=len(chunks),
    confidence=confidence,
    category=category
)
```

---

## 10. ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ

### 10.1 ë°ì´í„° ë³´ì•ˆ

#### í†µí™” ë…¹ìŒ ë³´í˜¸
- **ì•”í˜¸í™”**: ë””ìŠ¤í¬ ì €ì¥ ì‹œ AES-256 ì•”í˜¸í™”
- **ì ‘ê·¼ ì œì–´**: ì‚¬ìš©ìë³„ ê²©ë¦¬ (owner í•„í„°)
- **ë³´ê´€ ê¸°ê°„**: ì„¤ì • ê°€ëŠ¥ (ê¸°ë³¸ 90ì¼), ìë™ ì‚­ì œ

#### Vector DB ë³´ì•ˆ
- **ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²©ë¦¬**: ì‚¬ìš©ìë³„ ë¶„ë¦¬
- **ì¿¼ë¦¬ í•„í„°**: `owner` í•„ë“œ ê°•ì œ ì ìš©
- **ì ‘ê·¼ ë¡œê·¸**: ëª¨ë“  ê²€ìƒ‰ ê¸°ë¡

#### Google Cloud API
- **Service Account**: ìµœì†Œ ê¶Œí•œ ì›ì¹™
- **API Key ê´€ë¦¬**: Secret Manager ì‚¬ìš©
- **ê°ì‚¬ ë¡œê·¸**: Cloud Audit Logs í™œì„±í™”

### 10.2 ê°œì¸ì •ë³´ ë³´í˜¸

#### GDPR/ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜
1. **ëª…ì‹œì  ë™ì˜**: ë…¹ìŒ ë° AI ì²˜ë¦¬ ë™ì˜ í•„ìš”
2. **íˆ¬ëª…ì„±**: AI ë¹„ì„œì„ì„ ëª…í™•íˆ ê³ ì§€
3. **ì—´ëŒ/ì‚­ì œ ê¶Œë¦¬**: API ì œê³µ
4. **ë°ì´í„° ìµœì†Œí™”**: í•„ìš”í•œ ì •ë³´ë§Œ ì €ì¥

#### PII ì²˜ë¦¬
- **STT í•„í„°ë§**: ê°œì¸ì‹ë³„ì •ë³´ ë§ˆìŠ¤í‚¹ (ì„ íƒ)
- **ë¡œê·¸ ì œì™¸**: ì „í™”ë²ˆí˜¸, ì£¼ì†Œ ë“± ë¯¼ê° ì •ë³´
- **VectorDB ì €ì¥ ì „**: LLMìœ¼ë¡œ PII ì œê±° ê²€í† 

### 10.3 Prompt Injection ë°©ì–´

```python
def sanitize_user_input(text: str) -> str:
    """Prompt Injection ë°©ì§€"""
    # 1. ì‹œìŠ¤í…œ ëª…ë ¹ì–´ íŒ¨í„´ ì œê±°
    text = re.sub(r'(ignore|forget|disregard)\s+(previous|all|above)', '', text, flags=re.IGNORECASE)
    
    # 2. ê¸¸ì´ ì œí•œ
    text = text[:500]
    
    # 3. íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
    text = text.replace("{", "").replace("}", "")
    
    return text
```

---

## 11. ì„±ëŠ¥ ìµœì í™”

### 11.1 ì§€ì—°ì‹œê°„ ìµœì†Œí™”

#### ëª©í‘œ ì§€ì—°ì‹œê°„
- **ì „ì²´ ì‘ë‹µ**: <2ì´ˆ (ì‚¬ìš©ì ì§ˆë¬¸ â†’ AI ë‹µë³€ ì‹œì‘)
  - STT: <500ms
  - RAG ê²€ìƒ‰: <200ms
  - LLM ìƒì„±: <1000ms
  - TTS ì‹œì‘: <300ms

#### ìµœì í™” ì „ëµ

1. **Streaming í™œìš©**
   - STT: Interim results ì¦‰ì‹œ ì²˜ë¦¬
   - TTS: ì²« ì²­í¬ ì¦‰ì‹œ ì¬ìƒ (ì „ì²´ ìƒì„± ëŒ€ê¸° X)
   - LLM: Streaming API ì‚¬ìš© (ê°€ëŠ¥ ì‹œ)

2. **ë³‘ë ¬ ì²˜ë¦¬**
```python
# RAG ê²€ìƒ‰ê³¼ ë™ì‹œì— ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
context_docs, history = await asyncio.gather(
    rag.search(user_text),
    load_conversation_history(call_id)
)
```

3. **ìºì‹±**
   - ê³ ì • ì¸ì‚¬ë§ TTS ë¯¸ë¦¬ ìƒì„±
   - ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ë‹µë³€ ìºì‹±
   - Embedding ëª¨ë¸ ë©”ëª¨ë¦¬ ë¡œë“œ

4. **Connection Pooling**
   - Google Cloud gRPC ì—°ê²° ì¬ì‚¬ìš©
   - Vector DB ì—°ê²° í’€

### 11.2 ë¹„ìš© ìµœì í™”

#### Google Cloud ë¹„ìš© ì¶”ì • (ì›” 1000 í†µí™” ê¸°ì¤€)

| ì„œë¹„ìŠ¤ | ì‚¬ìš©ëŸ‰ | ë¹„ìš© |
|-------|-------|-----|
| **STT** | 1000 í†µí™” Ã— 3ë¶„ = 3000ë¶„ | $18 |
| **TTS** | 1000 ì‘ë‹µ Ã— 100ì = 100Kì | $1.6 |
| **Gemini** | 1000 ìš”ì²­ Ã— 500ì = 500Kì | $0.125 |
| **í•©ê³„** | - | **~$20/ì›”** |

#### ì ˆì•½ ì „ëµ
1. **STT**: Enhanced ëª¨ë¸ í•„ìš” ì‹œë§Œ ì‚¬ìš©
2. **TTS**: ê³ ì • ì‘ë‹µ ë¯¸ë¦¬ ìƒì„±
3. **Gemini**: í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ìµœì í™”
4. **ë¬´ë£Œ í‹°ì–´**: ì´ˆê¸° ê°œë°œ ì‹œ í™œìš©

### 11.3 í™•ì¥ì„±

#### ìˆ˜í‰ í™•ì¥ (Scale-out)
- **Stateless ì„¤ê³„**: AI Orchestrator ë¬´ìƒíƒœ
- **Session Affinity**: í†µí™” ë‹¨ìœ„ ê³ ì • (Load Balancer)
- **Shared Storage**: ë…¹ìŒ íŒŒì¼ S3/GCS

#### ìˆ˜ì§ í™•ì¥ (Scale-up)
- CPU: ë™ì‹œ í†µí™” ì¦ê°€ ì‹œ 4 â†’ 8 Core
- ë©”ëª¨ë¦¬: Embedding ëª¨ë¸ ë¡œë“œ ì‹œ 8 â†’ 16GB

---

## 12. í…ŒìŠ¤íŠ¸ ì „ëµ

### 12.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/ai_voicebot/test_orchestrator.py

import pytest
from src.ai_voicebot.orchestrator import AIOrchestrator

@pytest.mark.asyncio
async def test_greeting_playback():
    """ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ í…ŒìŠ¤íŠ¸"""
    orchestrator = AIOrchestrator(mock_config)
    
    await orchestrator.handle_call("call_123", {"caller": "1004"})
    
    assert orchestrator.state == AIState.LISTENING
    assert len(orchestrator.conversation_history) == 1
    assert orchestrator.conversation_history[0]["role"] == "assistant"
    
@pytest.mark.asyncio
async def test_barge_in():
    """Barge-in ë™ì‘ í…ŒìŠ¤íŠ¸"""
    orchestrator = AIOrchestrator(mock_config)
    orchestrator.state = AIState.SPEAKING
    orchestrator.is_speaking = True
    
    # ì‚¬ìš©ì ë°œí™” ê°ì§€
    await orchestrator.on_vad_detected(speech_detected=True)
    
    assert orchestrator.is_speaking == False
    assert orchestrator.state == AIState.LISTENING
```

### 12.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_ai_workflow.py

@pytest.mark.integration
async def test_full_ai_conversation():
    """ì „ì²´ AI ëŒ€í™” íë¦„ í…ŒìŠ¤íŠ¸"""
    # 1. ë¶€ì¬ì¤‘ í˜¸ ì‹œë®¬ë ˆì´ì…˜
    call = await pbx.receive_invite("1004", "1008")
    
    # 2. 10ì´ˆ ëŒ€ê¸° (no-answer-timeout)
    await asyncio.sleep(10)
    
    # 3. AI ëª¨ë“œ í™œì„±í™” í™•ì¸
    assert call.is_ai_handled == True
    
    # 4. ì‚¬ìš©ì ìŒì„± ì…ë ¥
    await call.send_audio(load_audio("test_question.wav"))
    
    # 5. AI ì‘ë‹µ í™•ì¸
    response = await call.wait_for_response(timeout=5)
    assert response is not None
    assert len(response.text) > 0
```

### 12.3 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```python
# tests/performance/test_latency.py

@pytest.mark.benchmark
async def test_response_latency():
    """ì‘ë‹µ ì§€ì—°ì‹œê°„ í…ŒìŠ¤íŠ¸"""
    orchestrator = AIOrchestrator(config)
    
    start = time.time()
    await orchestrator.generate_and_speak_response("ë‹¤ìŒ ì£¼ íšŒì˜ ì‹œê°„ì´ ì–¸ì œì¸ê°€ìš”?")
    latency = time.time() - start
    
    # ëª©í‘œ: 2ì´ˆ ì´ë‚´
    assert latency < 2.0
```

---

## 13. í–¥í›„ ê°œì„  ì‚¬í•­ (Roadmap)

### Phase 1: MVP (í˜„ì¬)
- âœ… ê¸°ë³¸ AI ë³´ì´ìŠ¤ë´‡ êµ¬í˜„
- âœ… ë…¹ìŒ ë° ì§€ì‹ ì¶”ì¶œ
- âœ… Google Cloud AI í†µí•©
- âœ… ChromaDB ë¡œì»¬ ê°œë°œ

### Phase 2: ê¸°ëŠ¥ ê°•í™” (3ê°œì›”)
- ğŸ“‹ **ê°ì • ì¸ì‹**: STT + ê°ì • ë¶„ì„
- ğŸ“‹ **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ì¤‘êµ­ì–´ ì¶”ê°€
- ğŸ“‹ **í†µí™” ìš”ì•½**: í†µí™” ì¢…ë£Œ í›„ ìë™ ìš”ì•½
- ğŸ“‹ **Pinecone ë§ˆì´ê·¸ë ˆì´ì…˜**: í”„ë¡œë•ì…˜ ì „í™˜

### Phase 3: ê³ ë„í™” (6ê°œì›”)
- ğŸ“‹ **Multi-turn ì»¨í…ìŠ¤íŠ¸**: ê¸´ ëŒ€í™” ë©”ëª¨ë¦¬
- ğŸ“‹ **Action API**: ì¼ì • ë“±ë¡, ë©”ì¼ ì „ì†¡ ë“±
- ğŸ“‹ **Voice Cloning**: ì°©ì‹ ì ëª©ì†Œë¦¬ í•™ìŠµ
- ğŸ“‹ **Dashboard**: ê´€ë¦¬ì UI

### Phase 4: ì—”í„°í”„ë¼ì´ì¦ˆ (12ê°œì›”)
- ğŸ“‹ **Fine-tuning LLM**: ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸
- ğŸ“‹ **On-premise LLM**: ë°ì´í„° ì£¼ê¶Œ
- ğŸ“‹ **A/B Testing**: ì‘ë‹µ í’ˆì§ˆ ê°œì„ 
- ğŸ“‹ **Analytics**: í†µí™” ì¸ì‚¬ì´íŠ¸

---

## 14. ì²´í¬ë¦¬ìŠ¤íŠ¸

### 14.1 ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **í™˜ê²½ ì„¤ì •**
  - [ ] Google Cloud í”„ë¡œì íŠ¸ ìƒì„±
  - [ ] Service Account í‚¤ ë°œê¸‰
  - [ ] API í™œì„±í™” (STT, TTS, Gemini)
  - [ ] ChromaDB ì„¤ì¹˜
  - [ ] ì˜ì¡´ì„± ì„¤ì¹˜ (`requirements.txt`)

- [ ] **ê¸°ì¡´ PBX í™•ì¥**
  - [ ] Call Manager: ë¶€ì¬ì¤‘ íƒ€ì´ë¨¸ ì¶”ê°€
  - [ ] Call Manager: AI ëª¨ë“œ í™œì„±í™” ë¡œì§
  - [ ] RTP Relay: AI ëª¨ë“ˆ ì—°ë™

- [ ] **AI ëª¨ë“ˆ êµ¬í˜„**
  - [ ] AI Orchestrator í•µì‹¬ ë¡œì§
  - [ ] Audio Buffer & Jitter
  - [ ] VAD í†µí•©
  - [ ] STT gRPC Client
  - [ ] TTS gRPC Client
  - [ ] Gemini LLM Client
  - [ ] RAG Engine
  - [ ] Vector DB ì¶”ìƒí™”
  - [ ] ChromaDB êµ¬í˜„
  - [ ] Text Embedder
  - [ ] Call Recorder
  - [ ] Knowledge Extractor

- [ ] **í…ŒìŠ¤íŠ¸**
  - [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (80% ì»¤ë²„ë¦¬ì§€)
  - [ ] í†µí•© í…ŒìŠ¤íŠ¸ (í•µì‹¬ ì‹œë‚˜ë¦¬ì˜¤)
  - [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì§€ì—°ì‹œê°„ ëª©í‘œ)
  - [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (100 ë™ì‹œ í†µí™”)

- [ ] **ë¬¸ì„œí™”**
  - [ ] API ë¬¸ì„œ (Swagger/OpenAPI)
  - [ ] ìš´ì˜ ë§¤ë‰´ì–¼
  - [ ] íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### 14.2 ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì¸í”„ë¼**
  - [ ] VM/Kubernetes í´ëŸ¬ìŠ¤í„° ì¤€ë¹„
  - [ ] ë„¤íŠ¸ì›Œí¬ ì„¤ì • (ë°©í™”ë²½, ë¡œë“œ ë°¸ëŸ°ì„œ)
  - [ ] ì €ì¥ì†Œ ì„¤ì • (ë…¹ìŒ íŒŒì¼, ChromaDB)
  - [ ] Secret ê´€ë¦¬ (API í‚¤)

- [ ] **ëª¨ë‹ˆí„°ë§**
  - [ ] Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  - [ ] Grafana ëŒ€ì‹œë³´ë“œ ìƒì„±
  - [ ] ì•ŒëŒ ì„¤ì • (ì—ëŸ¬ìœ¨, ì§€ì—°ì‹œê°„)
  - [ ] ë¡œê·¸ ìˆ˜ì§‘ (ELK/Loki)

- [ ] **ë³´ì•ˆ**
  - [ ] ì•”í˜¸í™” í‚¤ ì„¤ì •
  - [ ] ì ‘ê·¼ ì œì–´ ì •ì±…
  - [ ] ê°ì‚¬ ë¡œê·¸ í™œì„±í™”
  - [ ] ê°œì¸ì •ë³´ ë™ì˜ í”„ë¡œì„¸ìŠ¤

- [ ] **ìš´ì˜**
  - [ ] ë°±ì—… ì •ì±… ìˆ˜ë¦½
  - [ ] ì¥ì•  ëŒ€ì‘ í”„ë¡œì„¸ìŠ¤
  - [ ] ë¹„ìš© ëª¨ë‹ˆí„°ë§
  - [ ] ì„±ëŠ¥ íŠœë‹

---

## 15. FAQ

### Q1: ê¸°ì¡´ PBX ì‚¬ìš©ìì—ê²Œ ì˜í–¥ì´ ìˆë‚˜ìš”?
**A**: ì•„ë‹ˆìš”. AI ê¸°ëŠ¥ì€ **ì°©ì‹ ìê°€ ì‘ë‹µí•˜ì§€ ì•Šì„ ë•Œë§Œ** í™œì„±í™”ë©ë‹ˆë‹¤. ì¼ë°˜ í†µí™”ëŠ” ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

### Q2: ë…¹ìŒ íŒŒì¼ ì €ì¥ ìš©ëŸ‰ì€?
**A**: 10ë¶„ í†µí™” ê¸°ì¤€:
- Mixed WAV: ~10MB
- Caller/Callee ê° WAV: ~10MB
- í…ìŠ¤íŠ¸: ~10KB
- **ì´ ~30MB/í†µí™”**

100 í†µí™”/ì¼ = **3GB/ì¼**, **90GB/ì›”**

### Q3: Google Cloud ë¹„ìš©ì´ ê±±ì •ë©ë‹ˆë‹¤.
**A**: ë¬´ë£Œ í‹°ì–´ë¡œ ì‹œì‘ ê°€ëŠ¥:
- STT: ì›” 60ë¶„ ë¬´ë£Œ
- TTS: ì›” 100ë§Œ ë¬¸ì ë¬´ë£Œ
- Gemini: 60 requests/minute ë¬´ë£Œ

ìœ ë£Œ ì „í™˜ ì‹œ ì›” 1000 í†µí™” ê¸°ì¤€ **~$20**

### Q4: On-premise LLM ì‚¬ìš© ê°€ëŠ¥í•œê°€ìš”?
**A**: ë„¤. Ollama + Llama 3 ë“±ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨, GPU í•„ìš” (V100 ì´ìƒ ê¶Œì¥)

### Q5: í•œêµ­ì–´ ì„±ëŠ¥ì´ ê±±ì •ë©ë‹ˆë‹¤.
**A**: Google STT/TTSëŠ” í•œêµ­ì–´ ìµœìƒìœ„ ìˆ˜ì¤€ì…ë‹ˆë‹¤. Geminië„ í•œêµ­ì–´ ìš°ìˆ˜í•©ë‹ˆë‹¤.

### Q6: Vector DBëŠ” ì–¸ì œ Pineconeìœ¼ë¡œ ì „í™˜í•˜ë‚˜ìš”?
**A**: 
- **ê°œë°œ/í”„ë¡œí† íƒ€ì…**: ChromaDB (ë¬´ë£Œ, ê°„ë‹¨)
- **í”„ë¡œë•ì…˜ (1000+ í†µí™”)**: Pinecone (í™•ì¥ì„±, SLA)

---

## 16. ì°¸ê³  ìë£Œ

### 16.1 Google Cloud ë¬¸ì„œ
- [Speech-to-Text Streaming](https://cloud.google.com/speech-to-text/docs/streaming-recognize)
- [Text-to-Speech gRPC](https://cloud.google.com/text-to-speech/docs/reference/rpc)
- [Gemini API](https://ai.google.dev/docs)

### 16.2 Vector DB
- [ChromaDB Getting Started](https://docs.trychroma.com/getting-started)
- [Pinecone Python Client](https://docs.pinecone.io/docs/python-client)

### 16.3 ì˜¤í”ˆì†ŒìŠ¤
- [Sentence Transformers](https://www.sbert.net/)
- [webrtcvad](https://github.com/wiseman/py-webrtcvad)
- [pydub](https://github.com/jiaaro/pydub)

---

## 17. ë‹¤ìŒ ë‹¨ê³„

### ì¦‰ì‹œ ì‹¤í–‰
1. **Google Cloud ì„¤ì •** (1ì‹œê°„)
   ```bash
   # GCP í”„ë¡œì íŠ¸ ìƒì„±
   gcloud projects create sip-pbx-ai
   
   # API í™œì„±í™”
   gcloud services enable speech.googleapis.com
   gcloud services enable texttospeech.googleapis.com
   gcloud services enable generativelanguage.googleapis.com
   
   # Service Account í‚¤ ìƒì„±
   gcloud iam service-accounts create sip-pbx-ai-sa
   gcloud iam service-accounts keys create credentials/gcp-key.json \
     --iam-account sip-pbx-ai-sa@sip-pbx-ai.iam.gserviceaccount.com
   ```

2. **ì˜ì¡´ì„± ì„¤ì¹˜** (10ë¶„)
   ```bash
   pip install google-cloud-speech google-cloud-texttospeech \
               google-generativeai chromadb sentence-transformers \
               webrtcvad pydub
   ```

3. **ê°„ë‹¨í•œ STT/TTS í…ŒìŠ¤íŠ¸** (30ë¶„)
   ```python
   # tests/quick_test_google_apis.py
   from google.cloud import speech, texttospeech
   
   # STT í…ŒìŠ¤íŠ¸
   client = speech.SpeechClient()
   # ... í…ŒìŠ¤íŠ¸ ì½”ë“œ
   
   # TTS í…ŒìŠ¤íŠ¸
   client = texttospeech.TextToSpeechClient()
   # ... í…ŒìŠ¤íŠ¸ ì½”ë“œ
   ```

### 1ì£¼ì°¨
- AI Orchestrator ê¸°ë³¸ êµ¬ì¡° êµ¬í˜„
- STT/TTS í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- ê³ ì • ì¸ì‚¬ë§ ì¬ìƒ í…ŒìŠ¤íŠ¸

### 2ì£¼ì°¨
- LLM í†µí•© (Gemini)
- RAG Engine êµ¬í˜„
- ChromaDB ì—°ë™

### 3ì£¼ì°¨
- Call Manager í™•ì¥
- RTP Relay ì—°ë™
- í†µí•© í…ŒìŠ¤íŠ¸

### 4ì£¼ì°¨
- ë…¹ìŒ ê¸°ëŠ¥ êµ¬í˜„
- ì§€ì‹ ì¶”ì¶œ ë¡œì§
- ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”

---

**ë¬¸ì„œ ì‘ì„± ì™„ë£Œ**

ì´ ì•„í‚¤í…ì²˜ ë¬¸ì„œëŠ” í˜„ì¬ IP-PBX ì‹œìŠ¤í…œì„ ê¸°ë°˜ìœ¼ë¡œ AI ì‹¤ì‹œê°„ í†µí™” ì‘ëŒ€ ì‹œìŠ¤í…œì„ í™•ì¥ êµ¬í˜„í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ê¸°ìˆ  ì²­ì‚¬ì§„ì…ë‹ˆë‹¤.

**ì§ˆë¬¸ì´ ìˆìœ¼ì‹œê±°ë‚˜ íŠ¹ì • ì„¹ì…˜ì„ ë” ìƒì„¸íˆ ì„¤ëª…í•´ë“œë ¤ì•¼ í•  ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!** ğŸ—ï¸

