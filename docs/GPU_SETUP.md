# ğŸ® GPU ê°€ì† ì„¤ì • ê°€ì´ë“œ

SIP PBXì˜ AI ê¸°ëŠ¥(í…ìŠ¤íŠ¸ ì„ë² ë”©)ì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ **5-10ë°° ì†ë„ í–¥ìƒ**ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“Š GPU vs CPU ì„±ëŠ¥ ë¹„êµ

| ì‘ì—… | CPU | GPU (CUDA) | ì†ë„ í–¥ìƒ |
|------|-----|-----------|---------|
| ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© | 50-100ms | **10-20ms** | **5ë°°** |
| ë°°ì¹˜ ì„ë² ë”© (32ê°œ) | 800-1500ms | **150-300ms** | **5-10ë°°** |
| ëª¨ë¸ ë¡œë”© | 0.5ì´ˆ | 0.8ì´ˆ | ì•½ê°„ ëŠë¦¼ |

**ê²°ë¡ **: GPUëŠ” **ì‹¤ì‹œê°„ ì²˜ë¦¬ì™€ ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ ì—„ì²­ë‚œ ì„±ëŠ¥ í–¥ìƒ** ì œê³µ!

---

## ğŸ” GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

### 1. NVIDIA GPU í™•ì¸

**Windows**:
```powershell
# NVIDIA ì œì–´íŒì—ì„œ í™•ì¸
# ë˜ëŠ” ì¥ì¹˜ ê´€ë¦¬ì â†’ ë””ìŠ¤í”Œë ˆì´ ì–´ëŒ‘í„°

# GPU ì •ë³´ í™•ì¸
nvidia-smi
```

**Linux**:
```bash
lspci | grep -i nvidia
nvidia-smi
```

### 2. CUDA ì§€ì› GPU í™•ì¸

**ì§€ì› GPU ëª©ë¡**: https://developer.nvidia.com/cuda-gpus

**ìµœì†Œ ìš”êµ¬ì‚¬í•­**:
- NVIDIA GPU (GTX 900 ì‹œë¦¬ì¦ˆ ì´ìƒ, RTX ì‹œë¦¬ì¦ˆ, Tesla, Quadro ë“±)
- CUDA Compute Capability 3.5 ì´ìƒ

---

## ğŸš€ GPU ì„¤ì¹˜ ë°©ë²•

### Step 1: NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜

**Windows**:
1. https://www.nvidia.com/drivers ë°©ë¬¸
2. GPU ëª¨ë¸ ì„ íƒ ë° ë“œë¼ì´ë²„ ë‹¤ìš´ë¡œë“œ
3. ì„¤ì¹˜ í›„ ì¬ë¶€íŒ…

**Linux (Ubuntu/Debian)**:
```bash
# ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜
sudo apt update
sudo apt install nvidia-driver-535  # ë˜ëŠ” ìµœì‹  ë²„ì „

# ì¬ë¶€íŒ…
sudo reboot

# í™•ì¸
nvidia-smi
```

---

### Step 2: CUDA Toolkit ì„¤ì¹˜ (ì„ íƒ)

**í•„ìˆ˜ ì•„ë‹˜!** PyTorchì— CUDAê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ë§Œì•½ ìˆ˜ë™ ì„¤ì¹˜ë¥¼ ì›í•œë‹¤ë©´:
- https://developer.nvidia.com/cuda-downloads
- CUDA 11.8 ë˜ëŠ” 12.1 ë²„ì „ ì„¤ì¹˜

---

### Step 3: PyTorch CUDA ë²„ì „ ì„¤ì¹˜

**í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™**:
```powershell
cd C:\work\workspace_sippbx\sip-pbx
```

**ê°€ìƒ í™˜ê²½ í™œì„±í™”**:
```powershell
.\venv\Scripts\Activate.ps1  # Windows
# source venv/bin/activate    # Linux/Mac
```

**ê¸°ì¡´ PyTorch ì œê±° ë° CUDA ë²„ì „ ì„¤ì¹˜**:
```powershell
# 1. ê¸°ì¡´ CPU ë²„ì „ ì œê±°
pip uninstall torch torchvision torchaudio -y

# 2. CUDA ë²„ì „ ì„¤ì¹˜ (CUDA 11.8)
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118

# ë˜ëŠ” CUDA 12.1
# pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121
```

---

### Step 4: GPU ë™ì‘ í™•ì¸

**Pythonì—ì„œ í™•ì¸**:
```python
import torch

print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU count: {torch.cuda.device_count()}")
print(f"GPU name: {torch.cuda.get_device_name(0)}")
```

**ì˜ˆìƒ ì¶œë ¥**:
```
CUDA available: True
CUDA version: 11.8
GPU count: 1
GPU name: NVIDIA GeForce RTX 3060
```

---

## ğŸ¯ ì„œë²„ì—ì„œ GPU ì‚¬ìš© í™•ì¸

### 1. ì„œë²„ ì‹œì‘

```powershell
cd C:\work\workspace_sippbx\sip-pbx
python src\main.py
```

### 2. ë¡œê·¸ í™•ì¸

**GPU ì‚¬ìš© ì¤‘**:
```json
{
  "event": "ğŸ® [GPU] CUDA available! Using GPU acceleration",
  "device": "cuda",
  "gpu_name": "NVIDIA GeForce RTX 3060",
  "gpu_memory_gb": "12.00GB",
  "level": "info"
}

{
  "event": "âœ… [GPU] Model loaded on GPU",
  "model": "paraphrase-multilingual-mpnet-base-v2",
  "device": "cuda",
  "level": "info"
}
```

**CPU ì‚¬ìš© ì¤‘** (GPU ì—†ê±°ë‚˜ CUDA ë¯¸ì„¤ì¹˜):
```json
{
  "event": "ğŸ’» [CPU] CUDA not available, using CPU",
  "device": "cpu",
  "level": "info"
}
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "CUDA out of memory"

**ì›ì¸**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°**:
```python
# config.yamlì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
google_cloud:
  embedding:
    batch_size: 16  # ê¸°ë³¸ 32 â†’ 16ìœ¼ë¡œ ê°ì†Œ
```

---

### ë¬¸ì œ 2: "torch.cuda.is_available() returns False"

**ì›ì¸**: CUDA PyTorchê°€ ì•„ë‹Œ CPU ë²„ì „ ì„¤ì¹˜ë¨

**í•´ê²°**:
```powershell
# ì¬ì„¤ì¹˜
pip uninstall torch -y
pip install torch==2.1.2 --index-url https://download.pytorch.org/whl/cu118
```

---

### ë¬¸ì œ 3: "nvidia-smi: command not found"

**ì›ì¸**: NVIDIA ë“œë¼ì´ë²„ ë¯¸ì„¤ì¹˜

**í•´ê²°**: Step 1ì˜ ë“œë¼ì´ë²„ ì„¤ì¹˜ ê°€ì´ë“œ ì°¸ê³ 

---

### ë¬¸ì œ 4: ë“œë¼ì´ë²„ ë²„ì „ ë¶ˆì¼ì¹˜

**í™•ì¸**:
```powershell
nvidia-smi
# Driver Version: 537.42   CUDA Version: 12.2
```

**CUDA 11.8 í•„ìš” ì‹œ**:
- Driver Version 520 ì´ìƒ í•„ìš”
- ë“œë¼ì´ë²„ê°€ ì˜¤ë˜ë˜ì—ˆë‹¤ë©´ ì—…ë°ì´íŠ¸

---

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### GPU ì‚¬ìš©ë¥  í™•ì¸

**ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**:
```powershell
# 1ì´ˆë§ˆë‹¤ ê°±ì‹ 
nvidia-smi -l 1
```

### APIë¡œ í†µê³„ í™•ì¸

```bash
# AI Voicebot í†µê³„ í™•ì¸
curl http://localhost:8000/api/stats/embedder

# ì˜ˆìƒ ì‘ë‹µ
{
  "device": "cuda",
  "gpu_name": "NVIDIA GeForce RTX 3060",
  "gpu_memory_allocated_mb": 245.5,
  "gpu_memory_total_gb": 12.0,
  "total_embeddings": 1523
}
```

---

## ğŸ’¡ ì¶”ì²œ GPU

### ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©
- **NVIDIA GTX 1660 Super** (6GB VRAM) - ì•½ 30ë§Œì›
- **NVIDIA RTX 3060** (12GB VRAM) - ì•½ 40ë§Œì›

### í”„ë¡œë•ì…˜ìš©
- **NVIDIA RTX 4060 Ti** (16GB VRAM) - ì•½ 70ë§Œì›
- **NVIDIA RTX 4090** (24GB VRAM) - ì•½ 250ë§Œì›
- **NVIDIA A100** (40GB/80GB VRAM) - í´ë¼ìš°ë“œ ì¶”ì²œ

### í´ë¼ìš°ë“œ ì˜µì…˜
- **AWS EC2 G4dn** (NVIDIA T4, 16GB VRAM)
- **Google Cloud Platform** (NVIDIA T4/V100/A100)
- **Azure NC ì‹œë¦¬ì¦ˆ** (NVIDIA V100)

---

## â“ FAQ

### Q1: GPUê°€ ê¼­ í•„ìš”í•œê°€ìš”?
**A**: ì•„ë‹ˆìš”. CPUë§Œìœ¼ë¡œë„ ì‘ë™í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ **ëŒ€ëŸ‰ ì²˜ë¦¬ë‚˜ ì‹¤ì‹œê°„ ì‘ë‹µ**ì´ í•„ìš”í•˜ë©´ GPUë¥¼ ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤.

### Q2: ë…¸íŠ¸ë¶ GPUë„ ê°€ëŠ¥í•œê°€ìš”?
**A**: ë„¤! NVIDIA GPUê°€ ìˆëŠ” ë…¸íŠ¸ë¶(GTX/RTX ì‹œë¦¬ì¦ˆ)ì´ë©´ ëª¨ë‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### Q3: AMD GPUëŠ” ì•ˆë˜ë‚˜ìš”?
**A**: í˜„ì¬ëŠ” NVIDIA CUDAë§Œ ì§€ì›í•©ë‹ˆë‹¤. AMD ROCm ì§€ì›ì€ í–¥í›„ ì¶”ê°€ ì˜ˆì •ì…ë‹ˆë‹¤.

### Q4: ì—¬ëŸ¬ GPUê°€ ìˆìœ¼ë©´?
**A**: ê¸°ë³¸ì ìœ¼ë¡œ GPU 0ë²ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:
```python
# config.yaml
google_cloud:
  embedding:
    device: "cuda:1"  # GPU 1ë²ˆ ì‚¬ìš©
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- PyTorch CUDA ì„¤ì¹˜: https://pytorch.org/get-started/locally/
- NVIDIA CUDA Toolkit: https://developer.nvidia.com/cuda-toolkit
- Sentence Transformers: https://www.sbert.net/

---

**ğŸ‰ GPU ì„¤ì • ì™„ë£Œ!** ì´ì œ AI ê¸°ëŠ¥ì´ **5-10ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤!**
