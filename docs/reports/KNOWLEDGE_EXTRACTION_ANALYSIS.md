# ğŸ“Š ì¼ë°˜ í†µí™” ì§€ì‹ ì¶”ì¶œ ê²€í†  ë° êµ¬í˜„ ë³´ê³ ì„œ

## ğŸ“‹ ê²€í†  ì¼ì
**2026-01-07**

---

## âœ… ì„¤ê³„ì„œ í™•ì¸ ê²°ê³¼

### 1. ì„¤ê³„ì„œì— ëª…ì‹œë¨ (`docs/ai-voicebot-architecture.md` ì„¹ì…˜ 4.4)

**ì§€ì‹ ì¶”ì¶œ ì›Œí¬í”Œë¡œìš°**:
```
í†µí™” ì¢…ë£Œ â†’ ì „ì²´ í…ìŠ¤íŠ¸ ë¡œë“œ â†’ í™”ìë³„ ë°œí™” ë¶„ë¦¬ â†’ ì°©ì‹ ì ë°œí™”ë§Œ ì¶”ì¶œ
                                                            â†“
                                         LLM ìœ ìš©ì„± íŒë‹¨ (ì‹ ë¢°ë„ 0.7 ì´ìƒ)
                                                            â†“
                                    ìœ ìš©í•¨ â†’ í…ìŠ¤íŠ¸ ì²­í‚¹ â†’ ì„ë² ë”© â†’ VectorDB ì €ì¥
```

**LLM ìœ ìš©ì„± íŒë‹¨ ê¸°ì¤€**:
- âœ… ì•½ì† ì¼ì •
- âœ… ì—°ë½ì²˜ ì •ë³´
- âœ… ì—…ë¬´ ì§€ì‹œì‚¬í•­
- âœ… ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€
- âœ… ê°œì¸ ì„ í˜¸ë„

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "is_useful": true/false,
  "confidence": 0.0-1.0,
  "reason": "íŒë‹¨ ì´ìœ ",
  "extracted_info": [
    {
      "text": "ì¶”ì¶œí•  í…ìŠ¤íŠ¸",
      "category": "ì•½ì†|ì •ë³´|ì§€ì‹œ|ê¸°íƒ€",
      "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    }
  ]
}
```

---

## âœ… êµ¬í˜„ ìƒíƒœ ê²€í† 

### 1. KnowledgeExtractor âœ… (ì™„ì „ êµ¬í˜„)
**íŒŒì¼**: `src/ai_voicebot/knowledge/knowledge_extractor.py` (308 lines)

**êµ¬í˜„ëœ ê¸°ëŠ¥**:
- âœ… `extract_from_call()` - ë©”ì¸ ì¶”ì¶œ ë©”ì„œë“œ
- âœ… `_load_transcript()` - ì „ì‚¬ í…ìŠ¤íŠ¸ ë¡œë“œ
- âœ… `_filter_by_speaker()` - í™”ìë³„ í•„í„°ë§ (caller/callee)
- âœ… `_chunk_text()` - í…ìŠ¤íŠ¸ ì²­í‚¹ (ì˜¤ë²„ë© í¬í•¨)
- âœ… LLM ìœ ìš©ì„± íŒë‹¨ í†µí•©
- âœ… ì„ë² ë”© ìƒì„± ë° VectorDB ì €ì¥
- âœ… ë©”íƒ€ë°ì´í„° ê´€ë¦¬
- âœ… í†µê³„ ì¶”ì 

**ì„¤ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°**:
- `min_confidence`: ìµœì†Œ ì‹ ë¢°ë„ (ê¸°ë³¸ê°’: 0.7)
- `chunk_size`: ì²­í¬ í¬ê¸° (ê¸°ë³¸ê°’: 500ì)
- `chunk_overlap`: ì²­í¬ ì˜¤ë²„ë© (ê¸°ë³¸ê°’: 50ì)
- `min_text_length`: ìµœì†Œ í…ìŠ¤íŠ¸ ê¸¸ì´ (ê¸°ë³¸ê°’: 50ì)

**ì›Œí¬í”Œë¡œìš°**:
```python
async def extract_from_call(call_id, transcript_path, owner_id, speaker):
    # 1. ì „ì‚¬ í…ìŠ¤íŠ¸ ë¡œë“œ
    transcript = await self._load_transcript(transcript_path)
    
    # 2. í™”ì í•„í„°ë§ (ì°©ì‹ ì ë°œí™”ë§Œ)
    speaker_text = self._filter_by_speaker(transcript, speaker)
    
    # 3. LLM ìœ ìš©ì„± íŒë‹¨
    judgment = await self.llm.judge_usefulness(
        transcript=speaker_text,
        speaker=speaker
    )
    
    # 4. ì‹ ë¢°ë„ í™•ì¸ (0.7 ì´ìƒ)
    if judgment["confidence"] < self.min_confidence:
        return  # ì§€ì‹ ì¶”ì¶œ ì•ˆ í•¨
    
    # 5. í…ìŠ¤íŠ¸ ì²­í‚¹
    chunks = self._chunk_text(text)
    
    # 6. ì„ë² ë”© + VectorDB ì €ì¥
    for chunk in chunks:
        embedding = await self.embedder.embed(chunk)
        await self.vector_db.upsert(doc_id, embedding, chunk, metadata)
```

---

### 2. LLMClient.judge_usefulness() âœ… (ì™„ì „ êµ¬í˜„)
**íŒŒì¼**: `src/ai_voicebot/ai_pipeline/llm_client.py`

**êµ¬í˜„ í™•ì¸**:
```python
async def judge_usefulness(
    self, 
    transcript: str, 
    speaker: str = "callee"
) -> Dict:
    """
    í†µí™” ë‚´ìš©ì˜ ìœ ìš©ì„± íŒë‹¨ (VectorDB ì €ì¥ ê°€ì¹˜)
    
    Returns:
        {
            "is_useful": bool,
            "confidence": float,
            "reason": str,
            "extracted_info": List[Dict]
        }
    """
```

**í”„ë¡¬í”„íŠ¸**:
```python
prompt = f"""
ë‹¤ìŒ í†µí™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í–¥í›„ AI ë¹„ì„œê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” 
ìœ ìš©í•œ ì •ë³´ê°€ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ìœ ìš©í•œ ì •ë³´ ì˜ˆì‹œ:
- ì•½ì† ì¼ì •
- ì—°ë½ì²˜ ì •ë³´
- ì—…ë¬´ ì§€ì‹œì‚¬í•­
- ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€
- ê°œì¸ ì„ í˜¸ë„

í†µí™” ë‚´ìš©:
{transcript}

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "is_useful": true/false,
  "confidence": 0.0-1.0,
  "reason": "íŒë‹¨ ì´ìœ ",
  "extracted_info": [...]
}}
"""
```

---

### 3. AI í†µí™” ì§€ì‹ ì¶”ì¶œ âœ… (ì‘ë™ ì¤‘)
**íŒŒì¼**: `src/ai_voicebot/orchestrator.py`

**êµ¬í˜„ ìœ„ì¹˜**: `AIOrchestrator.end_call()`

```python
async def end_call(self):
    # ... ë…¹ìŒ ì €ì¥ ...
    
    # ì§€ì‹ ì¶”ì¶œ (ë¹„ë™ê¸°, ë°±ê·¸ë¼ìš´ë“œ)
    if transcript:
        asyncio.create_task(
            self.extractor.extract_from_call(
                call_id=self.call_id,
                transcript_path=metadata.get("files", {}).get("transcript", ""),
                owner_id=self.callee,
                speaker="callee"  # ì°©ì‹ ì ë°œí™”ë§Œ ì¶”ì¶œ
            )
        )
```

**ìƒíƒœ**: âœ… **ì‘ë™ ì¤‘**

---

### 4. ì¼ë°˜ SIP í†µí™” ì§€ì‹ ì¶”ì¶œ âœ… (êµ¬í˜„ ì™„ë£Œ)
**íŒŒì¼**: `src/sip_core/call_manager.py`

**ì´ì „ ìƒíƒœ**: âŒ ë¯¸êµ¬í˜„

**ì‹ ê·œ êµ¬í˜„**: âœ… ì™„ë£Œ

#### 4.1 CallManager ì´ˆê¸°í™” ìˆ˜ì •
```python
def __init__(
    self,
    # ... ê¸°ì¡´ íŒŒë¼ë¯¸í„° ...
    knowledge_extractor = None,  # ì‹ ê·œ íŒŒë¼ë¯¸í„°
):
    # ...
    self.knowledge_extractor = knowledge_extractor
    if knowledge_extractor:
        logger.info("Knowledge extraction enabled for regular calls")
```

#### 4.2 trigger_knowledge_extraction() ë©”ì„œë“œ (ì‹ ê·œ)
**ìœ„ì¹˜**: `src/sip_core/call_manager.py` (line 701-763)

**í˜¸ì¶œ ê²½ë¡œ**:
```
SIPEndpoint._cleanup_call()
    â†“
CallManager.trigger_knowledge_extraction()
    â†“ (5ì´ˆ delay)
KnowledgeExtractor.extract_from_call()
```

**êµ¬í˜„ ë‚´ìš©**:
```python
async def trigger_knowledge_extraction(
    self,
    call_id: str,
    recording_dir_name: str,
    callee_username: str
) -> None:
    """Knowledge Extraction íŠ¸ë¦¬ê±° (SIP Endpointì—ì„œ í˜¸ì¶œ)
    
    Args:
        call_id: í˜¸ ID
        recording_dir_name: ë…¹ìŒ ë””ë ‰í† ë¦¬ëª…
        callee_username: ì°©ì‹ ì ì‚¬ìš©ìëª…
    """
    if not self.knowledge_extractor or not self.recording_enabled:
        return
    
    transcript_path = Path(f"./recordings/{recording_dir_name}/transcript.txt")
    callee_id = f"sip:{callee_username}@unknown"
    
    # STT ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦° í›„ ì§€ì‹ ì¶”ì¶œ ì‹¤í–‰ (5ì´ˆ delay)
    async def delayed_extraction():
        await asyncio.sleep(5)  # STT ì™„ë£Œ ëŒ€ê¸°
        
        if not transcript_path.exists():
            logger.warning("Transcript file not found after delay")
            return
        
        await self.knowledge_extractor.extract_from_call(
            call_id=call_id,
            transcript_path=str(transcript_path),
            owner_id=callee_id,
            speaker="callee"  # ì°©ì‹ ì ë°œí™”ë§Œ ì¶”ì¶œ
        )
    
    asyncio.create_task(delayed_extraction())
```

**íŠ¹ì§•**:
- âœ… **5ì´ˆ ì§€ì—°**: STT í›„ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
- âœ… **ë¹„ë™ê¸° ì‹¤í–‰**: í†µí™” ì¢…ë£Œë¥¼ ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ
- âœ… **ì—ëŸ¬ í•¸ë“¤ë§**: transcript íŒŒì¼ ì—†ì„ ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬

#### 4.3 SIPEndpoint._cleanup_call()ì—ì„œ í˜¸ì¶œ
**ìœ„ì¹˜**: `src/sip_core/sip_endpoint.py` (line 1682-1704)

**í”Œë¡œìš°**:
```python
async def _cleanup_call(self, call_id: str) -> None:
    # ... ë…¹ìŒ ì¢…ë£Œ ...
    
    # âœ… Knowledge Extraction íŠ¸ë¦¬ê±° (CallManagerì— ìœ„ì„)
    if self._call_manager and recording_metadata:
        recording_dir_name = recording_metadata.get('dir_name')
        is_ai_call = call_info.get('is_ai_call', False)
        
        if recording_dir_name and not is_ai_call:
            # ì¼ë°˜ SIP í†µí™”ë§Œ Knowledge Extraction ìˆ˜í–‰
            await self._call_manager.trigger_knowledge_extraction(
                call_id=original_call_id,
                recording_dir_name=recording_dir_name,
                callee_username=call_info.get('callee_username', 'unknown')
            )
```

**ì¡°ê±´**:
- âœ… `recording_dir_name`ì´ ì¡´ì¬í•´ì•¼ í•¨
- âœ… `has_transcript` (transcript ì¡´ì¬)
- âœ… `is_ai_call == False` â€” AI í†µí™”ëŠ” ì œì™¸ (CallManager.ai_enabled_calls ë˜ëŠ” call_info.ai_mode_activated/is_ai_callë¡œ íŒë‹¨)
- âœ… `knowledge_extractor`ê°€ ì´ˆê¸°í™”ë˜ì–´ ìˆì–´ì•¼ í•¨
- âœ… `recording_enabled == True`

### 5. Knowledge extraction scope (human-only + HITL)

**Extraction runs only for**:
1. **Human-to-human calls**: caller â†” callee; when the call ends, `_cleanup_call` runs and triggers extraction only when the call is not AI-handled (`is_ai_call` is false).
2. **HITL results**: When operators enter a response in the frontend and choose to save to the knowledge base, that is the only knowledge path for AI-handled calls.
   - **Flow**: Frontend â†’ WebSocket `submit_hitl_response` or API â†’ `HITLService.submit_response()` â†’ when `save_to_kb=True` â†’ `KnowledgeService.add_from_hitl(question, answer, ...)` â†’ vector DB.

**AI-to-caller calls are excluded** from call-based extraction (no transcript â†’ knowledge extraction from that call).

---

## âš ï¸ ì œí•œ ì‚¬í•­ ë° ì „ì œ ì¡°ê±´

### 1. Transcript ìƒì„± í•„ìš”

**ì¼ë°˜ SIP í†µí™”ì—ì„œ ì§€ì‹ ì¶”ì¶œì´ ì‘ë™í•˜ë ¤ë©´**:
- âœ… **ì „ì œ ì¡°ê±´**: `transcript.txt` íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨
- âŒ **í˜„ì¬ ë¬¸ì œ**: SIPCallRecorderê°€ transcriptë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ

**ì´ìœ **:
- ì¼ë°˜ SIP í†µí™”ëŠ” AI Orchestratorê°€ ì—†ìŒ
- STT(Speech-to-Text)ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
- RTP íŒ¨í‚·ì€ ë…¹ìŒë˜ì§€ë§Œ, í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì§€ ì•ŠìŒ

### 2. í•´ê²° ë°©ì•ˆ

#### ì˜µì…˜ 1: í›„ì²˜ë¦¬ STT (ê¶Œì¥)
```python
# SIPCallRecorderì—ì„œ í†µí™” ì¢…ë£Œ ì‹œ í›„ì²˜ë¦¬ STT ì‹¤í–‰
async def stop_recording(self, call_id):
    # ... WAV íŒŒì¼ ì €ì¥ ...
    
    # í›„ì²˜ë¦¬ STT (ì„ íƒì )
    if self.stt_enabled:
        transcript = await self._transcribe_audio(
            audio_path=mixed_wav_path
        )
        
        # transcript.txt ì €ì¥
        transcript_path = call_dir / "transcript.txt"
        with open(transcript_path, 'w', encoding='utf-8') as f:
            f.write(transcript)
```

**ì¥ì **:
- âœ… ì‹¤ì‹œê°„ STT ë¶€ë‹´ ì—†ìŒ
- âœ… ë…¹ìŒ íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ì „ì‚¬ ê°€ëŠ¥
- âœ… Google Speech-to-Text API ì‚¬ìš© ê°€ëŠ¥

**ë‹¨ì **:
- âŒ ì¶”ê°€ API ë¹„ìš©
- âŒ ì²˜ë¦¬ ì‹œê°„ ì§€ì—° (ëª‡ ì´ˆ ~ ëª‡ ë¶„)

#### ì˜µì…˜ 2: ì‹¤ì‹œê°„ STT (ê³ ê¸‰)
```python
# RTP Relayì—ì„œ ì‹¤ì‹œê°„ STT ì‹¤í–‰
class RTPRelayWorker:
    def on_packet_received(self, socket_type, data, addr):
        # ... ë…¹ìŒ íŒ¨í‚· ì „ë‹¬ ...
        
        # ì‹¤ì‹œê°„ STT (ì„ íƒì )
        if self.stt_enabled and not self.ai_mode:
            asyncio.create_task(
                self.stt_client.process_audio(
                    audio_data=data,
                    call_id=self.call_id
                )
            )
```

**ì¥ì **:
- âœ… ì‹¤ì‹œê°„ ì „ì‚¬
- âœ… ì¦‰ì‹œ ì§€ì‹ ì¶”ì¶œ ê°€ëŠ¥

**ë‹¨ì **:
- âŒ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶€ë‹´
- âŒ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì‚¬ìš©
- âŒ êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ

#### ì˜µì…˜ 3: ìˆ˜ë™ ì—…ë¡œë“œ (ê°„ë‹¨)
```python
# Frontendì—ì„œ ìˆ˜ë™ìœ¼ë¡œ transcript ì—…ë¡œë“œ
POST /api/calls/{call_id}/transcript
{
    "transcript": "ë°œì‹ ì: ì•ˆë…•í•˜ì„¸ìš”\nì°©ì‹ ì: ë„¤ ì•ˆë…•í•˜ì„¸ìš”..."
}

# ì—…ë¡œë“œ í›„ ìˆ˜ë™ìœ¼ë¡œ ì§€ì‹ ì¶”ì¶œ íŠ¸ë¦¬ê±°
POST /api/calls/{call_id}/extract-knowledge
```

**ì¥ì **:
- âœ… ê°€ì¥ ê°„ë‹¨í•œ êµ¬í˜„
- âœ… API ë¹„ìš© ì—†ìŒ
- âœ… ì‚¬ìš©ìê°€ ì§ì ‘ í™•ì¸ ê°€ëŠ¥

**ë‹¨ì **:
- âŒ ìˆ˜ë™ ì‘ì—… í•„ìš”
- âŒ í™•ì¥ì„± ë‚®ìŒ

---

## ğŸ“Š í˜„ì¬ êµ¬í˜„ ì™„ì„±ë„

### ì „ì²´ ì‹œìŠ¤í…œ
| êµ¬ì„± ìš”ì†Œ | ìƒíƒœ | ì™„ì„±ë„ |
|-----------|------|--------|
| **KnowledgeExtractor** | âœ… ì™„ì „ êµ¬í˜„ | 100% |
| **LLMClient.judge_usefulness** | âœ… ì™„ì „ êµ¬í˜„ | 100% |
| **AI í†µí™” ì§€ì‹ ì¶”ì¶œ** | âœ… ì‘ë™ ì¤‘ | 100% |
| **ì¼ë°˜ í†µí™” ì§€ì‹ ì¶”ì¶œ íŠ¸ë¦¬ê±°** | âœ… ì™„ë£Œ | 100% |
| **trigger_knowledge_extraction()** | âœ… ì™„ë£Œ | 100% |
| **SIPEndpoint._cleanup_call() í†µí•©** | âœ… ì™„ë£Œ | 100% |
| **ì¼ë°˜ í†µí™” Transcript ìƒì„±** | âš ï¸ í›„ì²˜ë¦¬ STT í•„ìš” | 0% |

### ì‘ë™ ì‹œë‚˜ë¦¬ì˜¤

#### âœ… ì‹œë‚˜ë¦¬ì˜¤ 1: AI í†µí™” (AI ì‘ëŒ€ ëª¨ë“œ)
```
1. User Aê°€ User Bì—ê²Œ ì „í™”
2. User B ë¶€ì¬ â†’ AI ì‘ëŒ€ ì‹œì‘
   - íƒ€ì´ë¨¸ ê¸°ë°˜: no_answer_timeout (10ì´ˆ) ê²½ê³¼
   - ìˆ˜ë™ ì„¤ì •: ì›¹ì—ì„œ "ë¶€ì¬ì¤‘" ìƒíƒœ ì„¤ì •
3. AI Orchestratorê°€ ì‹¤ì‹œê°„ STT ì‹¤í–‰
   â””â”€> transcript.txt ìƒì„± (ì‹¤ì‹œê°„)
4. í†µí™” ì¢…ë£Œ
5. AIOrchestrator.end_call() í˜¸ì¶œ
6. KnowledgeExtractor.extract_from_call() ì¦‰ì‹œ í˜¸ì¶œ
7. LLM ìœ ìš©ì„± íŒë‹¨ (ì‹ ë¢°ë„ 0.7 ì´ìƒ)
8. í…ìŠ¤íŠ¸ ì²­í‚¹ ë° ì„ë² ë”©
9. VectorDB ì €ì¥ âœ…
```

**AI ì‘ëŒ€ ëª¨ë“œ íŠ¹ì§•**:
- âœ… **ì‹¤ì‹œê°„ STT**: í†µí™” ì¤‘ ì‹¤ì‹œê°„ ì „ì‚¬
- âœ… **ì¦‰ì‹œ ì¶”ì¶œ**: í†µí™” ì¢…ë£Œ í›„ ë°”ë¡œ ì§€ì‹ ì¶”ì¶œ (ì§€ì—° ì—†ìŒ)
- âœ… **í™”ì ë¶„ë¦¬**: STT Diarizationìœ¼ë¡œ caller/callee êµ¬ë¶„

#### âœ… ì‹œë‚˜ë¦¬ì˜¤ 2: ì¼ë°˜ SIP í†µí™” + í›„ì²˜ë¦¬ STT
```
1. User Aê°€ User Bì—ê²Œ ì „í™”
2. User Bê°€ ì§ì ‘ ì‘ë‹µ
3. SIPCallRecorderê°€ RTP íŒ¨í‚· ë…¹ìŒ
   â””â”€> caller.wav, callee.wav, mixed.wav ìƒì„±
4. í†µí™” ì¢…ë£Œ
5. SIPEndpoint._cleanup_call() í˜¸ì¶œ
6. SIPCallRecorderê°€ í›„ì²˜ë¦¬ STT ì‹¤í–‰
   â””â”€> transcript.txt ìƒì„± âœ…
7. CallManager.trigger_knowledge_extraction() í˜¸ì¶œ
   â””â”€> 5ì´ˆ delay (STT ì™„ë£Œ ëŒ€ê¸°)
8. KnowledgeExtractor.extract_from_call() ì‹¤í–‰
9. LLM ìœ ìš©ì„± íŒë‹¨
10. VectorDB ì €ì¥ âœ…
```

**ì¼ë°˜ SIP í†µí™” íŠ¹ì§•**:
- âœ… **í›„ì²˜ë¦¬ STT**: í†µí™” ì¢…ë£Œ í›„ ì „ì‚¬
- âœ… **5ì´ˆ ì§€ì—°**: STT ì™„ë£Œ ëŒ€ê¸° í›„ ì¶”ì¶œ
- âœ… **ë¹„ë™ê¸° ì²˜ë¦¬**: í†µí™” ì¢…ë£Œë¥¼ ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ

#### âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ 3: ì¼ë°˜ SIP í†µí™” (STT ë¯¸êµ¬í˜„ ì‹œ)
```
1. User Aê°€ User Bì—ê²Œ ì „í™”
2. User Bê°€ ì§ì ‘ ì‘ë‹µ
3. SIPCallRecorderê°€ RTP íŒ¨í‚· ë…¹ìŒ
   â””â”€> caller.wav, callee.wav, mixed.wav ìƒì„±
   â””â”€> âŒ transcript.txt ë¯¸ìƒì„±
4. í†µí™” ì¢…ë£Œ
5. CallManager.trigger_knowledge_extraction() í˜¸ì¶œ
6. 5ì´ˆ delay í›„ transcript.txt í™•ì¸
7. âŒ transcript.txtê°€ ì—†ì–´ì„œ ì§€ì‹ ì¶”ì¶œ ìŠ¤í‚µ
   â””â”€> ë¡œê·¸: "Transcript file not found after delay"
```

---

## ğŸ”§ ì¶”ê°€ êµ¬í˜„ í•„ìš” ì‚¬í•­

### 1. SIPCallRecorderì— í›„ì²˜ë¦¬ STT ì¶”ê°€
**íŒŒì¼**: `src/sip_core/sip_call_recorder.py`

**ì¶”ê°€ ë©”ì„œë“œ**:
```python
async def _transcribe_audio(
    self, 
    audio_path: Path,
    language: str = "ko-KR"
) -> str:
    """
    ë…¹ìŒ íŒŒì¼ì„ STTë¡œ ì „ì‚¬
    
    Args:
        audio_path: WAV íŒŒì¼ ê²½ë¡œ
        language: ì–¸ì–´ ì½”ë“œ
        
    Returns:
        ì „ì‚¬ í…ìŠ¤íŠ¸
    """
    # Google Speech-to-Text API ì‚¬ìš©
    from google.cloud import speech
    
    client = speech.SpeechClient()
    
    with open(audio_path, 'rb') as f:
        audio = speech.RecognitionAudio(content=f.read())
    
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code=language,
        enable_automatic_punctuation=True,
        enable_word_time_offsets=False
    )
    
    response = client.recognize(config=config, audio=audio)
    
    # ê²°ê³¼ ì¡°í•©
    transcript_lines = []
    for result in response.results:
        transcript_lines.append(result.alternatives[0].transcript)
    
    return '\n'.join(transcript_lines)
```

**stop_recording() ìˆ˜ì •**:
```python
async def stop_recording(self, call_id: str) -> dict:
    # ... WAV íŒŒì¼ ì €ì¥ ...
    
    # í›„ì²˜ë¦¬ STT (ì„ íƒì )
    if hasattr(self, 'stt_enabled') and self.stt_enabled:
        try:
            # Mixed audioì—ì„œ ì „ì‚¬
            transcript = await self._transcribe_audio(mixed_path)
            
            # transcript.txt ì €ì¥
            transcript_path = call_dir / "transcript.txt"
            with open(transcript_path, 'w', encoding='utf-8') as f:
                # í˜•ì‹: "í™”ì: í…ìŠ¤íŠ¸"
                # ì‹¤ì œë¡œëŠ” í™”ì ë¶„ë¦¬(diarization) í•„ìš”
                f.write(f"í†µí™” ë‚´ìš©:\n{transcript}")
            
            logger.info("Transcript generated",
                       call_id=call_id,
                       transcript_length=len(transcript))
        except Exception as e:
            logger.error("Transcription error",
                        call_id=call_id,
                        error=str(e))
    
    return metadata
```

### 2. CallManager ì´ˆê¸°í™” ì‹œ KnowledgeExtractor ì „ë‹¬
**íŒŒì¼**: `src/main.py` ë˜ëŠ” SIP PBX ì´ˆê¸°í™” ì½”ë“œ

```python
# KnowledgeExtractor ìƒì„±
knowledge_extractor = KnowledgeExtractor(
    llm_client=llm_client,
    embedder=embedder,
    vector_db=vector_db,
    min_confidence=0.7
)

# CallManager ìƒì„± ì‹œ ì „ë‹¬
call_manager = CallManager(
    call_repository=call_repository,
    media_session_manager=media_session_manager,
    ai_orchestrator=ai_orchestrator,
    knowledge_extractor=knowledge_extractor,  # ì‹ ê·œ
    recording_enabled=True
)
```

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### 1. ì§€ì‹ ë² ì´ìŠ¤ ìë™ í™•ì¥
- âœ… AI í†µí™”ë¿ë§Œ ì•„ë‹ˆë¼ ì¼ë°˜ í†µí™”ì—ì„œë„ ì§€ì‹ ìˆ˜ì§‘
- âœ… ë” ë§ì€ ë°ì´í„°ë¡œ RAG í’ˆì§ˆ í–¥ìƒ
- âœ… ì‚¬ìš©ìë³„ ë§ì¶¤í˜• ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•

### 2. AI ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ
- âœ… ì‹¤ì œ í†µí™” ë‚´ìš© ê¸°ë°˜ í•™ìŠµ
- âœ… ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ìë™ ìˆ˜ì§‘
- âœ… ê°œì¸ ì„ í˜¸ë„ íŒŒì•…

### 3. ìš´ì˜ íš¨ìœ¨ì„±
- âœ… ìˆ˜ë™ ì§€ì‹ ì…ë ¥ ë¶ˆí•„ìš”
- âœ… ìë™ìœ¼ë¡œ ìµœì‹  ì •ë³´ ìœ ì§€
- âœ… í†µí™” ì´ë ¥ í™œìš©ë„ ì¦ê°€

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: AI Attendant Timer Test
**ëª©ì **: íƒ€ì´ë¨¸ ê¸°ë°˜ AI ì‘ëŒ€ ëª¨ë“œì—ì„œ Knowledge Extraction ê²€ì¦

**Given**:
- `no_answer_timeout = 10ì´ˆ`
- AI Orchestrator ì´ˆê¸°í™” ì™„ë£Œ
- KnowledgeExtractor ì„¤ì • ì™„ë£Œ

**When**:
- ë°œì‹ ìê°€ ì°©ì‹ ìì—ê²Œ ì „í™”
- ì°©ì‹ ìê°€ 10ì´ˆê°„ ë¬´ì‘ë‹µ

**Then**:
- AIê°€ ìë™ìœ¼ë¡œ ì‘ë‹µ ì‹œì‘
- ì‹¤ì‹œê°„ STT ì‹¤í–‰ â†’ `transcript.txt` ìƒì„±
- í†µí™” ì¢…ë£Œ í›„ `AIOrchestrator.end_call()` í˜¸ì¶œ
- `KnowledgeExtractor.extract_from_call()` ì¦‰ì‹œ ì‹¤í–‰
- LLM ìœ ìš©ì„± íŒë‹¨ ìˆ˜í–‰
- VectorDBì— ì§€ì‹ ì €ì¥

**ê²€ì¦ ë°©ë²•**:
```bash
# ë¡œê·¸ í™•ì¸
grep "knowledge_extraction\|VectorDB Flow" logs/app.log

# VectorDB í™•ì¸
# ChromaDB ë˜ëŠ” Pineconeì—ì„œ í•´ë‹¹ call_idë¡œ ê²€ìƒ‰
```

---

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: Manual Away Status Test
**ëª©ì **: ìˆ˜ë™ ë¶€ì¬ì¤‘ ì„¤ì • ì‹œ ì¦‰ì‹œ AI ì‘ë‹µ ë° Knowledge Extraction ê²€ì¦

**Given**:
- ì›¹ì—ì„œ "ë¶€ì¬ì¤‘" ìƒíƒœ ì„¤ì •
- `/api/operator/status` API í˜¸ì¶œ ì™„ë£Œ

**When**:
- ì „í™” ìˆ˜ì‹ 

**Then**:
- ì¦‰ì‹œ AIê°€ ì‘ë‹µ (íƒ€ì´ë¨¸ ëŒ€ê¸° ì—†ìŒ)
- ì‹¤ì‹œê°„ STT ì‹¤í–‰
- í†µí™” ì¢…ë£Œ í›„ Knowledge Extraction ì‹¤í–‰

**ê²€ì¦ ë°©ë²•**:
```bash
# ë¶€ì¬ì¤‘ ìƒíƒœ í™•ì¸
curl -X GET http://localhost:8000/api/operator/status

# ë¡œê·¸ í™•ì¸
grep "callee_is_away\|ai_mode_activated" logs/app.log
```

---

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: Knowledge Extraction Test (ì¼ë°˜ SIP í†µí™”)
**ëª©ì **: ì¼ë°˜ SIP í†µí™”ì—ì„œ í›„ì²˜ë¦¬ STT ë° Knowledge Extraction ê²€ì¦

**Given**:
- ì¼ë°˜ SIP í†µí™” (AI ëª¨ë“œ ì•„ë‹˜)
- í›„ì²˜ë¦¬ STT ì„¤ì • ì™„ë£Œ
- `recording_enabled = True`

**When**:
- í†µí™” ì¢…ë£Œ
- STT í›„ì²˜ë¦¬ ì™„ë£Œ (ì•½ 3-5ì´ˆ ì†Œìš”)

**Then**:
- `SIPEndpoint._cleanup_call()` í˜¸ì¶œ
- `CallManager.trigger_knowledge_extraction()` í˜¸ì¶œ
- 5ì´ˆ delay í›„ `transcript.txt` í™•ì¸
- `KnowledgeExtractor.extract_from_call()` ì‹¤í–‰
- LLM ìœ ìš©ì„± íŒë‹¨ ë° VectorDB ì €ì¥

**ê²€ì¦ ë°©ë²•**:
```bash
# transcript íŒŒì¼ í™•ì¸
ls -la recordings/{call_id}/transcript.txt

# ë¡œê·¸ í™•ì¸
grep "trigger_knowledge_extraction\|Knowledge Flow" logs/app.log

# VectorDB í™•ì¸
# ì €ì¥ëœ ì§€ì‹ ê²€ìƒ‰
```

---

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 4: Knowledge Extraction ì‹¤íŒ¨ ì¼€ì´ìŠ¤
**ëª©ì **: transcript íŒŒì¼ì´ ì—†ì„ ë•Œ ì•ˆì „í•œ ì²˜ë¦¬ ê²€ì¦

**Given**:
- ì¼ë°˜ SIP í†µí™”
- í›„ì²˜ë¦¬ STT ë¯¸ì„¤ì • ë˜ëŠ” ì‹¤íŒ¨

**When**:
- í†µí™” ì¢…ë£Œ
- `trigger_knowledge_extraction()` í˜¸ì¶œ
- 5ì´ˆ delay í›„ `transcript.txt` í™•ì¸

**Then**:
- `transcript.txt` íŒŒì¼ ì—†ìŒ ê°ì§€
- ì§€ì‹ ì¶”ì¶œ ìŠ¤í‚µ (ì—ëŸ¬ ì—†ìŒ)
- ê²½ê³  ë¡œê·¸ ì¶œë ¥: "Transcript file not found after delay"

**ê²€ì¦ ë°©ë²•**:
```bash
# ë¡œê·¸ í™•ì¸
grep "Transcript file not found" logs/app.log
```

---

## ğŸ“ ê²°ë¡ 

### í˜„ì¬ ìƒíƒœ
- âœ… **ì„¤ê³„ì„œ**: ëª…ì‹œë˜ì–´ ìˆìŒ (ì„¹ì…˜ 4.4)
- âœ… **KnowledgeExtractor**: ì™„ì „ êµ¬í˜„ (100%)
- âœ… **LLM ìœ ìš©ì„± íŒë‹¨**: ì™„ì „ êµ¬í˜„ (100%)
- âœ… **AI í†µí™” ì§€ì‹ ì¶”ì¶œ**: ì‘ë™ ì¤‘ (100%)
- âœ… **ì¼ë°˜ í†µí™” íŠ¸ë¦¬ê±°**: êµ¬í˜„ ì™„ë£Œ (100%)
- âœ… **trigger_knowledge_extraction()**: êµ¬í˜„ ì™„ë£Œ (100%)
- âœ… **SIPEndpoint._cleanup_call() í†µí•©**: ì™„ë£Œ (100%)
- âš ï¸ **ì¼ë°˜ í†µí™” Transcript ìƒì„±**: í›„ì²˜ë¦¬ STT í•„ìš” (0%)

### AI ì‘ëŒ€ ëª¨ë“œ í†µí•©
- âœ… **íƒ€ì´ë¨¸ ê¸°ë°˜**: `no_answer_timeout` ê²½ê³¼ ì‹œ ìë™ AI ì‘ë‹µ
- âœ… **ìˆ˜ë™ ì„¤ì •**: ì›¹ APIë¡œ ë¶€ì¬ì¤‘ ìƒíƒœ ì„¤ì • ì‹œ ì¦‰ì‹œ AI ì‘ë‹µ
- âœ… **ì‹¤ì‹œê°„ STT**: AI ì‘ëŒ€ ëª¨ë“œì—ì„œ ì‹¤ì‹œê°„ ì „ì‚¬
- âœ… **ì¦‰ì‹œ ì¶”ì¶œ**: AI í†µí™” ì¢…ë£Œ í›„ ì§€ì—° ì—†ì´ ì§€ì‹ ì¶”ì¶œ

### ê¶Œì¥ ì‚¬í•­
1. **ì¦‰ì‹œ**: í›„ì²˜ë¦¬ STTë¥¼ SIPCallRecorderì— ì¶”ê°€
2. **ë‹¨ê¸°**: CallManager ì´ˆê¸°í™” ì‹œ KnowledgeExtractor ì£¼ì… í™•ì¸
3. **ì¥ê¸°**: ì‹¤ì‹œê°„ STT + í™”ì ë¶„ë¦¬(diarization) êµ¬í˜„

### ë‹¤ìŒ ë‹¨ê³„
1. SIPCallRecorderì— í›„ì²˜ë¦¬ STT ì¶”ê°€
2. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ë° ê²€ì¦
3. ì„±ëŠ¥ ìµœì í™” (ë³‘ë ¬ ì²˜ë¦¬)
4. ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ì¶”ê°€

---

**ì‘ì„±ì**: Winston (Developer)  
**ì¼ì**: 2026-02-05  
**ìƒíƒœ**: ë¶„ì„ ì™„ë£Œ + íŠ¸ë¦¬ê±° êµ¬í˜„ ì™„ë£Œ + AI ì‘ëŒ€ ëª¨ë“œ í†µí•© ì™„ë£Œ  
**ë‹¤ìŒ**: Transcript ìƒì„± êµ¬í˜„ í•„ìš”

