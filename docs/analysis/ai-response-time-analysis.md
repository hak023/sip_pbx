# AI ë³´ì´ìŠ¤ë´‡ ì‘ë‹µ ì‹œê°„ ë¶„ì„

## ğŸ“Š ì „ì²´ ì‘ë‹µ ì‹œê°„ ì˜ˆìƒì¹˜

ì‚¬ìš©ì ë°œí™” ì¢…ë£Œ â†’ AI ì‘ë‹µ ì‹œì‘ê¹Œì§€ì˜ ì˜ˆìƒ ì‹œê°„ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

---

## ğŸ”„ ì‘ë‹µ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
[ì‚¬ìš©ì ë°œí™” ì¢…ë£Œ]
    â†“
[1] STT ìµœì¢… ê²°ê³¼ ìˆ˜ì‹  (Google Cloud Speech-to-Text)
    â†“
[2] VAD ì²˜ë¦¬ ë° ë‚´ë¶€ ë²„í¼ ì²˜ë¦¬
    â†“
[3] RAG ê²€ìƒ‰ (Vector DB ìœ ì‚¬ë„ ê²€ìƒ‰)
    â†“
[4] LLM ì‘ë‹µ ìƒì„± (Google Gemini)
    â†“
[5] TTS ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘ (Google Cloud TTS)
    â†“
[6] ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ ì²­í¬ RTP ì „ì†¡
    â†“
[AI ì‘ë‹µ ì‹œì‘]
```

---

## â±ï¸ ë‹¨ê³„ë³„ ì˜ˆìƒ ì‹œê°„

### 1ï¸âƒ£ STT ìµœì¢… ê²°ê³¼ ìˆ˜ì‹  (100~300ms)

**Google Cloud Speech-to-Text Streaming API**

- **ì¼ë°˜ì ì¸ ê²½ìš°**: 150~250ms
- **ìµœì  ì¡°ê±´ (ì§§ì€ ë°œí™”)**: 100~150ms
- **ì§€ì—° ì¡°ê±´ (ê¸´ ë°œí™”, ë„¤íŠ¸ì›Œí¬ ì§€ì—°)**: 250~300ms

**ì˜í–¥ ìš”ì¸:**
- ì‚¬ìš©ì ë°œí™” ê¸¸ì´ (ì§§ì„ìˆ˜ë¡ ë¹ ë¦„)
- ë„¤íŠ¸ì›Œí¬ ì§€ì—° (í•œêµ­ â†’ Google Cloud US/Asia ë¦¬ì „)
- Telephony ëª¨ë¸ ì‚¬ìš© (ì „í™” í’ˆì§ˆ ì˜¤ë””ì˜¤ ìµœì í™”)
- VAD ê°ì§€ ì •í™•ë„ (ë°œí™” ì¢…ë£Œ ì¸ì‹)

**ì„¤ì •ê°’ (config.yaml):**
```yaml
google_cloud:
  stt:
    model: "telephony"           # ì „í™” í’ˆì§ˆ ìµœì í™”
    language_code: "ko-KR"
    sample_rate: 16000
    enable_automatic_punctuation: true
```

**ì˜ˆìƒ ì‹œê°„: 150ms (í‰ê· )**

---

### 2ï¸âƒ£ VAD ë° ë‚´ë¶€ ë²„í¼ ì²˜ë¦¬ (10~30ms)

**WebRTC VAD + Audio Buffer**

- **VAD í”„ë ˆì„ ì²˜ë¦¬**: 10ms
- **Jitter Buffer ì§€ì—°**: 60ms (ì„¤ì •ê°’)
- **ë‚´ë¶€ í ì²˜ë¦¬**: 5~10ms

**ì„¤ì •ê°’:**
```yaml
vad:
  aggressiveness: 3              # 0-3, 3ì´ ê°€ì¥ ë¯¼ê°
  frame_duration_ms: 30          # 10, 20, 30
```

**ìµœì í™”:**
- VADëŠ” STTì™€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ì¶”ê°€ ì§€ì—° ì—†ìŒ
- Jitter BufferëŠ” STT ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì— ì´ë¯¸ ì²˜ë¦¬ë¨

**ì˜ˆìƒ ì‹œê°„: ~0ms (ë³‘ë ¬ ì²˜ë¦¬)**

---

### 3ï¸âƒ£ RAG ê²€ìƒ‰ (50~150ms)

**Vector DB ìœ ì‚¬ë„ ê²€ìƒ‰ + ì¬ìˆœìœ„í™”**

- **í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±**: 20~50ms
  - Sentence Transformers (ë¡œì»¬ ëª¨ë¸)
  - ëª¨ë¸: `all-MiniLM-L6-v2` (384ì°¨ì›)
  
- **Vector DB ê²€ìƒ‰**: 20~50ms
  - ChromaDB (ê°œë°œ): 10~30ms (ë¡œì»¬ ë””ìŠ¤í¬)
  - Pinecone (í”„ë¡œë•ì…˜): 30~50ms (ë„¤íŠ¸ì›Œí¬ API)
  
- **ì¬ìˆœìœ„í™” (ì„ íƒ)**: 10~50ms
  - í‚¤ì›Œë“œ ë§¤ì¹­
  - ë¬¸ì„œ ê¸¸ì´ ì¡°ì •

**ì„¤ì •ê°’:**
```yaml
vector_db:
  provider: "chromadb"           # ë˜ëŠ” "pinecone"
  top_k: 3                       # ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
  similarity_threshold: 0.7
  reranking_enabled: false       # trueì¼ ê²½ìš° +10~50ms
```

**ì˜ˆìƒ ì‹œê°„:**
- ChromaDB (ê°œë°œ): 50~80ms
- Pinecone (í”„ë¡œë•ì…˜): 70~120ms
- **í‰ê· : 80ms**

---

### 4ï¸âƒ£ LLM ì‘ë‹µ ìƒì„± (500~1500ms)

**Google Gemini Pro API**

- **ì§§ì€ ì‘ë‹µ (1~2ë¬¸ì¥)**: 500~800ms
- **ì¤‘ê°„ ì‘ë‹µ (3~5ë¬¸ì¥)**: 800~1200ms
- **ê¸´ ì‘ë‹µ (6ë¬¸ì¥ ì´ìƒ)**: 1200~1500ms

**ì˜í–¥ ìš”ì¸:**
- ìƒì„±í•  í…ìŠ¤íŠ¸ ê¸¸ì´ (`max_tokens`)
- ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (ëŒ€í™” íˆìŠ¤í† ë¦¬ + RAG ë¬¸ì„œ)
- Gemini API ë¦¬ì „ ë° ë¶€í•˜
- Temperature ì„¤ì • (ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„)

**ì„¤ì •ê°’:**
```yaml
gemini:
  model: "gemini-pro"
  temperature: 0.7               # 0.3~0.5ë¡œ ë‚®ì¶”ë©´ +10~20% ì†ë„ í–¥ìƒ
  max_tokens: 200                # í† í° ìˆ˜ ì œí•œ (ì§§ì„ìˆ˜ë¡ ë¹ ë¦„)
  top_p: 1.0
  top_k: 1
```

**ìµœì í™” ì „ëµ:**
1. **max_tokens ì œí•œ**: 200 í† í° (ì•½ 1~2ë¬¸ì¥)
2. **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìµœì í™”**: "1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€"
3. **ëŒ€í™” íˆìŠ¤í† ë¦¬ ì œí•œ**: ìµœê·¼ 10í„´ë§Œ ìœ ì§€
4. **ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ì œí•œ**: top_k=3

**ì˜ˆìƒ ì‹œê°„:**
- ìµœì í™”ëœ ì§§ì€ ì‘ë‹µ: 500~700ms
- **í‰ê· : 800ms**

---

### 5ï¸âƒ£ TTS ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘ (200~400ms)

**Google Cloud Text-to-Speech API**

- **API í˜¸ì¶œ ì§€ì—°**: 100~200ms
- **ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ ì²­í¬ ìƒì„±**: 100~200ms

**ì˜í–¥ ìš”ì¸:**
- ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´
- TTS ëª¨ë¸ (Neural2 ëª¨ë¸ ì‚¬ìš©)
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°

**ì„¤ì •ê°’:**
```yaml
tts:
  voice_name: "ko-KR-Neural2-A"  # ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
  speaking_rate: 1.0             # ë§í•˜ê¸° ì†ë„
  pitch: 0.0
  volume_gain_db: 0.0
```

**ìŠ¤íŠ¸ë¦¬ë° íŠ¹ì„±:**
- TTSëŠ” ì „ì²´ ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ ì „ì— ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ê°€ëŠ¥
- ì²« ë²ˆì§¸ ì²­í¬(4KB)ë§Œ ìƒì„±ë˜ë©´ ì¬ìƒ ì‹œì‘
- ì‚¬ìš©ìëŠ” ì „ì²´ ìƒì„± ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ

**ì˜ˆìƒ ì‹œê°„: 250ms (ì²« ì²­í¬ ìƒì„±)**

---

### 6ï¸âƒ£ RTP ì „ì†¡ ë° ì¬ìƒ ì‹œì‘ (~50ms)

**RTP Relay + ë„¤íŠ¸ì›Œí¬ ì „ì†¡**

- **RTP íŒ¨í‚· ìƒì„±**: 5~10ms
- **ë„¤íŠ¸ì›Œí¬ ì „ì†¡ ì§€ì—°**: 20~40ms (ë¡œì»¬ ë„¤íŠ¸ì›Œí¬)
- **Caller ì¸¡ ì§€í„° ë²„í¼**: 20~60ms

**ì˜ˆìƒ ì‹œê°„: 50ms**

---

## ğŸ“ˆ ì „ì²´ ì‘ë‹µ ì‹œê°„ ìš”ì•½

### âš¡ ìµœì  ì¡°ê±´ (Best Case)
```
STT ìµœì¢… ê²°ê³¼:        100ms
VAD/ë²„í¼:              0ms (ë³‘ë ¬)
RAG ê²€ìƒ‰:             50ms
LLM ì‘ë‹µ:            500ms
TTS ì²« ì²­í¬:         200ms
RTP ì „ì†¡:             30ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í•©ê³„:                880ms (~0.9ì´ˆ)
```

### ğŸ¯ ì¼ë°˜ì ì¸ ê²½ìš° (Average Case)
```
STT ìµœì¢… ê²°ê³¼:        150ms
VAD/ë²„í¼:              0ms (ë³‘ë ¬)
RAG ê²€ìƒ‰:             80ms
LLM ì‘ë‹µ:            800ms
TTS ì²« ì²­í¬:         250ms
RTP ì „ì†¡:             50ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í•©ê³„:               1330ms (~1.3ì´ˆ)
```

### ğŸŒ ìµœì•… ì¡°ê±´ (Worst Case)
```
STT ìµœì¢… ê²°ê³¼:        300ms
VAD/ë²„í¼:              0ms (ë³‘ë ¬)
RAG ê²€ìƒ‰:            150ms
LLM ì‘ë‹µ:           1500ms
TTS ì²« ì²­í¬:         400ms
RTP ì „ì†¡:             80ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í•©ê³„:               2430ms (~2.4ì´ˆ)
```

---

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë° ìµœì í™”

### ì‚¬ìš©ì ê²½í—˜ ê´€ì 

**ì‘ë‹µ ì‹œê°„ ê¸°ì¤€ (ì‹¬ë¦¬í•™ ì—°êµ¬):**
- **0.1ì´ˆ ì´í•˜**: ì¦‰ê° ë°˜ì‘ (ì¸ì‹ ë¶ˆê°€)
- **0.1~1.0ì´ˆ**: ì•½ê°„ì˜ ì§€ì—° (ìì—°ìŠ¤ëŸ¬ì›€)
- **1.0~3.0ì´ˆ**: ëª…í™•í•œ ì§€ì—° (ìˆ˜ìš© ê°€ëŠ¥)
- **3.0ì´ˆ ì´ìƒ**: ì‹œìŠ¤í…œ ëŠë¦¼ (ë¶ˆí¸í•¨)

**AI ë³´ì´ìŠ¤ë´‡ ì‘ë‹µ ì‹œê°„:**
- âœ… **1.3ì´ˆ (í‰ê· )**: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìˆ˜ì¤€
- âš ï¸ **2.4ì´ˆ (ìµœì•…)**: ìˆ˜ìš© ê°€ëŠ¥í•˜ì§€ë§Œ ê°œì„  í•„ìš”

### ğŸš€ ìµœì í™” ì „ëµ

#### 1. LLM ì‘ë‹µ ì†ë„ ê°œì„  (500ms ë‹¨ì¶•)

**A. ëª¨ë¸ ë³€ê²½:**
```yaml
gemini:
  model: "gemini-1.5-flash"      # gemini-proë³´ë‹¤ 2~3ë°° ë¹ ë¦„
  max_tokens: 150                # 200 â†’ 150 (ì§§ì€ ì‘ë‹µ)
  temperature: 0.5               # 0.7 â†’ 0.5 (ë” ê²°ì •ë¡ ì )
```

**B. ìŠ¤íŠ¸ë¦¬ë° ìƒì„± (í–¥í›„ ì§€ì› ì‹œ):**
- LLMì´ í† í°ì„ ìƒì„±í•˜ëŠ” ì¦‰ì‹œ TTSë¡œ ì „ì†¡
- ì „ì²´ ì‘ë‹µ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ
- ì˜ˆìƒ ì ˆê°: 300~500ms

**C. í”„ë¡¬í”„íŠ¸ ìµœì í™”:**
```python
system_prompt = """
ë‹¹ì‹ ì€ ì „í™” ì‘ëŒ€ AIì…ë‹ˆë‹¤.
ê·œì¹™:
1. 1ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ (ìµœëŒ€ 20ë‹¨ì–´)
2. ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ ìƒëµ
3. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
"""
```

#### 2. RAG ê²€ìƒ‰ ìµœì í™” (30ms ë‹¨ì¶•)

**A. ìºì‹±:**
```python
# ìì£¼ ë¬»ëŠ” ì§ˆë¬¸(FAQ) ìºì‹±
faq_cache = {
    "ì˜ì—…ì‹œê°„": "í‰ì¼ 9ì‹œë¶€í„° 6ì‹œê¹Œì§€ì…ë‹ˆë‹¤.",
    "ì£¼ì†Œ": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123ì…ë‹ˆë‹¤."
}
```

**B. Vector DB ì¸ë±ìŠ¤ ìµœì í™”:**
```yaml
vector_db:
  chromadb:
    persist_directory: "./data/chromadb"
    # SSD ì‚¬ìš© ê¶Œì¥
```

#### 3. TTS ìƒì„± ìµœì í™” (50ms ë‹¨ì¶•)

**A. ìŒì„± ì„¤ì •:**
```yaml
tts:
  speaking_rate: 1.1             # 1.0 â†’ 1.1 (10% ë¹ ë¥´ê²Œ)
  # ì²­í¬ í¬ê¸° ì¡°ì •ìœ¼ë¡œ ì²« ì²­í¬ ë” ë¹ ë¥´ê²Œ ìƒì„±
```

**B. ë³‘ë ¬ ì²˜ë¦¬:**
```python
# LLM ìƒì„±ê³¼ TTS ìš”ì²­ì„ ë³‘ë ¬ë¡œ
asyncio.gather(
    llm.generate_response(...),
    tts.prepare_synthesis(...)   # ìŒì„± ì—”ì§„ ì¤€ë¹„
)
```

#### 4. ë„¤íŠ¸ì›Œí¬ ìµœì í™” (20ms ë‹¨ì¶•)

**A. ë¦¬ì „ ì„ íƒ:**
- Google Cloud Asia ë¦¬ì „ ì‚¬ìš© (ì„œìš¸ â†’ ë„ì¿„)
- ë„¤íŠ¸ì›Œí¬ ì§€ì—° ê°ì†Œ

**B. ì—°ê²° ì¬ì‚¬ìš©:**
```python
# gRPC ì—°ê²° í’€ë§
# HTTP/2 keep-alive
```

---

## ğŸ“Š ìµœì í™” í›„ ì˜ˆìƒ ì‹œê°„

### ğŸ¯ ìµœì í™” ì ìš© ì‹œ (Optimized Case)
```
STT ìµœì¢… ê²°ê³¼:        120ms  (â†“30ms, ë„¤íŠ¸ì›Œí¬ ìµœì í™”)
VAD/ë²„í¼:              0ms
RAG ê²€ìƒ‰:             50ms  (â†“30ms, ìºì‹±)
LLM ì‘ë‹µ:            400ms  (â†“400ms, Flash ëª¨ë¸)
TTS ì²« ì²­í¬:         180ms  (â†“70ms, ë³‘ë ¬ ì²˜ë¦¬)
RTP ì „ì†¡:             30ms  (â†“20ms, ë„¤íŠ¸ì›Œí¬)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í•©ê³„:                780ms (~0.8ì´ˆ) âœ¨
```

**ê°œì„ ìœ¨: 41% (1330ms â†’ 780ms)**

---

## ğŸ” ì‹¤ì œ ì¸¡ì • ë°©ë²•

### ì½”ë“œ ê³„ì¸¡ (Instrumentation)

```python
# src/ai_voicebot/orchestrator.py

import time
import structlog

logger = structlog.get_logger(__name__)

class AIOrchestrator:
    async def _generate_and_speak_response(self, user_text: str):
        # ì „ì²´ ì‹œì‘ ì‹œê°„
        total_start = time.time()
        
        self.state = AIState.THINKING
        
        # 1. RAG ê²€ìƒ‰
        rag_start = time.time()
        context_docs = await self.rag.search(user_text, owner_filter=self.callee_id)
        rag_time = (time.time() - rag_start) * 1000  # ms
        
        # 2. LLM ìƒì„±
        llm_start = time.time()
        response_text = await self.llm.generate_response(
            user_text=user_text,
            context_docs=[doc.text for doc in context_docs],
            system_prompt=self.config.google_cloud.gemini.system_prompt
        )
        llm_time = (time.time() - llm_start) * 1000  # ms
        
        # 3. TTS ì²« ì²­í¬
        tts_start = time.time()
        await self._speak(response_text)
        tts_first_chunk = (time.time() - tts_start) * 1000  # ms
        
        # ì „ì²´ ì‹œê°„
        total_time = (time.time() - total_start) * 1000  # ms
        
        # ë¡œê·¸ ê¸°ë¡
        logger.info("ai_response_time_breakdown",
                   call_id=self.call_id,
                   user_text_length=len(user_text),
                   response_text_length=len(response_text),
                   rag_search_ms=round(rag_time, 1),
                   llm_generation_ms=round(llm_time, 1),
                   tts_first_chunk_ms=round(tts_first_chunk, 1),
                   total_response_ms=round(total_time, 1))
        
        # Prometheus ë©”íŠ¸ë¦­
        self._record_metrics(rag_time, llm_time, tts_first_chunk, total_time)
```

### Prometheus ë©”íŠ¸ë¦­ ì •ì˜

```python
# src/monitoring/metrics.py

from prometheus_client import Histogram

ai_response_time = Histogram(
    'ai_response_time_seconds',
    'AI ì „ì²´ ì‘ë‹µ ì‹œê°„',
    buckets=[0.5, 0.8, 1.0, 1.5, 2.0, 3.0, 5.0]
)

rag_search_time = Histogram(
    'rag_search_time_seconds',
    'RAG ê²€ìƒ‰ ì‹œê°„',
    buckets=[0.01, 0.05, 0.1, 0.2, 0.5]
)

llm_generation_time = Histogram(
    'llm_generation_time_seconds',
    'LLM ìƒì„± ì‹œê°„',
    buckets=[0.3, 0.5, 0.8, 1.0, 1.5, 2.0]
)

tts_first_chunk_time = Histogram(
    'tts_first_chunk_time_seconds',
    'TTS ì²« ì²­í¬ ìƒì„± ì‹œê°„',
    buckets=[0.1, 0.2, 0.3, 0.5, 1.0]
)
```

---

## ğŸ“‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

```python
# tests/performance/test_response_time.py

import pytest
import time

class TestAIResponseTime:
    """AI ì‘ë‹µ ì‹œê°„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_simple_question_response_time(self):
        """ê°„ë‹¨í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        orchestrator = AIOrchestrator(...)
        
        start = time.time()
        await orchestrator._generate_and_speak_response("ì•ˆë…•í•˜ì„¸ìš”")
        duration = (time.time() - start) * 1000
        
        # ëª©í‘œ: 1.5ì´ˆ ì´ë‚´
        assert duration < 1500, f"ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {duration}ms"
    
    @pytest.mark.asyncio
    async def test_rag_search_response_time(self):
        """RAG ê²€ìƒ‰ í¬í•¨ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        orchestrator = AIOrchestrator(...)
        
        start = time.time()
        await orchestrator._generate_and_speak_response("ì˜ì—…ì‹œê°„ì´ ì–¸ì œì¸ê°€ìš”?")
        duration = (time.time() - start) * 1000
        
        # ëª©í‘œ: 2ì´ˆ ì´ë‚´
        assert duration < 2000, f"ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {duration}ms"
    
    @pytest.mark.asyncio
    async def test_p95_response_time(self):
        """P95 ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ (100íšŒ ë°˜ë³µ)"""
        orchestrator = AIOrchestrator(...)
        durations = []
        
        for _ in range(100):
            start = time.time()
            await orchestrator._generate_and_speak_response("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
            durations.append((time.time() - start) * 1000)
        
        p95 = sorted(durations)[94]  # 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜
        
        # ëª©í‘œ: P95 < 2.5ì´ˆ
        assert p95 < 2500, f"P95 ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {p95}ms"
```

---

## ğŸ¯ ê²°ë¡ 

### í˜„ì¬ ì‹œìŠ¤í…œ ì˜ˆìƒ ì‘ë‹µ ì‹œê°„

| ì‹œë‚˜ë¦¬ì˜¤ | ì˜ˆìƒ ì‹œê°„ | ì‚¬ìš©ì ê²½í—˜ |
|---------|----------|----------|
| **ìµœì  ì¡°ê±´** | 0.9ì´ˆ | âœ… ë§¤ìš° ìì—°ìŠ¤ëŸ¬ì›€ |
| **ì¼ë°˜ì ì¸ ê²½ìš°** | **1.3ì´ˆ** | âœ… ìì—°ìŠ¤ëŸ¬ì›€ |
| **ìµœì•… ì¡°ê±´** | 2.4ì´ˆ | âš ï¸ ìˆ˜ìš© ê°€ëŠ¥ |
| **ìµœì í™” í›„** | 0.8ì´ˆ | âœ¨ ê±°ì˜ ì¦‰ê° ë°˜ì‘ |

### ê¶Œì¥ ì‚¬í•­

1. **ì´ˆê¸° ë°°í¬**: í˜„ì¬ ì•„í‚¤í…ì²˜ (í‰ê·  1.3ì´ˆ)
   - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìˆ˜ì¤€
   - ì¶”ê°€ ìµœì í™” ì—†ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥

2. **1ì°¨ ìµœì í™”** (2ì£¼ ë‚´):
   - Gemini Flash ëª¨ë¸ ì ìš©
   - max_tokens 150ìœ¼ë¡œ ì œí•œ
   - í”„ë¡¬í”„íŠ¸ ìµœì í™”
   - **ëª©í‘œ: 1.0ì´ˆ**

3. **2ì°¨ ìµœì í™”** (1ê°œì›” ë‚´):
   - FAQ ìºì‹± êµ¬í˜„
   - ë„¤íŠ¸ì›Œí¬ ë¦¬ì „ ìµœì í™”
   - LLM ìŠ¤íŠ¸ë¦¬ë° (ì§€ì› ì‹œ)
   - **ëª©í‘œ: 0.8ì´ˆ**

### ê²½ìŸ ì œí’ˆ ë¹„êµ

- **Google Assistant**: 0.8~1.2ì´ˆ
- **Amazon Alexa**: 1.0~1.5ì´ˆ
- **Apple Siri**: 0.9~1.3ì´ˆ
- **ë³¸ ì‹œìŠ¤í…œ (ì˜ˆìƒ)**: 1.3ì´ˆ â†’ **ê²½ìŸë ¥ ìˆìŒ** âœ…

---

## ğŸ“ ë¬¸ì˜

ì„±ëŠ¥ ê´€ë ¨ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ìµœì í™” ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ê°œë°œíŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”.

