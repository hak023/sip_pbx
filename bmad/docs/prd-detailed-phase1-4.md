# SmartPBX AI - Detailed Product Requirements Document
## Active RAG ê¸°ë°˜ ì§€ëŠ¥í˜• í†µí™” ì‘ëŒ€ ì‹œìŠ¤í…œ - Phase 1-4 ìƒì„¸ ìš”êµ¬ì‚¬í•­

**ë¬¸ì„œ ë²„ì „**: v2.0  
**ì‘ì„±ì¼**: 2026-01-30  
**ì‘ì„±ì**: Product Team  
**ìƒíƒœ**: Draft for Review

---

## ğŸ“‹ ëª©ì°¨

1. [ë¬¸ì„œ ê°œìš”](#ë¬¸ì„œ-ê°œìš”)
2. [Phase 1: Active RAG ê¸°ë°˜ ì§€ì‹ ìë™ êµ¬ì¶•](#phase-1-active-rag-ê¸°ë°˜-ì§€ì‹-ìë™-êµ¬ì¶•)
3. [Phase 2: AI ê¸°ë°˜ Dynamic ARS](#phase-2-ai-ê¸°ë°˜-dynamic-ars)
4. [Phase 3: HITL + Shadowing Mode](#phase-3-hitl--shadowing-mode)
5. [Phase 4: Agentic AI + Multi-Agent](#phase-4-agentic-ai--multi-agent)
6. [Cross-cutting Concerns](#cross-cutting-concerns)
7. [ë¶€ë¡: User Story í…œí”Œë¦¿](#ë¶€ë¡-user-story-í…œí”Œë¦¿)

---

## ë¬¸ì„œ ê°œìš”

### ëª©ì 
ë³¸ ë¬¸ì„œëŠ” SmartPBX AIì˜ Phase 1-4ì— ëŒ€í•œ ìƒì„¸ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ê³¼ User Storyë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ê° PhaseëŠ” ë…ë¦½ì ìœ¼ë¡œ ë°°í¬ ê°€ëŠ¥í•˜ë©°(Incrementally Deliverable), ì´ì „ Phaseì˜ ê¸°ëŠ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.

### ë²”ìœ„
- **In Scope**: Phase 1-4ì˜ ëª¨ë“  AI ê´€ë ¨ ê¸°ëŠ¥ (Active RAG, AI-ARS, HITL, Agentic AI)
- **Out of Scope**: ê¸°ë³¸ SIP PBX ê¸°ëŠ¥ (ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ, ë³„ë„ PRD ì°¸ì¡°)

### ìš©ì–´ ì •ì˜
| ìš©ì–´ | ì •ì˜ |
|------|------|
| **Active RAG** | ì‹¤ì‹œê°„ìœ¼ë¡œ í†µí™” ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” Retrieval Augmented Generation |
| **HITL** | Human-In-The-Loop, ìš´ì˜ìê°€ AI í•™ìŠµì— ì§ì ‘ ê°œì…í•˜ëŠ” ì‹œìŠ¤í…œ |
| **Shadowing Mode** | AIê°€ ìƒë‹´ì›ì—ê²Œ ì‹¤ì‹œê°„ ë‹µë³€ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ëª¨ë“œ |
| **Agentic AI** | ììœ¨ì ìœ¼ë¡œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ê²°ì •ì„ ë‚´ë¦¬ëŠ” AI Agent |
| **Confidence Score** | AI ë‹µë³€ì˜ ì‹ ë¢°ë„ ì ìˆ˜ (0-100%) |
| **Diarization** | í†µí™” ì¤‘ í™”ì(ë°œì‹ ì/ìˆ˜ì‹ ì) êµ¬ë¶„ |

---

## Phase 1: Active RAG ê¸°ë°˜ ì§€ì‹ ìë™ êµ¬ì¶•

### Epic 1.1: í†µí™” ë°ì´í„° ìë™ ìˆ˜ì§‘ ë° ì €ì¥

#### ê°œìš”
ëª¨ë“  í†µí™”ëŠ” STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ë˜ê³ , í™”ì ë¶„ë¦¬(Diarization)ë¥¼ í†µí•´ ë°œì‹ ì/ìˆ˜ì‹ ìë¥¼ êµ¬ë¶„í•˜ì—¬ Vector Databaseì— ìë™ ì €ì¥ë©ë‹ˆë‹¤.

---

#### Feature 1.1.1: í†µí™” Transcript ì‹¤ì‹œê°„ ìƒì„±

**Feature ID**: `F1.1.1`  
**Priority**: P0 (Must Have)  
**Complexity**: Medium  
**Estimated Story Points**: 8

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-1.1.1-01 | í†µí™” ì‹œì‘ ì‹œ STT íŒŒì´í”„ë¼ì¸ ìë™ í™œì„±í™” | âœ… SIP INVITE ìˆ˜ì‹  í›„ 1ì´ˆ ì´ë‚´ STT ì‹œì‘ |
| FR-1.1.1-02 | Real-time STT (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ) ì§€ì› | âœ… RTP íŒ¨í‚· ìˆ˜ì‹  ì¦‰ì‹œ í…ìŠ¤íŠ¸ ë³€í™˜ (ì§€ì—° <500ms) |
| FR-1.1.1-03 | í†µí™” ì¢…ë£Œ ì‹œ Full Transcript ìƒì„± | âœ… BYE ë©”ì‹œì§€ í›„ 5ì´ˆ ì´ë‚´ ì™„ì „í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± |
| FR-1.1.1-04 | Diarization (í™”ì ë¶„ë¦¬) ìë™ ì ìš© | âœ… Speaker 1 = Caller, Speaker 2 = Calleeë¡œ ìë™ ë¶„ë¥˜ |
| FR-1.1.1-05 | Transcript ë©”íƒ€ë°ì´í„° í¬í•¨ | âœ… Call-ID, íƒ€ì„ìŠ¤íƒ¬í”„, í†µí™” ì‹œê°„, ì°¸ì—¬ì ì •ë³´ í¬í•¨ |

##### Non-Functional Requirements

| ID | Requirement | Target |
|----|-------------|--------|
| NFR-1.1.1-01 | STT Latency (ì‹¤ì‹œê°„ ëª¨ë“œ) | < 500ms |
| NFR-1.1.1-02 | STT ì •í™•ë„ (WER) | < 10% (í•œêµ­ì–´) |
| NFR-1.1.1-03 | ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥ í†µí™” ìˆ˜ | 100ê°œ ì´ìƒ |
| NFR-1.1.1-04 | Transcript ì €ì¥ ì‹¤íŒ¨ìœ¨ | < 0.1% |

##### User Stories

**US-1.1.1-01**: ì‹¤ì‹œê°„ í†µí™” í…ìŠ¤íŠ¸ ë³€í™˜
```gherkin
As a: ì‹œìŠ¤í…œ ê´€ë¦¬ì
I want to: ëª¨ë“  í†µí™”ê°€ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤
So that: í†µí™” ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ 1003ë²ˆìœ¼ë¡œ ì „í™”ë¥¼ ê±¸ ë•Œ
- When: í†µí™”ê°€ ì—°ê²°ë˜ê³  ëŒ€í™”ê°€ ì‹œì‘ë˜ë©´
- Then: ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: í™”ìê°€ ìë™ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (Caller vs. Callee)
- And: ë³€í™˜ëœ í…ìŠ¤íŠ¸ëŠ” 500ms ì´ë‚´ì— ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Input (Audio): "ì•ˆë…•í•˜ì„¸ìš”, ì£¼ë¬¸ ì¡°íšŒí•˜ë ¤ê³  í•©ë‹ˆë‹¤"
  Output (Text): "[Caller] ì•ˆë…•í•˜ì„¸ìš”, ì£¼ë¬¸ ì¡°íšŒí•˜ë ¤ê³  í•©ë‹ˆë‹¤"
  Timestamp: 2026-01-30T10:00:01.500Z
```

**US-1.1.1-02**: í†µí™” ì¢…ë£Œ í›„ Complete Transcript ìƒì„±
```gherkin
As a: ê³ ê°ì„¼í„° ìš´ì˜ì
I want to: í†µí™” ì¢…ë£Œ í›„ ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë°›ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤
So that: í†µí™” ë‚´ìš©ì„ ë¦¬ë·°í•˜ê³  í’ˆì§ˆì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ê³¼ ìƒë‹´ì›ì˜ í†µí™”ê°€ ì¢…ë£Œë  ë•Œ
- When: BYE ë©”ì‹œì§€ê°€ ì „ì†¡ë˜ë©´
- Then: 5ì´ˆ ì´ë‚´ì— ì „ì²´ í†µí™” Transcriptê°€ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: TranscriptëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
  * Call-ID
  * í†µí™” ì‹œì‘/ì¢…ë£Œ ì‹œê°„
  * í†µí™” ê¸¸ì´
  * ë°œì‹ ì/ìˆ˜ì‹ ì ì •ë³´
  * íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ì „ì²´ ëŒ€í™” ë‚´ìš©
- And: íŒŒì¼ì€ recordings/{call_id}/transcript.txt ê²½ë¡œì— ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤

Example Transcript:
---
Call ID: abc123
Start Time: 2026-01-30T10:00:00Z
End Time: 2026-01-30T10:05:30Z
Duration: 330 seconds
Caller: 1003 (010-1234-5678)
Callee: 1004 (ìƒë‹´ì› ê¹€ì² ìˆ˜)

[00:01] [Caller] ì•ˆë…•í•˜ì„¸ìš”, ì£¼ë¬¸ ì¡°íšŒí•˜ë ¤ê³  í•©ë‹ˆë‹¤
[00:03] [Callee] ì•ˆë…•í•˜ì„¸ìš”. ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?
[00:06] [Caller] ì£¼ë¬¸ë²ˆí˜¸ëŠ” 2024-0130-001ì…ë‹ˆë‹¤
[00:10] [Callee] í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”
...
---
```

##### Technical Design

**Architecture**:
```
[SIP Call] â†’ [RTP Stream] â†’ [STT Pipeline]
                                  â†“
                         [Diarization Engine]
                                  â†“
                         [Transcript Builder]
                                  â†“
                    [File Storage (recordings/)]
```

**Components**:
1. **STT Processor**: Google Cloud Speech-to-Text (Streaming API)
2. **Diarization**: Google Speech Diarization (2 speakers)
3. **Transcript Builder**: Python asyncio-based processor
4. **Storage**: Local file system + S3 backup (optional)

**API Dependencies**:
- Google Cloud Speech-to-Text API v2
- ì¸ì¦: Service Account (gcp-key.json)
- Quota: 1,000 minutes/day (Free tier)

##### Testing Strategy

**Unit Tests**:
- [ ] STT íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
- [ ] Diarization ì •í™•ë„ í…ŒìŠ¤íŠ¸ (Ground Truth ë°ì´í„° ì‚¬ìš©)
- [ ] Transcript íŒŒì¼ ìƒì„± ë° ì €ì¥ í…ŒìŠ¤íŠ¸

**Integration Tests**:
- [ ] End-to-end í†µí™” â†’ Transcript ìƒì„± í…ŒìŠ¤íŠ¸
- [ ] ë™ì‹œ 100í†µí™” ì²˜ë¦¬ ë¶€í•˜ í…ŒìŠ¤íŠ¸
- [ ] STT ì„œë¹„ìŠ¤ ì¥ì•  ì‹œ Fallback í…ŒìŠ¤íŠ¸

**Performance Tests**:
- [ ] STT Latency ì¸¡ì • (target: <500ms)
- [ ] Throughput ì¸¡ì • (target: 100 concurrent calls)

##### Dependencies
- âœ… SIP PBX Core (ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ)
- âœ… RTP Relay (ì´ë¯¸ êµ¬í˜„ ì™„ë£Œ)
- â¬œ Google Cloud ê³„ì • ì„¤ì •
- â¬œ Service Account ê¶Œí•œ ì„¤ì •

---

#### Feature 1.1.2: í™”ì ë¶„ë¦¬ ë° ì—­í•  íƒœê¹…

**Feature ID**: `F1.1.2`  
**Priority**: P0 (Must Have)  
**Complexity**: Medium  
**Estimated Story Points**: 5

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-1.1.2-01 | í†µí™” ì¤‘ í™”ì ìë™ êµ¬ë¶„ (Caller vs. Callee) | âœ… Diarization ì •í™•ë„ > 95% |
| FR-1.1.2-02 | ì—­í•  ìë™ ë§¤í•‘ (ë°œì‹ ì â†’ Caller, ìˆ˜ì‹ ì â†’ Callee) | âœ… SIP í—¤ë”ì˜ From/To í•„ë“œ ê¸°ë°˜ ìë™ ë¶„ë¥˜ |
| FR-1.1.2-03 | ê° ë°œí™”(Utterance)ì— í™”ì ì •ë³´ íƒœê¹… | âœ… ëª¨ë“  í…ìŠ¤íŠ¸ì— [Caller] ë˜ëŠ” [Callee] íƒœê·¸ ì¶”ê°€ |
| FR-1.1.2-04 | 3ì í†µí™” ì§€ì› (Transfer ì‹œë‚˜ë¦¬ì˜¤) | âœ… Speaker 3 ì¶”ê°€ ì‹œ ìë™ ê°ì§€ ë° íƒœê¹… |

##### User Stories

**US-1.1.2-01**: í™”ì ìë™ êµ¬ë¶„
```gherkin
As a: AI ì‹œìŠ¤í…œ
I want to: í†µí™” ì¤‘ ëˆ„ê°€ ë§í•˜ê³  ìˆëŠ”ì§€ ìë™ìœ¼ë¡œ êµ¬ë¶„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: RAG ê²€ìƒ‰ ì‹œ "ê³ ê°ì´ ì§ˆë¬¸"ê³¼ "ìƒë‹´ì›ì´ ë‹µë³€"ì„ ì •í™•íˆ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ê³¼ ìƒë‹´ì›ì´ ëŒ€í™” ì¤‘ì¼ ë•Œ
- When: í™”ìê°€ ë°”ë€Œë©´
- Then: ì‹œìŠ¤í…œì€ ìë™ìœ¼ë¡œ í™”ìë¥¼ ì¸ì‹í•´ì•¼ í•©ë‹ˆë‹¤
- And: ê° ë°œí™”ì— [Caller] ë˜ëŠ” [Callee] íƒœê·¸ë¥¼ ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤
- And: í™”ì êµ¬ë¶„ ì •í™•ë„ëŠ” 95% ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Input Audio 1: "ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?"
  Output: [Caller] ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?
  
  Input Audio 2: "2ì¼ ì´ë‚´ì— ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤"
  Output: [Callee] 2ì¼ ì´ë‚´ì— ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤
```

##### Technical Design

**Diarization Flow**:
```python
# Google Speech Diarization ì„¤ì •
diarization_config = speech.SpeakerDiarizationConfig(
    enable_speaker_diarization=True,
    min_speaker_count=2,
    max_speaker_count=3  # Transfer ì§€ì›
)

# í™”ì ë§¤í•‘
speaker_map = {
    "speaker_0": "Caller",  # From SIP header
    "speaker_1": "Callee",  # To SIP header
    "speaker_2": "Agent_2"  # Transfer ì‹œ
}
```

---

### Epic 1.2: Vector Database í†µí•© ë° ì§€ì‹ ì €ì¥

#### Feature 1.2.1: Transcript â†’ Knowledge Extraction

**Feature ID**: `F1.2.1`  
**Priority**: P0 (Must Have)  
**Complexity**: High  
**Estimated Story Points**: 13

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-1.2.1-01 | Transcriptì—ì„œ Q&A ìŒ ìë™ ì¶”ì¶œ | âœ… LLM ê¸°ë°˜ ìë™ ì¶”ì¶œ (Gemini 2.5 Flash) |
| FR-1.2.1-02 | ì˜ë¯¸ ê¸°ë°˜ Chunking (Semantic Chunking) | âœ… ëŒ€í™” ë§¥ë½ ìœ ì§€í•˜ë©° 512 tokens ì´í•˜ë¡œ ë¶„í•  |
| FR-1.2.1-03 | ë©”íƒ€ë°ì´í„° ìë™ íƒœê¹… | âœ… ë¬¸ì˜ ìœ í˜•, ê°ì •, í•´ê²° ì—¬ë¶€ ìë™ ë¶„ë¥˜ |
| FR-1.2.1-04 | ì¤‘ë³µ ì œê±° (Deduplication) | âœ… Embedding ìœ ì‚¬ë„ > 0.95ì¸ ê²½ìš° ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬ |
| FR-1.2.1-05 | ì €í’ˆì§ˆ ë°ì´í„° í•„í„°ë§ | âœ… Transcript í’ˆì§ˆ ì ìˆ˜ < 0.6ì¸ ê²½ìš° ì œì™¸ |

##### User Stories

**US-1.2.1-01**: Q&A ìë™ ì¶”ì¶œ
```gherkin
As a: ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
I want to: í†µí™” Transcriptì—ì„œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: í–¥í›„ ìœ ì‚¬í•œ ì§ˆë¬¸ì— ë°”ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: í†µí™” Transcriptê°€ ìƒì„±ë˜ì—ˆì„ ë•Œ
- When: Knowledge Extraction íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ë˜ë©´
- Then: ì˜ë¯¸ìˆëŠ” Q&A ìŒì´ ì¶”ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ê° Q&AëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
  * Question (ê³ ê° ì§ˆë¬¸)
  * Answer (ìƒë‹´ì› ë‹µë³€)
  * Context (ëŒ€í™” ë§¥ë½)
  * Metadata (ë¬¸ì˜ ìœ í˜•, í•´ê²° ì—¬ë¶€)
- And: ì¶”ì¶œë¥ ì€ í†µí™”ë‹¹ í‰ê·  3ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Input Transcript:
    [Caller] ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?
    [Callee] ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?
    [Caller] 2024-0130-001ì…ë‹ˆë‹¤
    [Callee] í™•ì¸í•´ë³´ë‹ˆ ë‚´ì¼ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤
  
  Output Q&A:
    {
      "question": "ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?",
      "answer": "ì£¼ë¬¸ë²ˆí˜¸ 2024-0130-001 ê¸°ì¤€, ë‚´ì¼ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤",
      "context": "ë°°ì†¡ ì¡°íšŒ ë¬¸ì˜",
      "metadata": {
        "category": "delivery_inquiry",
        "resolved": true,
        "sentiment": "neutral"
      }
    }
```

##### Technical Design

**Knowledge Extraction Pipeline**:
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate

# 1. Semantic Chunking
splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,
    chunk_overlap=50,
    separators=["\n[Caller]", "\n[Callee]"]  # í™”ì ì „í™˜ ê¸°ì¤€
)

# 2. Q&A Extraction (LLM)
extraction_prompt = PromptTemplate(
    input_variables=["transcript"],
    template="""
    ë‹¤ìŒ í†µí™” Transcriptì—ì„œ ê³ ê°ì˜ ì§ˆë¬¸ê³¼ ìƒë‹´ì›ì˜ ë‹µë³€ì„ ì¶”ì¶œí•˜ì„¸ìš”.
    
    Transcript:
    {transcript}
    
    Output (JSON):
    {{
      "qa_pairs": [
        {{
          "question": "ê³ ê° ì§ˆë¬¸",
          "answer": "ìƒë‹´ì› ë‹µë³€",
          "category": "ë¬¸ì˜ ìœ í˜•",
          "resolved": true/false
        }}
      ]
    }}
    """
)

# 3. Metadata Tagging
categories = ["ë°°ì†¡", "í™˜ë¶ˆ", "êµí™˜", "ìƒí’ˆë¬¸ì˜", "ê¸°íƒ€"]
sentiment_analyzer = pipeline("sentiment-analysis", model="beomi/KcBERT")
```

---

#### Feature 1.2.2: Vector Database ì €ì¥

**Feature ID**: `F1.2.2`  
**Priority**: P0 (Must Have)  
**Complexity**: Medium  
**Estimated Story Points**: 8

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-1.2.2-01 | Embedding ìƒì„± (OpenAI text-embedding-3-large) | âœ… Embedding dimension: 3072 |
| FR-1.2.2-02 | Vector DBì— ìë™ ì €ì¥ (Pinecone or Qdrant) | âœ… ì €ì¥ ì„±ê³µë¥  > 99.9% |
| FR-1.2.2-03 | ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥ | âœ… Call-ID, ë‚ ì§œ, ì¹´í…Œê³ ë¦¬, ê°ì • ë“± í¬í•¨ |
| FR-1.2.2-04 | ì¸ë±ìŠ¤ ìë™ ì—…ë°ì´íŠ¸ | âœ… ì €ì¥ í›„ 3ì´ˆ ì´ë‚´ ê²€ìƒ‰ ê°€ëŠ¥ |
| FR-1.2.2-05 | Backup ë° ë³µêµ¬ ê¸°ëŠ¥ | âœ… ì¼ì¼ ìë™ ë°±ì—…, PITR ì§€ì› |

##### User Stories

**US-1.2.2-01**: ì§€ì‹ ìë™ ì €ì¥
```gherkin
As a: ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
I want to: ì¶”ì¶œí•œ Q&Aë¥¼ Vector Databaseì— ìë™ìœ¼ë¡œ ì €ì¥í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: AIê°€ ìœ ì‚¬í•œ ì§ˆë¬¸ì— ë¹ ë¥´ê²Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: Q&Aê°€ ì¶”ì¶œë˜ì—ˆì„ ë•Œ
- When: Vector DB ì €ì¥ í”„ë¡œì„¸ìŠ¤ê°€ ì‹¤í–‰ë˜ë©´
- Then: ê° Q&AëŠ” Embeddingìœ¼ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: Vector DBì— ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ë©”íƒ€ë°ì´í„°ê°€ í•¨ê»˜ ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ì €ì¥ í›„ 3ì´ˆ ì´ë‚´ì— ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤

Example:
  Input Q&A:
    question: "ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?"
    answer: "ì£¼ë¬¸ë²ˆí˜¸ ê¸°ì¤€, 2ì¼ ì´ë‚´ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤"
  
  Process:
    1. Embedding ìƒì„±: [0.123, -0.456, ..., 0.789] (3072 dim)
    2. Metadata ì¤€ë¹„:
       {
         "call_id": "abc123",
         "date": "2026-01-30",
         "category": "delivery",
         "resolved": true
       }
    3. Vector DB ì €ì¥: Pinecone.upsert(...)
  
  Result:
    âœ… Stored in Pinecone namespace: "knowledge-base"
    âœ… Index updated
    âœ… Searchable in 3 seconds
```

##### Technical Design

**Vector DB Selection**:
| Criteria | Pinecone | Qdrant | Decision |
|----------|----------|--------|----------|
| Performance | â­â­â­â­â­ | â­â­â­â­ | Pinecone |
| Cost | $70/month | Free (self-hosted) | Qdrant (ì´ˆê¸°) |
| Scalability | Managed | Self-managed | Pinecone (ì¥ê¸°) |
| **Decision** | - | âœ… | **Qdrant (Phase 1), Pinecone (Phase 2+)** |

**Implementation**:
```python
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct

# Qdrant Client ì´ˆê¸°í™”
client = QdrantClient(host="localhost", port=6333)

# Collection ìƒì„± (ì´ˆê¸° 1íšŒ)
client.create_collection(
    collection_name="knowledge_base",
    vectors_config=VectorParams(size=3072, distance=Distance.COSINE)
)

# Vector ì €ì¥
def store_qa_pair(qa: dict, embedding: list):
    point = PointStruct(
        id=qa["id"],
        vector=embedding,
        payload={
            "question": qa["question"],
            "answer": qa["answer"],
            "call_id": qa["call_id"],
            "date": qa["date"],
            "category": qa["category"],
            "resolved": qa["resolved"]
        }
    )
    client.upsert(collection_name="knowledge_base", points=[point])
```

---

### Epic 1.3: RAG Retrieval ì—”ì§„

#### Feature 1.3.1: Semantic Search

**Feature ID**: `F1.3.1`  
**Priority**: P0 (Must Have)  
**Complexity**: High  
**Estimated Story Points**: 13

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-1.3.1-01 | ê³ ê° ì§ˆë¬¸ì„ Embeddingìœ¼ë¡œ ë³€í™˜ | âœ… ë³€í™˜ ì‹œê°„ < 200ms |
| FR-1.3.1-02 | Vector DBì—ì„œ Top-K ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ | âœ… K=5, ê²€ìƒ‰ ì‹œê°„ < 100ms |
| FR-1.3.1-03 | Reranking (ì¬ìˆœìœ„í™”) | âœ… Cohere Rerank or Cross-encoder ì‚¬ìš© |
| FR-1.3.1-04 | Confidence Score ê³„ì‚° | âœ… Similarity score > 0.7ì´ë©´ "High confidence" |
| FR-1.3.1-05 | ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ì‹œ Fallback | âœ… "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" ë°˜í™˜ |

##### User Stories

**US-1.3.1-01**: ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
```gherkin
As a: AI ì‹œìŠ¤í…œ
I want to: ê³ ê°ì˜ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ê³¼ê±° Q&Aë¥¼ ì°¾ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ "ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?"ë¼ê³  ì§ˆë¬¸í•  ë•Œ
- When: RAG Retrieval ì—”ì§„ì´ ì‹¤í–‰ë˜ë©´
- Then: Vector DBì—ì„œ ìœ ì‚¬í•œ ì§ˆë¬¸ë“¤ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤
- And: Top 5 ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤
- And: ê° ê²°ê³¼ëŠ” ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- And: ì´ ì²˜ë¦¬ ì‹œê°„ì€ 300ms ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤

Example:
  Input Query: "ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?"
  
  Process:
    1. Query Embedding: [0.111, -0.222, ..., 0.333]
    2. Vector Search (Top 5):
       - Result 1: "ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?" (similarity: 0.95)
       - Result 2: "ì£¼ë¬¸í•œ ìƒí’ˆ ì–¸ì œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?" (similarity: 0.92)
       - Result 3: "ë°°ì†¡ ì˜ˆì •ì¼ ì•Œë ¤ì£¼ì„¸ìš”" (similarity: 0.88)
       - Result 4: "ë°°ì†¡ ì¡°íšŒí•˜ê³  ì‹¶ì–´ìš”" (similarity: 0.75)
       - Result 5: "ë°°ì†¡ ìƒíƒœ í™•ì¸ ë°©ë²•" (similarity: 0.72)
    3. Reranking (optional)
    4. Return Top 3 with answers
  
  Output:
    [
      {
        "question": "ë°°ì†¡ì€ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?",
        "answer": "ì£¼ë¬¸ë²ˆí˜¸ ê¸°ì¤€, 2ì¼ ì´ë‚´ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤",
        "confidence": 0.95,
        "source_call_id": "xyz789"
      },
      ...
    ]
  
  Performance:
    - Embedding: 150ms
    - Vector Search: 80ms
    - Reranking: 50ms
    - Total: 280ms âœ…
```

##### Technical Design

**RAG Pipeline**:
```python
from langchain.embeddings import OpenAIEmbeddings
from qdrant_client import QdrantClient

class RAGRetriever:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        self.vector_db = QdrantClient(host="localhost", port=6333)
    
    async def search(self, query: str, top_k: int = 5):
        # 1. Query Embedding
        query_vector = await self.embeddings.aembed_query(query)
        
        # 2. Vector Search
        results = self.vector_db.search(
            collection_name="knowledge_base",
            query_vector=query_vector,
            limit=top_k,
            score_threshold=0.7  # ìµœì†Œ ìœ ì‚¬ë„
        )
        
        # 3. Confidence Score ê³„ì‚°
        scored_results = []
        for result in results:
            confidence = self._calculate_confidence(result.score)
            scored_results.append({
                "question": result.payload["question"],
                "answer": result.payload["answer"],
                "confidence": confidence,
                "metadata": result.payload
            })
        
        return scored_results
    
    def _calculate_confidence(self, similarity: float) -> float:
        """
        Confidence mapping:
        - similarity > 0.9: High (90-100%)
        - similarity 0.7-0.9: Medium (70-90%)
        - similarity < 0.7: Low (<70%)
        """
        return min(similarity * 100, 100)
```

---

## Phase 2: AI ê¸°ë°˜ Dynamic ARS

### Epic 2.1: Natural Language IVR

#### Feature 2.1.1: Intent Classification

**Feature ID**: `F2.1.1`  
**Priority**: P0 (Must Have)  
**Complexity**: High  
**Estimated Story Points**: 13

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-2.1.1-01 | ê³ ê° ë°œí™”ì—ì„œ Intent ìë™ ì¶”ì¶œ | âœ… LLM ê¸°ë°˜ ë¶„ë¥˜ (Gemini 2.5 Flash) |
| FR-2.1.1-02 | ì£¼ìš” Intent ì§€ì› | âœ… ë°°ì†¡ ì¡°íšŒ, í™˜ë¶ˆ, êµí™˜, ìƒí’ˆ ë¬¸ì˜, ìƒë‹´ì› ì—°ê²° ë“± |
| FR-2.1.1-03 | Multi-intent ì§€ì› | âœ… "í™˜ë¶ˆí•˜ê³  ì¬ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”" â†’ [í™˜ë¶ˆ, ì£¼ë¬¸] 2ê°œ Intent |
| FR-2.1.1-04 | Intent Confidence Score | âœ… ì ìˆ˜ < 0.7ì´ë©´ í™•ì¸ ì§ˆë¬¸ ("~í•˜ì‹œëŠ” ê±´ê°€ìš”?") |
| FR-2.1.1-05 | Fallback Intent | âœ… ì´í•´ ëª»í•  ì‹œ "ìƒë‹´ì› ì—°ê²°" Intentë¡œ ì „í™˜ |

##### User Stories

**US-2.1.1-01**: ê³ ê° ì˜ë„ ìë™ íŒŒì•…
```gherkin
As a: AI IVR ì‹œìŠ¤í…œ
I want to: ê³ ê°ì´ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ ìë™ìœ¼ë¡œ íŒŒì•…í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ì—°ê²°í•˜ê±°ë‚˜ ì§ì ‘ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ ìì—°ì–´ë¡œ ë§í•  ë•Œ (ì˜ˆ: "ë°°ì†¡ ì¡°íšŒí•˜ê³  ì‹¶ì–´ìš”")
- When: Intent Classificationì´ ì‹¤í–‰ë˜ë©´
- Then: ê³ ê°ì˜ ì˜ë„ë¥¼ ì •í™•íˆ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤
- And: Confidence Scoreë¥¼ í•¨ê»˜ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤
- And: ì²˜ë¦¬ ì‹œê°„ì€ 500ms ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤

Example 1 - Single Intent:
  Input: "ë°°ì†¡ ì¡°íšŒí•˜ê³  ì‹¶ì–´ìš”"
  Output:
    {
      "intents": ["delivery_tracking"],
      "confidence": 0.95,
      "next_action": "ask_order_number"
    }

Example 2 - Multi Intent:
  Input: "í™˜ë¶ˆí•˜ê³  ì¬ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”"
  Output:
    {
      "intents": ["refund", "reorder"],
      "confidence": 0.88,
      "next_action": "clarify_priority"  # ìš°ì„ ìˆœìœ„ í™•ì¸
    }

Example 3 - Low Confidence:
  Input: "ê·¸ê±° ìˆì–ì•„ìš”, ê·¸ê±°..."
  Output:
    {
      "intents": ["unknown"],
      "confidence": 0.35,
      "next_action": "clarification_question"  # "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    }
```

##### Technical Design

**Intent Classification Pipeline**:
```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate

# LLM ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.3,  # ì¼ê´€ì„± ì¤‘ì‹œ
    max_output_tokens=150
)

# Intent Classification Prompt
intent_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ê³ ê° ì„¼í„° IVR ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ê³ ê°ì˜ ë°œí™”ì—ì„œ ì˜ë„(Intent)ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.

ê°€ëŠ¥í•œ Intent:
- delivery_tracking: ë°°ì†¡ ì¡°íšŒ
- refund: í™˜ë¶ˆ
- exchange: êµí™˜
- product_inquiry: ìƒí’ˆ ë¬¸ì˜
- order_status: ì£¼ë¬¸ ìƒíƒœ í™•ì¸
- agent_request: ìƒë‹´ì› ì—°ê²° ìš”ì²­
- unknown: ì•Œ ìˆ˜ ì—†ìŒ

ê³ ê° ë°œí™”: {user_input}

Output (JSON):
{{
  "intents": ["intent1", "intent2"],  # ë‹¤ì¤‘ ê°€ëŠ¥
  "confidence": 0.0~1.0,
  "reasoning": "ë¶„ë¥˜ ì´ìœ "
}}
""")

# Intent Classification í•¨ìˆ˜
async def classify_intent(user_input: str):
    response = await llm.ainvoke(intent_prompt.format(user_input=user_input))
    intent_data = json.loads(response.content)
    return intent_data
```

---

#### Feature 2.1.2: Context-aware Dialog Management

**Feature ID**: `F2.1.2`  
**Priority**: P0 (Must Have)  
**Complexity**: High  
**Estimated Story Points**: 21

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-2.1.2-01 | ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ (ìµœëŒ€ 10í„´) | âœ… ì´ì „ ë°œí™” ê¸°ì–µí•˜ê³  ì°¸ì¡° |
| FR-2.1.2-02 | Slot Filling (í•„ìš”í•œ ì •ë³´ ìˆ˜ì§‘) | âœ… ì£¼ë¬¸ë²ˆí˜¸, ì´ë¦„, ì „í™”ë²ˆí˜¸ ë“± ìë™ ìˆ˜ì§‘ |
| FR-2.1.2-03 | Dynamic Flow (ìƒí™©ì— ë”°ë¼ ë‹¤ìŒ ì§ˆë¬¸ ë³€ê²½) | âœ… "ì£¼ë¬¸ë²ˆí˜¸ ëª¨ë¦„" â†’ "ì´ë¦„ê³¼ ì „í™”ë²ˆí˜¸ë¡œ ì°¾ê¸°" |
| FR-2.1.2-04 | Error Recovery (ì˜¤ì¸ì‹ ì‹œ ì¬í™•ì¸) | âœ… "1234ë¼ê³  í•˜ì…¨ë‚˜ìš”?" í™•ì¸ ì§ˆë¬¸ |
| FR-2.1.2-05 | Early Exit (ì–¸ì œë“  ìƒë‹´ì› ì—°ê²°) | âœ… "ìƒë‹´ì›" í‚¤ì›Œë“œ ê°ì§€ ì‹œ ì¦‰ì‹œ ì „í™˜ |

##### User Stories

**US-2.1.2-01**: ë¬¸ë§¥ ì´í•´ ëŒ€í™”
```gherkin
As a: ê³ ê°
I want to: AIê°€ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤
So that: ë§¤ë²ˆ ì²˜ìŒë¶€í„° ì„¤ëª…í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ "ë°°ì†¡ ì¡°íšŒí•˜ê³  ì‹¶ì–´ìš”"ë¼ê³  ë§í•œ í›„
- When: AIê°€ "ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì„¸ìš”"ë¼ê³  ë¬»ê³ 
- And: ê³ ê°ì´ "1234"ë¼ê³  ë‹µí•˜ë©´
- Then: AIëŠ” ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  "1234ë²ˆ ì£¼ë¬¸ í™•ì¸í•´ë“œë¦´ê²Œìš”"ë¼ê³  ë‹µí•´ì•¼ í•©ë‹ˆë‹¤
- And: ê³ ê°ì´ "ê·¸ê±° ì–¸ì œ ë„ì°©í•´?"ë¼ê³  ë¬¼ìœ¼ë©´
- Then: AIëŠ” "ê·¸ê±° = 1234ë²ˆ ì£¼ë¬¸"ì„ì„ ì´í•´í•˜ê³  ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤

Example Dialog:
  Turn 1:
    Customer: "ë°°ì†¡ ì¡°íšŒí•˜ê³  ì‹¶ì–´ìš”"
    AI: "ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
    Context: {intent: "delivery_tracking", slots: {}}
  
  Turn 2:
    Customer: "2024-0130-001ì´ìš”"
    AI: "2024-0130-001ë²ˆ ì£¼ë¬¸ í™•ì¸í•´ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"
    Context: {intent: "delivery_tracking", slots: {order_number: "2024-0130-001"}}
  
  Turn 3:
    Customer: "ì–¸ì œ ë„ì°©í•´ìš”?"
    AI: (Context ì°¸ì¡°) "2024-0130-001ë²ˆ ì£¼ë¬¸ì€ ë‚´ì¼ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤"
    Context: {intent: "delivery_tracking", slots: {order_number: "2024-0130-001"}}
```

**US-2.1.2-02**: í•„ìš”í•œ ì •ë³´ ìë™ ìˆ˜ì§‘
```gherkin
As a: AI IVR ì‹œìŠ¤í…œ
I want to: ê³ ê°ì—ê²Œ í•„ìš”í•œ ì •ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ ë¬¼ì–´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ì™„ì „í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"ë¼ê³  ë§í•  ë•Œ
- When: Slot Fillingì´ ì‹œì‘ë˜ë©´
- Then: í•„ìš”í•œ ì •ë³´ë¥¼ í•˜ë‚˜ì”© ë¬¼ì–´ë´ì•¼ í•©ë‹ˆë‹¤:
  * Step 1: ì£¼ë¬¸ë²ˆí˜¸
  * Step 2: í™˜ë¶ˆ ì‚¬ìœ 
  * Step 3: í™˜ë¶ˆ ë°©ë²• (ê³„ì¢Œ or ì¹´ë“œ)
- And: ì´ë¯¸ ì œê³µëœ ì •ë³´ëŠ” ë‹¤ì‹œ ë¬»ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤
- And: ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ í™˜ë¶ˆ í”„ë¡œì„¸ìŠ¤ ì‹œì‘

Example:
  Required Slots: [order_number, reason, refund_method]
  
  Turn 1:
    Customer: "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"
    AI: "ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
    Slots: {}
  
  Turn 2:
    Customer: "2024-0130-001ì´ìš”. ìƒí’ˆì´ íŒŒì†ë˜ì–´ì„œìš”"
    AI: (2ê°œ slot ë™ì‹œ ìˆ˜ì§‘) "í™˜ë¶ˆ ë°©ë²•ì€ ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”? ê³„ì¢Œ ì…ê¸ˆ ë˜ëŠ” ì¹´ë“œ ì·¨ì†Œ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”"
    Slots: {order_number: "2024-0130-001", reason: "íŒŒì†"}
  
  Turn 3:
    Customer: "ê³„ì¢Œë¡œ ë¶€íƒë“œë ¤ìš”"
    AI: "í™˜ë¶ˆ ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 3-5 ì˜ì—…ì¼ ë‚´ ì…ê¸ˆ ì˜ˆì •ì…ë‹ˆë‹¤"
    Slots: {order_number: "2024-0130-001", reason: "íŒŒì†", refund_method: "ê³„ì¢Œ"}
    Action: submit_refund_request()
```

##### Technical Design

**Dialog State Management**:
```python
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class DialogContext:
    session_id: str
    intent: str
    slots: Dict[str, any]  # ìˆ˜ì§‘ëœ ì •ë³´
    required_slots: List[str]  # í•„ìš”í•œ ì •ë³´
    turn_count: int
    history: List[Dict]  # ëŒ€í™” ì´ë ¥
    
    def is_complete(self) -> bool:
        """ëª¨ë“  í•„ìˆ˜ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return all(slot in self.slots for slot in self.required_slots)
    
    def next_slot(self) -> str:
        """ë‹¤ìŒì— ë¬¼ì–´ë³¼ ì •ë³´"""
        for slot in self.required_slots:
            if slot not in self.slots:
                return slot
        return None

# Slot Definitions (Intentë³„)
SLOT_CONFIGS = {
    "delivery_tracking": {
        "required": ["order_number"],
        "optional": []
    },
    "refund": {
        "required": ["order_number", "reason", "refund_method"],
        "optional": ["account_number"]
    },
    "exchange": {
        "required": ["order_number", "reason", "new_product"],
        "optional": []
    }
}

# Dialog Manager
class DialogManager:
    def __init__(self):
        self.contexts: Dict[str, DialogContext] = {}
    
    async def process_turn(self, session_id: str, user_input: str):
        context = self.contexts.get(session_id)
        if not context:
            # ìƒˆ ëŒ€í™” ì‹œì‘
            intent = await classify_intent(user_input)
            context = self._create_context(session_id, intent)
        
        # Slot ì¶”ì¶œ
        extracted_slots = await self._extract_slots(user_input, context)
        context.slots.update(extracted_slots)
        context.turn_count += 1
        
        # ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
        if context.is_complete():
            response = await self._execute_action(context)
        else:
            next_slot = context.next_slot()
            response = await self._ask_for_slot(next_slot)
        
        # ëŒ€í™” ì´ë ¥ ì €ì¥
        context.history.append({
            "turn": context.turn_count,
            "user": user_input,
            "ai": response
        })
        
        return response
```

---

#### Feature 2.1.3: Tool Calling Integration

**Feature ID**: `F2.1.3`  
**Priority**: P1 (Should Have)  
**Complexity**: High  
**Estimated Story Points**: 13

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-2.1.3-01 | CRM API í†µí•© (ê³ ê° ì •ë³´ ì¡°íšŒ) | âœ… ì£¼ë¬¸ë²ˆí˜¸ë¡œ ì£¼ë¬¸ ì •ë³´ ì¡°íšŒ ê°€ëŠ¥ |
| FR-2.1.3-02 | ERP API í†µí•© (ì¬ê³ /ë°°ì†¡ ì •ë³´) | âœ… ì‹¤ì‹œê°„ ë°°ì†¡ ìƒíƒœ ì¡°íšŒ ê°€ëŠ¥ |
| FR-2.1.3-03 | Tool Registry ê´€ë¦¬ | âœ… ìƒˆ Tool ë™ì  ì¶”ê°€ ê°€ëŠ¥ |
| FR-2.1.3-04 | ê¶Œí•œ ê´€ë¦¬ | âœ… Toolë³„ ì½ê¸°/ì“°ê¸° ê¶Œí•œ ì„¤ì • |
| FR-2.1.3-05 | Error Handling | âœ… API ì¥ì•  ì‹œ Fallback ì‘ë‹µ |

##### User Stories

**US-2.1.3-01**: ì‹¤ì‹œê°„ ì •ë³´ ì¡°íšŒ
```gherkin
As a: AI IVR ì‹œìŠ¤í…œ
I want to: ì™¸ë¶€ ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ê³ ê°ì—ê²Œ ì •í™•í•œ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ "ë°°ì†¡ ìƒíƒœ ì•Œë ¤ì£¼ì„¸ìš”"ë¼ê³  ìš”ì²­í•  ë•Œ
- When: ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ìˆ˜ì§‘í•œ í›„
- Then: ERP APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì‹œê°„ ë°°ì†¡ ìƒíƒœë¥¼ ì¡°íšŒí•´ì•¼ í•©ë‹ˆë‹¤
- And: ì¡°íšŒ ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤
- And: API í˜¸ì¶œ ì‹œê°„ì€ 2ì´ˆ ì´ë‚´ì—¬ì•¼ í•©ë‹ˆë‹¤

Example:
  Customer: "ë°°ì†¡ ìƒíƒœ ì•Œë ¤ì£¼ì„¸ìš”"
  AI: "ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
  Customer: "2024-0130-001"
  AI: (Tool Call: get_delivery_status("2024-0130-001"))
      â†’ API Response: {
          "status": "in_transit",
          "location": "ì„œìš¸ ê°•ë‚¨êµ¬",
          "estimated_arrival": "2026-01-31"
        }
      â†’ "ì£¼ë¬¸ë²ˆí˜¸ 2024-0130-001ì€ í˜„ì¬ ì„œìš¸ ê°•ë‚¨êµ¬ì— ìˆìœ¼ë©°, ë‚´ì¼ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤"

Performance:
  - Intent Classification: 300ms
  - Slot Filling: 200ms
  - API Call: 1,500ms
  - Response Generation: 500ms
  - Total: 2,500ms âœ…
```

##### Technical Design

**Tool Registry**:
```python
from typing import Callable, Dict, Any
from pydantic import BaseModel

class Tool(BaseModel):
    name: str
    description: str
    parameters: Dict[str, Any]
    permission: str  # "read" or "write"
    function: Callable

# Tool Definitions
tools = [
    Tool(
        name="get_order_info",
        description="ì£¼ë¬¸ë²ˆí˜¸ë¡œ ì£¼ë¬¸ ì •ë³´ ì¡°íšŒ",
        parameters={
            "order_number": {
                "type": "string",
                "description": "ì£¼ë¬¸ë²ˆí˜¸ (ì˜ˆ: 2024-0130-001)"
            }
        },
        permission="read",
        function=lambda order_number: crm_api.get_order(order_number)
    ),
    Tool(
        name="get_delivery_status",
        description="ë°°ì†¡ ìƒíƒœ ì‹¤ì‹œê°„ ì¡°íšŒ",
        parameters={
            "order_number": {
                "type": "string"
            }
        },
        permission="read",
        function=lambda order_number: erp_api.get_delivery_status(order_number)
    ),
    Tool(
        name="submit_refund",
        description="í™˜ë¶ˆ ì‹ ì²­",
        parameters={
            "order_number": {"type": "string"},
            "reason": {"type": "string"},
            "refund_method": {"type": "string", "enum": ["ê³„ì¢Œ", "ì¹´ë“œ"]}
        },
        permission="write",  # ì“°ê¸° ê¶Œí•œ í•„ìš”
        function=lambda **kwargs: crm_api.submit_refund(**kwargs)
    )
]

# LLM Tool Calling (Gemini Function Calling)
from langchain.agents import create_tool_calling_agent

agent = create_tool_calling_agent(
    llm=llm,
    tools=tools,
    prompt=agent_prompt
)

# Usage
response = await agent.ainvoke({
    "input": "ì£¼ë¬¸ë²ˆí˜¸ 2024-0130-001 ë°°ì†¡ ìƒíƒœ ì•Œë ¤ì¤˜"
})
```

---

### Epic 2.2: ìš´ì˜ì Dashboard - ARS Flow ê´€ë¦¬

#### Feature 2.2.1: Visual Flow Editor

**Feature ID**: `F2.2.1`  
**Priority**: P1 (Should Have)  
**Complexity**: High  
**Estimated Story Points**: 21

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-2.2.1-01 | ë“œë˜ê·¸ì•¤ë“œë¡­ Flow Builder | âœ… React Flow ê¸°ë°˜ ì‹œê°ì  í¸ì§‘ê¸° |
| FR-2.2.1-02 | Node íƒ€ì… ì§€ì› | âœ… Intent, Slot, Tool, Response ë…¸ë“œ ì œê³µ |
| FR-2.2.1-03 | Condition ë¶„ê¸° | âœ… IF-ELSE ë¡œì§ ì§€ì› |
| FR-2.2.1-04 | Flow ê²€ì¦ | âœ… ì €ì¥ ì „ ë¬¸ë²• ì˜¤ë¥˜ ì²´í¬ |
| FR-2.2.1-05 | ë²„ì „ ê´€ë¦¬ | âœ… ì´ì „ ë²„ì „ ë¡¤ë°± ê°€ëŠ¥ |

##### User Stories

**US-2.2.1-01**: ë¹„ê°œë°œìë„ ARS ìˆ˜ì • ê°€ëŠ¥
```gherkin
As a: ê³ ê°ì„¼í„° ìš´ì˜ì
I want to: ê°œë°œì ë„ì›€ ì—†ì´ ì§ì ‘ ARS Flowë¥¼ ìˆ˜ì •í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ë¹ ë¥´ê²Œ ë¹„ì¦ˆë‹ˆìŠ¤ ë³€í™”ì— ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ìš´ì˜ìê°€ Dashboardì— ë¡œê·¸ì¸í•  ë•Œ
- When: "ARS Flow í¸ì§‘" ë©”ë‰´ë¥¼ í´ë¦­í•˜ë©´
- Then: ì‹œê°ì  Flow Editorê°€ ì—´ë ¤ì•¼ í•©ë‹ˆë‹¤
- And: ê¸°ì¡´ Flowê°€ ê·¸ë˜í”„ë¡œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ë…¸ë“œë¥¼ ë“œë˜ê·¸ì•¤ë“œë¡­ìœ¼ë¡œ ì¶”ê°€/ì‚­ì œ/ì—°ê²°í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- And: ì €ì¥ ë²„íŠ¼ í´ë¦­ ì‹œ ì¦‰ì‹œ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (ë°°í¬ ì‹œê°„ < 5ë¶„)

Example Scenario:
  Task: "ë°°ì†¡ ì¡°íšŒ" Flowì— "ë°°ì†¡ì§€ ë³€ê²½" ì˜µì…˜ ì¶”ê°€
  
  Steps:
    1. "ë°°ì†¡ ì¡°íšŒ" Flow ì—´ê¸°
    2. "ë°°ì†¡ ìƒíƒœ í™•ì¸" ë…¸ë“œ ì„ íƒ
    3. ìƒˆ ë…¸ë“œ ì¶”ê°€: "ë°°ì†¡ì§€ ë³€ê²½í•˜ì‹œê² ì–´ìš”?" (Response ë…¸ë“œ)
    4. ë¶„ê¸° ì¶”ê°€:
       - Yes â†’ "ìƒˆ ë°°ì†¡ì§€ ì…ë ¥í•´ì£¼ì„¸ìš”" (Slot ë…¸ë“œ)
       - No â†’ "ê°ì‚¬í•©ë‹ˆë‹¤" (Response ë…¸ë“œ)
    5. "ì €ì¥" ë²„íŠ¼ í´ë¦­
    6. ìë™ ë°°í¬ (5ë¶„ ì´ë‚´)
  
  Result:
    âœ… ë‹¤ìŒ í†µí™”ë¶€í„° ìƒˆ Flow ì ìš©
    âœ… ê°œë°œì ê°œì… ì—†ìŒ
    âœ… ë³€ê²½ ì´ë ¥ ìë™ ì €ì¥
```

##### Technical Design

**Frontend**:
- Framework: React 18 + TypeScript
- Flow Editor: React Flow (https://reactflow.dev/)
- State Management: Zustand
- UI Library: Material-UI

**Backend API**:
```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/api/flows")

class FlowDefinition(BaseModel):
    id: str
    name: str
    version: int
    nodes: List[Dict]
    edges: List[Dict]
    created_by: str
    created_at: datetime

@router.get("/flows")
async def list_flows():
    """ëª¨ë“  Flow ëª©ë¡"""
    return await flow_repository.get_all()

@router.get("/flows/{flow_id}")
async def get_flow(flow_id: str):
    """íŠ¹ì • Flow ì¡°íšŒ"""
    flow = await flow_repository.get_by_id(flow_id)
    if not flow:
        raise HTTPException(status_code=404)
    return flow

@router.post("/flows")
async def create_flow(flow: FlowDefinition):
    """ìƒˆ Flow ìƒì„±"""
    # Validation
    validate_flow(flow)
    # Save
    await flow_repository.create(flow)
    # Deploy
    await deploy_flow(flow)
    return {"id": flow.id, "status": "deployed"}

@router.put("/flows/{flow_id}")
async def update_flow(flow_id: str, flow: FlowDefinition):
    """Flow ì—…ë°ì´íŠ¸"""
    # Versioning
    flow.version += 1
    await flow_repository.update(flow_id, flow)
    await deploy_flow(flow)
    return {"id": flow_id, "version": flow.version}
```

---

## Phase 3: HITL + Shadowing Mode

### Epic 3.1: Real-time Feedback Loop

#### Feature 3.1.1: Confidence Monitoring

**Feature ID**: `F3.1.1`  
**Priority**: P0 (Must Have)  
**Complexity**: Medium  
**Estimated Story Points**: 8

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-3.1.1-01 | AI ë‹µë³€ë§ˆë‹¤ Confidence Score ê³„ì‚° | âœ… 0-100% ë²”ìœ„, ì‹¤ì‹œê°„ ê³„ì‚° |
| FR-3.1.1-02 | Low Confidence ê°ì§€ (<60%) | âœ… ê°ì§€ ì‹œ ì¦‰ì‹œ ìš´ì˜ìì—ê²Œ ì•Œë¦¼ |
| FR-3.1.1-03 | Confidence ê¸°ì¤€ ë™ì  ì¡°ì • | âœ… ìš´ì˜ìê°€ Threshold ì„¤ì • ê°€ëŠ¥ |
| FR-3.1.1-04 | Confidence ë¡œê·¸ ì €ì¥ | âœ… ëª¨ë“  ë‹µë³€ì˜ Confidence ê¸°ë¡ |

##### User Stories

**US-3.1.1-01**: AI ì‹ ë¢°ë„ ëª¨ë‹ˆí„°ë§
```gherkin
As a: ìš´ì˜ì
I want to: AIê°€ ë‹µë³€í•  ë•Œë§ˆë‹¤ ì‹ ë¢°ë„ë¥¼ í™•ì¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ì˜ëª»ëœ ë‹µë³€ì„ ì‚¬ì „ì— ì°¨ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: AIê°€ ê³ ê° ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ
- When: Confidence Scoreê°€ ê³„ì‚°ë˜ë©´
- Then: ì ìˆ˜ê°€ Dashboardì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ì ìˆ˜ê°€ 60% ë¯¸ë§Œì´ë©´ ê²½ê³  ì•Œë¦¼ì´ ë– ì•¼ í•©ë‹ˆë‹¤
- And: ìš´ì˜ìê°€ ê°œì… ì—¬ë¶€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Scenario: ê³ ê°ì´ "ì´ê±° ì–¸ì œ ì™€ìš”?"ë¼ê³  ì§ˆë¬¸
  
  AI Processing:
    1. RAG Retrieval: ìœ ì‚¬ ì§ˆë¬¸ ì°¾ê¸°
       - Result 1: "ë°°ì†¡ ì–¸ì œ ì˜¤ë‚˜ìš”?" (similarity: 0.68)
       - Result 2: "ì£¼ë¬¸í•œ ê±° ì–¸ì œ ì™€ìš”?" (similarity: 0.65)
    2. Confidence Calculation:
       - RAG Score: 0.68 (Medium)
       - Query Clarity: 0.45 (Low - "ì´ê±°"ê°€ ë¶ˆëª…í™•)
       - **Total Confidence: 56%** âš ï¸ Low
    3. Action: ìš´ì˜ìì—ê²Œ ì•Œë¦¼ ì „ì†¡
  
  Dashboard Alert:
    âš ï¸ Low Confidence Detected (56%)
    Call ID: abc123
    Customer: "ì´ê±° ì–¸ì œ ì™€ìš”?"
    AI Answer: "ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
    
    [ê°œì…í•˜ê¸°] [ë¬´ì‹œí•˜ê¸°]
```

##### Technical Design

**Confidence Score Calculation**:
```python
class ConfidenceCalculator:
    def calculate(self, query: str, rag_results: List, llm_response: str) -> float:
        """
        ì¢…í•© Confidence Score ê³„ì‚°
        
        Components:
        1. RAG Retrieval Score (40%)
        2. Query Clarity Score (30%)
        3. LLM Certainty Score (30%)
        """
        rag_score = self._rag_score(rag_results)
        clarity_score = self._query_clarity(query)
        llm_score = self._llm_certainty(llm_response)
        
        confidence = (
            rag_score * 0.4 +
            clarity_score * 0.3 +
            llm_score * 0.3
        )
        
        return min(confidence * 100, 100)
    
    def _rag_score(self, results: List) -> float:
        """RAG ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ"""
        if not results:
            return 0.0
        # Top 1 ê²°ê³¼ì˜ ìœ ì‚¬ë„
        return results[0]["similarity"]
    
    def _query_clarity(self, query: str) -> float:
        """ì§ˆë¬¸ ëª…í™•ì„± (ëŒ€ëª…ì‚¬, ë¶ˆì™„ì „í•œ ë¬¸ì¥ ê°ì§€)"""
        unclear_words = ["ì´ê±°", "ê·¸ê±°", "ì €ê±°", "ë­", "ì–´", "ìŒ"]
        unclear_count = sum(1 for word in unclear_words if word in query)
        return max(1.0 - (unclear_count * 0.2), 0.0)
    
    def _llm_certainty(self, response: str) -> float:
        """LLM ë‹µë³€ í™•ì‹¤ì„± (hedging í‘œí˜„ ê°ì§€)"""
        hedge_words = ["ì•„ë§ˆ", "ì•„ë§ˆë„", "í˜¹ì‹œ", "ì•„ë‹ê¹Œ", "ì‹¶ìŠµë‹ˆë‹¤", "ê²ƒ ê°™ìŠµë‹ˆë‹¤"]
        hedge_count = sum(1 for word in hedge_words if word in response)
        return max(1.0 - (hedge_count * 0.15), 0.0)
```

---

#### Feature 3.1.2: Real-time Operator Intervention

**Feature ID**: `F3.1.2`  
**Priority**: P0 (Must Have)  
**Complexity**: High  
**Estimated Story Points**: 21

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-3.1.2-01 | WebSocket ì‹¤ì‹œê°„ í†µì‹  | âœ… AI â†” ìš´ì˜ì ê°„ <200ms latency |
| FR-3.1.2-02 | ìš´ì˜ì Chat ì¸í„°í˜ì´ìŠ¤ | âœ… í†µí™” ì¤‘ ì±„íŒ…ìœ¼ë¡œ ì •ë‹µ ì…ë ¥ ê°€ëŠ¥ |
| FR-3.1.2-03 | AI ë‹µë³€ ëŒ€ì²´ | âœ… ìš´ì˜ì ì…ë ¥ â†’ AIê°€ ì¦‰ì‹œ ê³ ê°ì—ê²Œ ì „ë‹¬ |
| FR-3.1.2-04 | Feedback ì¦‰ì‹œ í•™ìŠµ | âœ… ì •ë‹µì€ VectorDBì— ì¦‰ì‹œ ì €ì¥ |
| FR-3.1.2-05 | ê°œì… ì´ë ¥ ê¸°ë¡ | âœ… ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„ ìˆ˜ì •í–ˆëŠ”ì§€ Audit Log |

##### User Stories

**US-3.1.2-01**: í†µí™” ì¤‘ AI ë‹µë³€ ìˆ˜ì •
```gherkin
As a: ìš´ì˜ì
I want to: AIê°€ ì˜ëª»ëœ ë‹µë³€ì„ í•˜ë ¤ê³  í•  ë•Œ ì¦‰ì‹œ ê°œì…í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ê³ ê°ì—ê²Œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: AIê°€ ê³ ê° ì§ˆë¬¸ì— ë‹µë³€í•˜ë ¤ê³  í•  ë•Œ
- When: Confidence Scoreê°€ 60% ë¯¸ë§Œì´ê³ 
- And: ìš´ì˜ìê°€ "ê°œì…í•˜ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´
- Then: ì‹¤ì‹œê°„ Chat ì°½ì´ ì—´ë ¤ì•¼ í•©ë‹ˆë‹¤
- And: AIê°€ ì œì‹œí•œ ë‹µë³€ì´ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ìš´ì˜ìê°€ ì •ë‹µì„ ì…ë ¥í•˜ë©´
- Then: AIê°€ ì¦‰ì‹œ ê³ ê°ì—ê²Œ ìˆ˜ì •ëœ ë‹µë³€ì„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤
- And: ìˆ˜ì •ëœ Q&AëŠ” VectorDBì— ì¦‰ì‹œ ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Scenario: ì‹ ì œí’ˆ ì¶œì‹œ ì§í›„ ë¬¸ì˜
  
  Call Flow:
    [10:00:00] Customer: "ì‹ ì œí’ˆ ì•„ì´í° 16 Pro ìˆë‚˜ìš”?"
    [10:00:01] AI (Internal): 
      - RAG Search: No results (ì‹ ì œí’ˆì´ë¼ DBì— ì—†ìŒ)
      - Confidence: 25% âš ï¸
      - Alert sent to Operator
    
    [10:00:02] Operator Dashboard:
      âš ï¸ Low Confidence (25%)
      Question: "ì‹ ì œí’ˆ ì•„ì´í° 16 Pro ìˆë‚˜ìš”?"
      AI Draft: "ì£„ì†¡í•©ë‹ˆë‹¤, í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
      
      [ê°œì…í•˜ê¸°] â† Click
    
    [10:00:03] Chat Window Opens:
      AI Draft: "ì£„ì†¡í•©ë‹ˆë‹¤, í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
      
      Operator Types:
      "ë„¤, ì•„ì´í° 16 ProëŠ” ì–´ì œ ì…ê³ ë˜ì—ˆìŠµë‹ˆë‹¤. 
       256GB ëª¨ë¸ ì¬ê³  ìˆìœ¼ë©°, ê°€ê²©ì€ â‚©1,500,000ì…ë‹ˆë‹¤"
      
      [ì „ì†¡] â† Click
    
    [10:00:05] AI to Customer (TTS):
      "ë„¤, ì•„ì´í° 16 ProëŠ” ì–´ì œ ì…ê³ ë˜ì—ˆìŠµë‹ˆë‹¤. 
       256GB ëª¨ë¸ ì¬ê³  ìˆìœ¼ë©°, ê°€ê²©ì€ â‚©1,500,000ì…ë‹ˆë‹¤"
    
    [10:00:06] Background:
      âœ… Q&A saved to VectorDB
      âœ… Audit Log created
      âœ… Next call: AI can answer this question automatically

Performance:
  - Operator notification: 200ms
  - Operator typing: 5s
  - AI TTS response: 3s
  - Total intervention time: ~8s
```

##### Technical Design

**Real-time Communication Architecture**:
```
[AI Agent] <--> [WebSocket Server] <--> [Operator Dashboard]
                        â†“
                [Message Queue]
                        â†“
                [Vector DB Writer]
```

**WebSocket Implementation**:
```python
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, call_id: str, websocket: WebSocket):
        await websocket.accept()
        self.active_connections[call_id] = websocket
    
    async def disconnect(self, call_id: str):
        self.active_connections.pop(call_id, None)
    
    async def send_alert(self, call_id: str, alert: dict):
        """ìš´ì˜ìì—ê²Œ Low Confidence ì•Œë¦¼"""
        if call_id in self.active_connections:
            await self.active_connections[call_id].send_json(alert)
    
    async def receive_feedback(self, call_id: str) -> dict:
        """ìš´ì˜ìë¡œë¶€í„° ì •ë‹µ ìˆ˜ì‹ """
        if call_id in self.active_connections:
            data = await self.active_connections[call_id].receive_json()
            return data
        return None

manager = ConnectionManager()

@app.websocket("/ws/call/{call_id}")
async def websocket_endpoint(websocket: WebSocket, call_id: str):
    await manager.connect(call_id, websocket)
    try:
        while True:
            data = await websocket.receive_json()
            # ìš´ì˜ì í”¼ë“œë°± ì²˜ë¦¬
            await process_operator_feedback(call_id, data)
    except WebSocketDisconnect:
        await manager.disconnect(call_id)

async def process_operator_feedback(call_id: str, feedback: dict):
    """ìš´ì˜ì í”¼ë“œë°± ì²˜ë¦¬"""
    # 1. AIì—ê²Œ ìƒˆ ë‹µë³€ ì „ë‹¬
    await ai_agent.update_response(call_id, feedback["answer"])
    
    # 2. VectorDBì— ì¦‰ì‹œ ì €ì¥
    await vector_db.upsert({
        "question": feedback["question"],
        "answer": feedback["answer"],
        "source": "operator_correction",
        "call_id": call_id,
        "timestamp": datetime.now()
    })
    
    # 3. Audit Log ê¸°ë¡
    await audit_log.create({
        "call_id": call_id,
        "operator_id": feedback["operator_id"],
        "action": "correction",
        "original_answer": feedback["original"],
        "new_answer": feedback["answer"]
    })
```

---

#### Feature 3.1.3: Post-call Review & Labeling

**Feature ID**: `F3.1.3`  
**Priority**: P1 (Should Have)  
**Complexity**: Medium  
**Estimated Story Points**: 13

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-3.1.3-01 | Low Confidence í†µí™” ìë™ ì¶”ì¶œ | âœ… Confidence < 70% í†µí™” ëª©ë¡í™” |
| FR-3.1.3-02 | Transcript Review UI | âœ… í†µí™” ë‚´ìš© ì¬ìƒ + í…ìŠ¤íŠ¸ í‘œì‹œ |
| FR-3.1.3-03 | ì •ë‹µ ë ˆì´ë¸”ë§ | âœ… "ì •ë‹µì€ ì´ê²ƒì…ë‹ˆë‹¤" ì…ë ¥ â†’ ì €ì¥ |
| FR-3.1.3-04 | Batch Processing | âœ… í•œ ë²ˆì— ì—¬ëŸ¬ í†µí™” ë¦¬ë·° ê°€ëŠ¥ |
| FR-3.1.3-05 | í•™ìŠµ íš¨ê³¼ ì¸¡ì • | âœ… Before/After Confidence ë¹„êµ |

##### User Stories

**US-3.1.3-01**: í†µí™” í›„ í’ˆì§ˆ ê°œì„ 
```gherkin
As a: ìš´ì˜ì
I want to: í•˜ë£¨ ì¢…ë£Œ í›„ AIê°€ ì˜ëª» ë‹µë³€í•œ í†µí™”ë¥¼ ë¦¬ë·°í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ë‚´ì¼ë¶€í„°ëŠ” ê°™ì€ ì‹¤ìˆ˜ë¥¼ í•˜ì§€ ì•Šë„ë¡ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: í•˜ë£¨ ì—…ë¬´ê°€ ì¢…ë£Œë˜ì—ˆì„ ë•Œ
- When: "í†µí™” ë¦¬ë·°" ë©”ë‰´ì— ì ‘ì†í•˜ë©´
- Then: Low Confidence í†µí™” ëª©ë¡ì´ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ê° í†µí™”ì˜ Confidence Score, ë¬¸ì œ ìœ í˜•ì´ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: í†µí™”ë¥¼ ì„ íƒí•˜ë©´ Transcriptì™€ AI ë‹µë³€ì„ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- And: ì •ë‹µì„ ì…ë ¥í•˜ê³  ì €ì¥í•˜ë©´
- Then: VectorDBì— ì¦‰ì‹œ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ë‹¤ìŒë‚  ìœ ì‚¬ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤

Example:
  End of Day Review:
  
  ğŸ“‹ Low Confidence Calls Today (2026-01-30):
  Total: 15 calls
  
  | Call ID | Time | Question | Confidence | Status |
  |---------|------|----------|------------|--------|
  | abc123 | 10:00 | "ì‹ ì œí’ˆ ìˆë‚˜ìš”?" | 25% | â¬œ Not Reviewed |
  | def456 | 14:30 | "ë°°ì†¡ì§€ ë³€ê²½ ê°€ëŠ¥?" | 58% | â¬œ Not Reviewed |
  | ghi789 | 16:00 | "ì´ê±° í™˜ë¶ˆë¼?" | 45% | â¬œ Not Reviewed |
  
  Operator Actions:
    1. Click "abc123" â†’ Open Review UI
    2. Listen to audio + Read transcript
    3. Review AI answer: "ì£„ì†¡í•©ë‹ˆë‹¤, í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
    4. Input correct answer: "ë„¤, ì•„ì´í° 16 Pro ì¬ê³  ìˆìŠµë‹ˆë‹¤"
    5. Click "Save & Learn"
    6. Status changed: âœ… Reviewed
  
  Next Day:
    Customer: "ì‹ ì œí’ˆ ì•„ì´í° 16 Pro ìˆë‚˜ìš”?"
    AI: (RAG finds yesterday's correction)
        "ë„¤, ì•„ì´í° 16 Pro ì¬ê³  ìˆìŠµë‹ˆë‹¤"
        Confidence: 92% âœ…
```

##### Technical Design

**Review Dashboard UI**:
```typescript
interface CallReview {
  callId: string;
  timestamp: Date;
  question: string;
  aiAnswer: string;
  confidence: number;
  audioUrl: string;
  transcriptUrl: string;
  status: 'pending' | 'reviewed' | 'skipped';
}

// React Component
const CallReviewDashboard: React.FC = () => {
  const [calls, setCalls] = useState<CallReview[]>([]);
  
  useEffect(() => {
    // Fetch low confidence calls
    fetchLowConfidenceCalls().then(setCalls);
  }, []);
  
  const handleReview = async (callId: string, correctAnswer: string) => {
    await api.submitCorrection(callId, correctAnswer);
    // Update status
    setCalls(prev => prev.map(call => 
      call.callId === callId 
        ? {...call, status: 'reviewed'} 
        : call
    ));
  };
  
  return (
    <div>
      <h1>í†µí™” ë¦¬ë·° (Low Confidence)</h1>
      <Table data={calls} onReview={handleReview} />
    </div>
  );
};
```

---

### Epic 3.2: Shadowing Mode (ì‹ ì… êµìœ¡ ë„êµ¬)

#### Feature 3.2.1: Real-time Agent Assistance

**Feature ID**: `F3.2.1`  
**Priority**: P1 (Should Have)  
**Complexity**: High  
**Estimated Story Points**: 21

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-3.2.1-01 | ìƒë‹´ì› í†µí™” ì¤‘ AI ê°€ì´ë“œ ì œê³µ | âœ… ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€ ê°€ì´ë“œ í‘œì‹œ |
| FR-3.2.1-02 | ê´€ë ¨ ì§€ì‹ ìë™ ê²€ìƒ‰ | âœ… ê³ ê° ì§ˆë¬¸ ë“¤ìœ¼ë©´ ì¦‰ì‹œ RAG ê²€ìƒ‰ |
| FR-3.2.1-03 | Script ì œê³µ | âœ… "ì´ë ‡ê²Œ ë‹µë³€í•˜ì„¸ìš”" í…œí”Œë¦¿ |
| FR-3.2.1-04 | ìƒë‹´ì› ìˆ˜ì¤€ë³„ ê°€ì´ë“œ ì¡°ì ˆ | âœ… ì‹ ì…/ê²½ë ¥ì— ë”°ë¼ ê°€ì´ë“œ ìˆ˜ì¤€ ë³€ê²½ |
| FR-3.2.1-05 | í•™ìŠµ íš¨ê³¼ ì¸¡ì • | âœ… ê°€ì´ë“œ ë”°ë¥¸ ê²½ìš° vs. ì•ˆ ë”°ë¥¸ ê²½ìš° ë¹„êµ |

##### User Stories

**US-3.2.1-01**: ì‹ ì… ìƒë‹´ì› ì‹¤ì‹œê°„ ì§€ì›
```gherkin
As a: ì‹ ì… ìƒë‹´ì›
I want to: í†µí™” ì¤‘ AIê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤
So that: ë§‰íˆì§€ ì•Šê³  ìì‹ ìˆê²Œ ê³ ê°ì„ ì‘ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ì‹ ì… ìƒë‹´ì›ì´ ê³ ê°ê³¼ í†µí™” ì¤‘ì¼ ë•Œ
- When: ê³ ê°ì´ ì§ˆë¬¸ì„ í•˜ë©´
- Then: AIê°€ ìë™ìœ¼ë¡œ ê´€ë ¨ ì§€ì‹ì„ ê²€ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤
- And: ìƒë‹´ì› í™”ë©´ì— ì¶”ì²œ ë‹µë³€ì´ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ë‹µë³€ í…œí”Œë¦¿, ê´€ë ¨ ì •ì±…, ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ê°€ í•¨ê»˜ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- And: ê°€ì´ë“œëŠ” 2ì´ˆ ì´ë‚´ì— í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Scenario: ì‹ ì… ìƒë‹´ì› ì²« í†µí™”
  
  [10:00:00] Customer: "ë°°ì†¡ë¹„ê°€ ì™œ ì´ë ‡ê²Œ ë¹„ì‹¸ìš”?"
  [10:00:01] AI Guidance (ìƒë‹´ì› í™”ë©´):
    
    ğŸ’¡ ì¶”ì²œ ë‹µë³€:
    "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œì£¼/ë„ì„œì‚°ê°„ ì§€ì—­ì€ ì¶”ê°€ ë°°ì†¡ë¹„ê°€ ë°œìƒí•©ë‹ˆë‹¤.
     ì¼ë°˜ ì§€ì—­ì€ 3ë§Œì› ì´ìƒ êµ¬ë§¤ ì‹œ ë¬´ë£Œë°°ì†¡ì…ë‹ˆë‹¤"
    
    ğŸ“‹ ê´€ë ¨ ì •ì±…:
    - ì œì£¼/ë„ì„œì‚°ê°„: +3,000ì›
    - ì¼ë°˜ ë°°ì†¡ë¹„: 3,000ì›
    - ë¬´ë£Œë°°ì†¡ ê¸°ì¤€: 30,000ì› ì´ìƒ
    
    ğŸ” ìœ ì‚¬ ì‚¬ë¡€ (3ê±´):
    - "ë°°ì†¡ë¹„ í™˜ë¶ˆ ì•ˆë˜ë‚˜ìš”?" â†’ "ë°°ì†¡ë¹„ëŠ” í™˜ë¶ˆ ì œì™¸ë©ë‹ˆë‹¤"
    - "ë„ì„œì‚°ê°„ì´ ì•„ë‹Œë° ë¹„ì‹¸ìš”" â†’ "ì£¼ì†Œ í™•ì¸ í›„ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤"
    
    [ì´ ë‹µë³€ ì‚¬ìš©] [ë‹¤ë¥¸ ë‹µë³€ ë³´ê¸°]
  
  [10:00:03] Agent (ìì‹ ìˆê²Œ): "ì£„ì†¡í•©ë‹ˆë‹¤. ì œì£¼/ë„ì„œì‚°ê°„ ì§€ì—­ì€..."
  [10:00:10] Customer: "ê·¸ëŸ¼ í™˜ë¶ˆ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
  [10:00:11] AI Guidance:
    "ë°°ì†¡ë¹„ëŠ” í™˜ë¶ˆ ëŒ€ìƒì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. 
     ë‹¨, ìƒí’ˆ í•˜ìë¡œ ì¸í•œ ë°˜í’ˆ ì‹œì—ëŠ” ë°°ì†¡ë¹„ë„ í™˜ë¶ˆë©ë‹ˆë‹¤"

Performance:
  - Customer question detected: 500ms
  - RAG search: 1,000ms
  - Guidance display: 1,500ms
  - Total: <2 seconds âœ…
```

##### Technical Design

**Shadowing Mode Architecture**:
```
[Agent Softphone] â†’ [STT Real-time] â†’ [AI Guidance Engine]
                                            â†“
                                       [RAG Search]
                                            â†“
                                    [Agent Dashboard]
```

**Agent Dashboard**:
```typescript
interface GuidanceCard {
  question: string;
  suggestedAnswer: string;
  relatedPolicies: string[];
  similarCases: Array<{question: string, answer: string}>;
  confidence: number;
}

const AgentDashboard: React.FC = () => {
  const [currentCall, setCurrentCall] = useState<Call | null>(null);
  const [guidance, setGuidance] = useState<GuidanceCard | null>(null);
  
  // WebSocket: ì‹¤ì‹œê°„ í†µí™” ë‚´ìš© ìˆ˜ì‹ 
  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/agent/${agentId}`);
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'customer_question') {
        // AIì—ê²Œ ê°€ì´ë“œ ìš”ì²­
        fetchGuidance(data.question).then(setGuidance);
      }
    };
    
    return () => ws.close();
  }, []);
  
  return (
    <div className="agent-dashboard">
      <div className="call-info">
        <h2>í†µí™” ì¤‘: {currentCall?.customerId}</h2>
      </div>
      
      {guidance && (
        <div className="ai-guidance">
          <h3>ğŸ’¡ AI ì¶”ì²œ ë‹µë³€</h3>
          <p className="suggested-answer">{guidance.suggestedAnswer}</p>
          
          <h4>ğŸ“‹ ê´€ë ¨ ì •ì±…</h4>
          <ul>
            {guidance.relatedPolicies.map((policy, i) => (
              <li key={i}>{policy}</li>
            ))}
          </ul>
          
          <h4>ğŸ” ìœ ì‚¬ ì‚¬ë¡€</h4>
          {guidance.similarCases.map((case, i) => (
            <div key={i} className="similar-case">
              <strong>Q: {case.question}</strong>
              <p>A: {case.answer}</p>
            </div>
          ))}
          
          <div className="actions">
            <button onClick={() => useThisAnswer(guidance.suggestedAnswer)}>
              ì´ ë‹µë³€ ì‚¬ìš©
            </button>
            <button onClick={() => fetchAlternatives()}>
              ë‹¤ë¥¸ ë‹µë³€ ë³´ê¸°
            </button>
          </div>
        </div>
      )}
    </div>
  );
};
```

---

## Phase 4: Agentic AI + Multi-Agent

### Epic 4.1: Tool-calling Agent

#### Feature 4.1.1: Autonomous Tool Execution

**Feature ID**: `F4.1.1`  
**Priority**: P2 (Nice to Have)  
**Complexity**: Very High  
**Estimated Story Points**: 34

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-4.1.1-01 | AIê°€ ììœ¨ì ìœ¼ë¡œ Tool ì„ íƒ ë° ì‹¤í–‰ | âœ… LangGraph Agent ê¸°ë°˜ |
| FR-4.1.1-02 | ë‹¤ë‹¨ê³„ Tool Chaining | âœ… Tool A â†’ Tool B â†’ Tool C ìˆœì°¨ ì‹¤í–‰ |
| FR-4.1.1-03 | Tool ì‹¤í–‰ ê¶Œí•œ ê´€ë¦¬ | âœ… ì½ê¸°/ì“°ê¸° ê¶Œí•œ ë¶„ë¦¬, ìŠ¹ì¸ í•„ìš” |
| FR-4.1.1-04 | Rollback ê¸°ëŠ¥ | âœ… Tool ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì´ì „ ìƒíƒœ ë³µêµ¬ |
| FR-4.1.1-05 | Audit Trail | âœ… ëª¨ë“  Tool ì‹¤í–‰ ì´ë ¥ ê¸°ë¡ |

##### User Stories

**US-4.1.1-01**: AIê°€ ì§ì ‘ ì‹œìŠ¤í…œ ì¡°ì‘
```gherkin
As a: ê³ ê°
I want to: AIê°€ ì§ì ‘ ë°°ì†¡ì§€ë¥¼ ë³€ê²½í•´ì£¼ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤
So that: ìƒë‹´ì›ì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ "ë°°ì†¡ì§€ ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”"ë¼ê³  ìš”ì²­í•  ë•Œ
- When: AI Agentê°€ ì‹¤í–‰ë˜ë©´
- Then: ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:
  1. Tool: get_order_info() - ì£¼ë¬¸ ì •ë³´ ì¡°íšŒ
  2. Tool: check_delivery_status() - ë°°ì†¡ ìƒíƒœ í™•ì¸ (ë³€ê²½ ê°€ëŠ¥ ì—¬ë¶€)
  3. Tool: update_delivery_address() - ë°°ì†¡ì§€ ë³€ê²½ (ì“°ê¸° ê¶Œí•œ)
  4. Tool: send_confirmation_sms() - ë³€ê²½ ì™„ë£Œ ë¬¸ì ì „ì†¡
- And: ê° Tool ì‹¤í–‰ ì „ ê³ ê° í™•ì¸ í•„ìš” (ì“°ê¸° ì‘ì—…)
- And: ì „ì²´ í”„ë¡œì„¸ìŠ¤ëŠ” 30ì´ˆ ì´ë‚´ì— ì™„ë£Œë˜ì–´ì•¼ í•©ë‹ˆë‹¤

Example:
  Customer: "ë°°ì†¡ì§€ ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”"
  
  AI Agent Workflow:
    Step 1: Intent = "update_delivery_address"
    Step 2: Slot Filling
      - AI: "ì£¼ë¬¸ë²ˆí˜¸ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
      - Customer: "2024-0130-001"
    
    Step 3: Tool Execution (ìë™)
      [Tool 1] get_order_info("2024-0130-001")
        â†’ Result: {status: "preparing", address: "ì„œìš¸ ê°•ë‚¨êµ¬..."}
      
      [Tool 2] check_delivery_status("2024-0130-001")
        â†’ Result: {changeable: true, reason: "ë°°ì†¡ ì „"}
      
      AI: "í˜„ì¬ ë°°ì†¡ ì „ ë‹¨ê³„ë¼ ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìƒˆ ì£¼ì†Œ ì•Œë ¤ì£¼ì„¸ìš”"
      Customer: "ì„œìš¸ ì„œì´ˆêµ¬ 123-45"
      
      [Tool 3] update_delivery_address("2024-0130-001", "ì„œìš¸ ì„œì´ˆêµ¬ 123-45")
        â†’ Requires Approval: "ë°°ì†¡ì§€ë¥¼ ë³€ê²½í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Yes/No)"
        â†’ Customer: "Yes"
        â†’ Result: {success: true, new_address: "ì„œìš¸ ì„œì´ˆêµ¬ 123-45"}
      
      [Tool 4] send_confirmation_sms(customer_phone, "ë°°ì†¡ì§€ ë³€ê²½ ì™„ë£Œ")
        â†’ Result: {sent: true}
    
    AI: "ë°°ì†¡ì§€ê°€ ì„œìš¸ ì„œì´ˆêµ¬ 123-45ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. 
         í™•ì¸ ë¬¸ì ì „ì†¡í–ˆìŠµë‹ˆë‹¤"

Timeline:
  - Slot Filling: 10s
  - Tool 1-2 (read): 3s
  - Customer confirmation: 5s
  - Tool 3-4 (write): 5s
  - Total: 23s âœ…
```

##### Technical Design

**LangGraph Agent Workflow**:
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class AgentState(TypedDict):
    messages: List[dict]
    intent: str
    slots: dict
    tool_results: List[dict]
    next_action: str

# Tool Definitions
tools = [
    {
        "name": "get_order_info",
        "description": "ì£¼ë¬¸ ì •ë³´ ì¡°íšŒ",
        "permission": "read",
        "function": crm_api.get_order
    },
    {
        "name": "update_delivery_address",
        "description": "ë°°ì†¡ì§€ ë³€ê²½",
        "permission": "write",  # ìŠ¹ì¸ í•„ìš”
        "function": crm_api.update_address,
        "requires_approval": True
    }
]

# Graph êµ¬ì„±
workflow = StateGraph(AgentState)

# Nodes
workflow.add_node("classify_intent", classify_intent_node)
workflow.add_node("fill_slots", slot_filling_node)
workflow.add_node("select_tool", tool_selection_node)
workflow.add_node("execute_tool", tool_execution_node)
workflow.add_node("generate_response", response_generation_node)

# Edges
workflow.add_edge("classify_intent", "fill_slots")
workflow.add_conditional_edges(
    "fill_slots",
    lambda state: "complete" if state["slots_complete"] else "continue",
    {
        "complete": "select_tool",
        "continue": "fill_slots"
    }
)
workflow.add_edge("select_tool", "execute_tool")
workflow.add_conditional_edges(
    "execute_tool",
    lambda state: "more_tools" if state["needs_more_tools"] else "done",
    {
        "more_tools": "select_tool",
        "done": "generate_response"
    }
)
workflow.add_edge("generate_response", END)

# Compile
agent = workflow.compile()

# Run
result = await agent.ainvoke({
    "messages": [{"role": "user", "content": "ë°°ì†¡ì§€ ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”"}]
})
```

---

### Epic 4.2: Multi-Agent Collaboration

#### Feature 4.2.1: Agent Orchestration

**Feature ID**: `F4.2.1`  
**Priority**: P2 (Nice to Have)  
**Complexity**: Very High  
**Estimated Story Points**: 34

##### Functional Requirements

| ID | Requirement | Acceptance Criteria |
|----|-------------|---------------------|
| FR-4.2.1-01 | ì—¬ëŸ¬ Agentê°€ í˜‘ë ¥í•˜ì—¬ ë¬¸ì œ í•´ê²° | âœ… Multi-Agent Orchestrator êµ¬í˜„ |
| FR-4.2.1-02 | Agent ê°„ Communication | âœ… Message Passing ë©”ì»¤ë‹ˆì¦˜ |
| FR-4.2.1-03 | ë³‘ë ¬ ì‹¤í–‰ ì§€ì› | âœ… ë…ë¦½ì ì¸ ì‘ì—…ì€ ë™ì‹œ ì‹¤í–‰ |
| FR-4.2.1-04 | Agent ìš°ì„ ìˆœìœ„ ê´€ë¦¬ | âœ… ì¤‘ìš”ë„ì— ë”°ë¼ ì‹¤í–‰ ìˆœì„œ ì¡°ì • |
| FR-4.2.1-05 | ê²°ê³¼ í†µí•© | âœ… ê° Agent ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„± |

##### User Stories

**US-4.2.1-01**: ë³µì¡í•œ ìš”ì²­ í•œ ë²ˆì— í•´ê²°
```gherkin
As a: ê³ ê°
I want to: ì—¬ëŸ¬ ê°œì˜ ìš”ì²­ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤
So that: ì—¬ëŸ¬ ë²ˆ ì „í™”í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤

Acceptance Criteria:
- Given: ê³ ê°ì´ ë³µì¡í•œ ìš”ì²­ì„ í•  ë•Œ
  ì˜ˆ: "í™˜ë¶ˆí•˜ê³  ì¬ì£¼ë¬¸í•˜ë ¤ê³  í•˜ëŠ”ë°, ì¿ í° ì‚¬ìš© ê°€ëŠ¥í•œì§€ ì•Œë ¤ì¤˜"
- When: Multi-Agent Systemì´ ì‹¤í–‰ë˜ë©´
- Then: ë‹¤ìŒ Agentë“¤ì´ í˜‘ë ¥í•´ì•¼ í•©ë‹ˆë‹¤:
  * Agent 1 (í™˜ë¶ˆ): í™˜ë¶ˆ ê°€ëŠ¥ ì—¬ë¶€ ë° ì ˆì°¨
  * Agent 2 (ì£¼ë¬¸): ì¬ì£¼ë¬¸ ê°€ëŠ¥ ìƒí’ˆ ëª©ë¡
  * Agent 3 (í”„ë¡œëª¨ì…˜): ì¿ í° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
- And: ê° Agentì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤
- And: ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì€ 45ì´ˆ ì´ë‚´ì—¬ì•¼ í•©ë‹ˆë‹¤

Example:
  Customer: "í™˜ë¶ˆí•˜ê³  ì¬ì£¼ë¬¸í•˜ë ¤ê³  í•˜ëŠ”ë°, ì¿ í° ì‚¬ìš© ê°€ëŠ¥í•œì§€ë„ ì•Œë ¤ì¤˜"
  
  Multi-Agent Workflow:
    Orchestrator: 3ê°œ Sub-task ì‹ë³„
    
    [Agent 1: RefundAgent] (ë³‘ë ¬ ì‹¤í–‰)
      Task: í™˜ë¶ˆ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
      Tools: get_order_info(), check_refund_policy()
      Result: {
        "refundable": true,
        "reason": "30ì¼ ì´ë‚´ ì£¼ë¬¸",
        "process_time": "3-5ì¼",
        "amount": 50000
      }
    
    [Agent 2: OrderAgent] (ë³‘ë ¬ ì‹¤í–‰)
      Task: ì¬ì£¼ë¬¸ ê°€ëŠ¥ ìƒí’ˆ í™•ì¸
      Tools: get_product_info(), check_stock()
      Result: {
        "available": true,
        "stock": 15,
        "price": 50000
      }
    
    [Agent 3: PromoAgent] (ë³‘ë ¬ ì‹¤í–‰)
      Task: ì¿ í° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
      Tools: get_customer_coupons(), check_coupon_policy()
      Result: {
        "usable_coupons": [
          {"name": "ì‹ ê·œíšŒì› 10%", "discount": 5000},
          {"name": "ì¬êµ¬ë§¤ 5000ì›", "discount": 5000}
        ],
        "restrictions": "í™˜ë¶ˆ í›„ ì¬ì£¼ë¬¸ ì‹œ ì¿ í° ì‚¬ìš© ê°€ëŠ¥"
      }
    
    [Orchestrator: Result Integration]
      Combine results from all agents:
      
      "ë„¤, í™˜ë¶ˆ ê°€ëŠ¥í•©ë‹ˆë‹¤. 3-5ì¼ ì†Œìš”ë˜ë©° 50,000ì› í™˜ë¶ˆë©ë‹ˆë‹¤.
       ì¬ì£¼ë¬¸í•˜ì‹¤ ìƒí’ˆì€ í˜„ì¬ ì¬ê³  15ê°œ ìˆìŠµë‹ˆë‹¤.
       í™˜ë¶ˆ ì™„ë£Œ í›„ ì¬ì£¼ë¬¸ ì‹œ 'ì‹ ê·œíšŒì› 10%' ë˜ëŠ” 'ì¬êµ¬ë§¤ 5000ì›' ì¿ í° ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
       í™˜ë¶ˆ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"

Timeline:
  - Task decomposition: 2s
  - Agent 1-3 (parallel): 15s
  - Result integration: 3s
  - Total: 20s âœ…
```

##### Technical Design

**Multi-Agent Architecture**:
```python
from typing import List, Dict
import asyncio

class Agent(BaseModel):
    name: str
    specialty: str
    tools: List[Tool]
    llm: ChatGoogleGenerativeAI
    
    async def execute(self, task: str) -> Dict:
        """Agentê°€ ìì‹ ì˜ íŠ¹í™” ì‘ì—… ìˆ˜í–‰"""
        # 1. Task ë¶„ì„
        # 2. Tool ì„ íƒ ë° ì‹¤í–‰
        # 3. ê²°ê³¼ ìƒì„±
        pass

class Orchestrator:
    def __init__(self):
        self.agents = {
            "refund": RefundAgent(),
            "order": OrderAgent(),
            "promo": PromoAgent(),
            "delivery": DeliveryAgent()
        }
    
    async def process(self, user_request: str):
        # 1. Task Decomposition
        tasks = await self.decompose_task(user_request)
        # Example: [
        #   {"agent": "refund", "task": "í™˜ë¶ˆ ê°€ëŠ¥ ì—¬ë¶€"},
        #   {"agent": "order", "task": "ì¬ì£¼ë¬¸ ê°€ëŠ¥ ìƒí’ˆ"},
        #   {"agent": "promo", "task": "ì¿ í° ì‚¬ìš© ê°€ëŠ¥"}
        # ]
        
        # 2. ë³‘ë ¬ ì‹¤í–‰ (ë…ë¦½ì ì¸ ì‘ì—…)
        results = await asyncio.gather(*[
            self.agents[task["agent"]].execute(task["task"])
            for task in tasks
        ])
        
        # 3. ê²°ê³¼ í†µí•©
        integrated_response = await self.integrate_results(results)
        
        return integrated_response
    
    async def decompose_task(self, request: str) -> List[Dict]:
        """LLMìœ¼ë¡œ ë³µì¡í•œ ìš”ì²­ì„ sub-taskë¡œ ë¶„í•´"""
        decompose_prompt = f"""
        ë‹¤ìŒ ê³ ê° ìš”ì²­ì„ ì—¬ëŸ¬ ê°œì˜ sub-taskë¡œ ë¶„í•´í•˜ì„¸ìš”:
        "{request}"
        
        ì‚¬ìš© ê°€ëŠ¥í•œ Agent:
        - refund: í™˜ë¶ˆ ê´€ë ¨
        - order: ì£¼ë¬¸ ê´€ë ¨
        - promo: ì¿ í°/í”„ë¡œëª¨ì…˜ ê´€ë ¨
        - delivery: ë°°ì†¡ ê´€ë ¨
        
        Output (JSON):
        [
          {{"agent": "agent_name", "task": "task_description"}},
          ...
        ]
        """
        response = await self.llm.ainvoke(decompose_prompt)
        return json.loads(response.content)
```

---

## Cross-cutting Concerns

### ì„±ëŠ¥ (Performance)

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| STT Latency | <500ms | RTP packet â†’ Text ì‹œê°„ |
| RAG Retrieval | <100ms | Query â†’ Top-K results |
| LLM Response | <1s | Query â†’ Generated response |
| End-to-End | <2s | ê³ ê° ì§ˆë¬¸ â†’ AI ë‹µë³€ (TTS í¬í•¨) |
| Throughput | 100 concurrent calls | Load test |
| Uptime | 99.9% | Prometheus monitoring |

### ë³´ì•ˆ (Security)

| Requirement | Implementation |
|-------------|----------------|
| í†µí™” ë°ì´í„° ì•”í˜¸í™” | AES-256 at rest, TLS 1.3 in transit |
| PII ë§ˆìŠ¤í‚¹ | ì´ë¦„, ì „í™”ë²ˆí˜¸, ì£¼ì†Œ ìë™ ë§ˆìŠ¤í‚¹ |
| ì ‘ê·¼ ì œì–´ | RBAC (Role-Based Access Control) |
| Audit Log | ëª¨ë“  Tool ì‹¤í–‰, Operator ê°œì… ê¸°ë¡ |
| GDPR ì¤€ìˆ˜ | Right to be forgotten (ë°ì´í„° ì‚­ì œ ìš”ì²­) |

### í™•ì¥ì„± (Scalability)

| Component | Scaling Strategy |
|-----------|------------------|
| SIP PBX | Horizontal (K8s StatefulSet, replicas: 3+) |
| Vector DB | Sharding by date (ì›”ë³„ ë¶„ë¦¬) |
| LLM | Rate limiting + Caching (Redis) |
| WebSocket | Load balancer (sticky sessions) |
| Storage | S3 for recordings, RDS for metadata |

### ëª¨ë‹ˆí„°ë§ (Monitoring)

```yaml
Metrics (Prometheus):
  - sip_pbx_active_calls: Gauge
  - rag_retrieval_latency_seconds: Histogram
  - llm_requests_total: Counter
  - confidence_score_distribution: Histogram
  - operator_intervention_rate: Gauge
  
Alerts:
  - HighLatency: RAG retrieval > 200ms for 5min
  - LowConfidence: >20% calls with confidence <60%
  - HighInterventionRate: Operator intervention > 15%
  - SystemDown: Uptime < 99%

Dashboards (Grafana):
  - Real-time Call Monitoring
  - AI Performance (Accuracy, Latency)
  - HITL Statistics
  - Cost Tracking (API usage)
```

---

## ë¶€ë¡: User Story í…œí”Œë¦¿

### Standard User Story Template

```gherkin
As a: [Role - ì‹œìŠ¤í…œ ê´€ë¦¬ì, ê³ ê°, ìš´ì˜ì, AI ì‹œìŠ¤í…œ ë“±]
I want to: [Goal - ë¬´ì—‡ì„ ì›í•˜ëŠ”ê°€]
So that: [Benefit - ì™œ ì›í•˜ëŠ”ê°€, ì–´ë–¤ ê°€ì¹˜ë¥¼ ì–»ëŠ”ê°€]

Acceptance Criteria:
- Given: [Precondition - ì „ì œ ì¡°ê±´]
- When: [Action - ì–´ë–¤ í–‰ë™ì„ í•  ë•Œ]
- Then: [Outcome - ì˜ˆìƒë˜ëŠ” ê²°ê³¼]
- And: [Additional conditions - ì¶”ê°€ ì¡°ê±´]

Example:
  [Concrete example with input/output]

Performance:
  [Non-functional requirements - latency, throughput ë“±]

Dependencies:
  - [Dependent features, APIs, services]
```

### Epic Template

```markdown
### Epic [ë²ˆí˜¸]: [Epic ì´ë¦„]

#### ê°œìš”
[Epicì˜ ëª©ì ê³¼ ë²”ìœ„ë¥¼ 1-2 ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…]

#### Business Value
[ì´ Epicì´ ì œê³µí•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜]

#### Features
- Feature [ë²ˆí˜¸]: [Feature ì´ë¦„]
- Feature [ë²ˆí˜¸]: [Feature ì´ë¦„]
...

#### Success Metrics
- [ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³µ ì§€í‘œ 1]
- [ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³µ ì§€í‘œ 2]

#### Timeline
- Start Date: [ì‹œì‘ì¼]
- Target Completion: [ëª©í‘œ ì™„ë£Œì¼]
- Dependencies: [ì˜ì¡´ì„±]
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… **Phase 1 Sprint Planning**
   - Epic 1.1-1.3ì„ 2ì£¼ Sprintë¡œ ë¶„í• 
   - Story Point ì¬ì¡°ì •
   - ê°œë°œì í• ë‹¹

2. â¬œ **Technical Spike**
   - Vector DB ì„ íƒ (Pinecone vs. Qdrant) POC
   - LangGraph Agent í”„ë¡œí† íƒ€ì…
   - WebSocket ì‹¤ì‹œê°„ í†µì‹  í…ŒìŠ¤íŠ¸

3. â¬œ **Design Review**
   - UI/UX ë””ìì¸ (Shadowing Mode Dashboard)
   - API ì„¤ê³„ ë¦¬ë·°
   - ë³´ì•ˆ ì•„í‚¤í…ì²˜ ê²€í† 

4. â¬œ **Stakeholder Approval**
   - ê²½ì˜ì§„ ìŠ¹ì¸
   - ì˜ˆì‚° í™•ì •
   - íŒ€ êµ¬ì„±

---

**ë¬¸ì„œ ë²„ì „ íˆìŠ¤í† ë¦¬**:
- v2.0 (2026-01-30): Phase 1-4 ìƒì„¸ ìš”êµ¬ì‚¬í•­ ë° User Story ì‘ì„±
- v1.1 (2026-01-05): ê¸°ë³¸ SIP PBX PRD
- v1.0 (2025-10-27): ì´ˆê¸° PRD ìƒì„±

**Maintained by**: Product Team  
**Last Updated**: 2026-01-30  
**Next Review**: 2026-02-15
